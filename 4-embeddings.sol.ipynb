{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-embeddings.sol.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPak0NxRmcYH8gNb2UYIQyo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillena/dcc-ia-nlp/blob/master/4-embeddings.sol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOPcd3UfJ5ec"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonMA0Csl_Z2"
      },
      "source": [
        "# Actividad 1: Word2vec en tensorflow\n",
        "\n",
        "Observe el preprocesamiento que se realiza al corpus, la estructura construida con Tensorflow y el procedimiento para entrenar el modelo.\n",
        "\n",
        "\n",
        "1.   Construya los word embeddings desde los pesos y sesgos del modelo entrenado\n",
        "2.   Visualice los embeddings bidimensionales en un gráfico de dispersión e interprete los resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zak8IEVRl8JD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCrljKgFmJFj"
      },
      "source": [
        "corpus = ['king is a strong man', \n",
        "          'queen is a wise woman', \n",
        "          'boy is a young man',\n",
        "          'girl is a young woman',\n",
        "          'prince is a young king',\n",
        "          'princess is a young queen',\n",
        "          'man is strong', \n",
        "          'woman is pretty',\n",
        "          'prince is a boy will be king',\n",
        "          'princess is a girl will be queen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VnMZGnBmS4V"
      },
      "source": [
        "def preprocess(text):\n",
        "  tokens = text.split(\" \")\n",
        "  return [token for token in tokens if len(token) > 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA6vpojsnI9L"
      },
      "source": [
        "def get_vocabulary(corpus):\n",
        "  vocabulary = []\n",
        "  for text in corpus:\n",
        "    vocabulary += text\n",
        "  return sorted(list(set(vocabulary)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InbdYdnmslf"
      },
      "source": [
        "sentences = list(map(preprocess, corpus))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaiaxx3Cm_eh"
      },
      "source": [
        "vocabulary = get_vocabulary(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCP-PFhln7wE"
      },
      "source": [
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        # Acá se toma una ventana de -WINDOWS_SIZE, WINDOWS_SIZE para generar el skip gram. Dado que las \n",
        "        # frases son cortas, se utiliza min y max para tener cuidado con los límites de la frase. \n",
        "        # Además, el +1 en el límite superior es para considerar el índice de la propia palabra en cuestión \n",
        "        # (probar qué ocurre cuando se elimina dicho +1)\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1]: \n",
        "            if neighbor != word:\n",
        "                data.append((word, neighbor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGhl12TpPEc"
      },
      "source": [
        "features = np.zeros((len(data),len(vocabulary)),dtype=np.float32)\n",
        "labels = np.zeros((len(data),len(vocabulary)),dtype=np.float32)\n",
        "for i,(feature,label) in enumerate(data):\n",
        "  features[i,vocabulary.index(feature)] = 1\n",
        "  labels[i,vocabulary.index(label)] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g1a0Y-szpRZ"
      },
      "source": [
        "class Word2Vec:\n",
        "  def __init__(self, vocab_size=0, embedding_dim=2, epochs=10000):\n",
        "    self.vocab_size=vocab_size\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.epochs=epochs\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
        "  def train(self, x_train=None, y_train=None):\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.vocab_size, self.embedding_dim]))\n",
        "    self.b1 = tf.Variable(tf.random.normal([self.embedding_dim])) #bias\n",
        " \n",
        "    self.W2 = tf.Variable(tf.random.normal([self.embedding_dim, self.vocab_size]))\n",
        "    self.b2 = tf.Variable(tf.random.normal([self.vocab_size]))\n",
        " \n",
        "    for _ in range(self.epochs):\n",
        "      with tf.GradientTape() as t:\n",
        "        hidden_layer = tf.add(tf.matmul(x_train,self.W1),self.b1) \n",
        "        output_layer = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, self.W2), self.b2))\n",
        "        cross_entropy_loss = tf.reduce_mean(-tf.math.reduce_sum(y_train * tf.math.log(output_layer), axis=[1]))\n",
        " \n",
        "      grads = t.gradient(cross_entropy_loss, [self.W1, self.b1, self.W2, self.b2])\n",
        "      self.optimizer.apply_gradients(zip(grads,[self.W1, self.b1, self.W2, self.b2]))\n",
        "      if(_ % 1000 == 0):\n",
        "        print(cross_entropy_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FswiyGsE0ETj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e24e6d-85bd-46f2-b6a0-ca423255867b"
      },
      "source": [
        "w2v = Word2Vec(vocab_size=len(vocabulary), epochs=10000)\n",
        "w2v.train(features, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.4456189, shape=(), dtype=float32)\n",
            "tf.Tensor(2.0129576, shape=(), dtype=float32)\n",
            "tf.Tensor(1.9267795, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8863031, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8666987, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8570851, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8509732, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8464859, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8429255, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8399556, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazPhyRg6Xqi"
      },
      "source": [
        "vectors = w2v.W1 + w2v.b1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fta0maHVeYv0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "f0399a37-9fe5-49a5-ebde-387bb2432ab9"
      },
      "source": [
        "import plotly.express as px\n",
        "px.scatter(x=vectors[:,0],y=vectors[:,1],text=vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"97f6a80b-6966-49ad-be6e-deba4075a63f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"97f6a80b-6966-49ad-be6e-deba4075a63f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '97f6a80b-6966-49ad-be6e-deba4075a63f',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"boy\", \"girl\", \"king\", \"man\", \"pretty\", \"prince\", \"princess\", \"queen\", \"strong\", \"will\", \"wise\", \"woman\", \"young\"], \"type\": \"scatter\", \"x\": [2.4160118103027344, 0.030059069395065308, 0.9851683378219604, 0.7323525547981262, -3.5570003986358643, 1.0405234098434448, 0.20826579630374908, 0.15071293711662292, 6.314052104949951, -0.1458485722541809, -1.7413665056228638, 0.10160708427429199, -0.19191226363182068], \"xaxis\": \"x\", \"y\": [-0.6877702474594116, 1.1454380750656128, -1.0500692129135132, -1.4682793617248535, 1.441593885421753, -0.5425188541412354, 1.573630452156067, 2.8638198375701904, -1.8496800661087036, -0.8703504800796509, -0.1052369773387909, 4.0289306640625, -0.9091567993164062], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('97f6a80b-6966-49ad-be6e-deba4075a63f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUqZEv1-4RL7"
      },
      "source": [
        "## Embeddings con gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDcmrlhNLkSC"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import gensim\n",
        "import gensim.downloader\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pc9wPn4vQgL"
      },
      "source": [
        "Descargamos el corpus Brown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxoUU72HiAEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c094b79e-6858-47cb-d8e1-07e6495c757c"
      },
      "source": [
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2y8Lb66OMHs"
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKoP29UJM60q"
      },
      "source": [
        "corpus = nltk.corpus.brown.sents()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqhjOSpvBUF"
      },
      "source": [
        "Entrenamos un modelo model sobre el corpus Brown, el cual contiene alrededor de 1.000.000 de palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCFDEXJlNDxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e6015b-288b-4c90-f89a-77e52f70c32b"
      },
      "source": [
        "model = gensim.models.word2vec.Word2Vec(sentences = corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-23 16:15:07,472 : INFO : collecting all words and their counts\n",
            "2021-11-23 16:15:07,477 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-11-23 16:15:08,096 : INFO : PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
            "2021-11-23 16:15:08,644 : INFO : PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
            "2021-11-23 16:15:09,239 : INFO : PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
            "2021-11-23 16:15:09,786 : INFO : PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
            "2021-11-23 16:15:10,215 : INFO : PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
            "2021-11-23 16:15:10,531 : INFO : collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
            "2021-11-23 16:15:10,532 : INFO : Loading a fresh vocabulary\n",
            "2021-11-23 16:15:10,592 : INFO : effective_min_count=5 retains 15173 unique words (27% of original 56057, drops 40884)\n",
            "2021-11-23 16:15:10,595 : INFO : effective_min_count=5 leaves 1095086 word corpus (94% of original 1161192, drops 66106)\n",
            "2021-11-23 16:15:10,652 : INFO : deleting the raw counts dictionary of 56057 items\n",
            "2021-11-23 16:15:10,658 : INFO : sample=0.001 downsamples 42 most-common words\n",
            "2021-11-23 16:15:10,661 : INFO : downsampling leaves estimated 781596 word corpus (71.4% of prior 1095086)\n",
            "2021-11-23 16:15:10,715 : INFO : estimated required memory for 15173 words and 100 dimensions: 19724900 bytes\n",
            "2021-11-23 16:15:10,717 : INFO : resetting layer weights\n",
            "2021-11-23 16:15:13,958 : INFO : training model with 3 workers on 15173 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2021-11-23 16:15:14,991 : INFO : EPOCH 1 - PROGRESS: at 20.81% examples, 169404 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:16,006 : INFO : EPOCH 1 - PROGRESS: at 42.29% examples, 173336 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:17,036 : INFO : EPOCH 1 - PROGRESS: at 61.85% examples, 174679 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:18,061 : INFO : EPOCH 1 - PROGRESS: at 89.23% examples, 173897 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:18,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-11-23 16:15:18,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-11-23 16:15:18,491 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-11-23 16:15:18,493 : INFO : EPOCH - 1 : training on 1161192 raw words (781703 effective words) took 4.5s, 172642 effective words/s\n",
            "2021-11-23 16:15:19,536 : INFO : EPOCH 2 - PROGRESS: at 20.81% examples, 167945 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:20,555 : INFO : EPOCH 2 - PROGRESS: at 42.29% examples, 172268 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:21,579 : INFO : EPOCH 2 - PROGRESS: at 62.56% examples, 176481 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:22,605 : INFO : EPOCH 2 - PROGRESS: at 89.23% examples, 173590 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:23,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-11-23 16:15:23,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-11-23 16:15:23,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-11-23 16:15:23,030 : INFO : EPOCH - 2 : training on 1161192 raw words (782023 effective words) took 4.5s, 172646 effective words/s\n",
            "2021-11-23 16:15:24,071 : INFO : EPOCH 3 - PROGRESS: at 20.81% examples, 168098 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:25,084 : INFO : EPOCH 3 - PROGRESS: at 42.29% examples, 173034 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:26,111 : INFO : EPOCH 3 - PROGRESS: at 62.56% examples, 176785 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:27,136 : INFO : EPOCH 3 - PROGRESS: at 89.23% examples, 173747 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:27,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-11-23 16:15:27,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-11-23 16:15:27,597 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-11-23 16:15:27,598 : INFO : EPOCH - 3 : training on 1161192 raw words (781609 effective words) took 4.6s, 171397 effective words/s\n",
            "2021-11-23 16:15:28,623 : INFO : EPOCH 4 - PROGRESS: at 20.81% examples, 170952 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:29,631 : INFO : EPOCH 4 - PROGRESS: at 42.29% examples, 174768 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:30,663 : INFO : EPOCH 4 - PROGRESS: at 62.56% examples, 177736 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:31,668 : INFO : EPOCH 4 - PROGRESS: at 89.23% examples, 175335 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:32,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-11-23 16:15:32,072 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-11-23 16:15:32,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-11-23 16:15:32,081 : INFO : EPOCH - 4 : training on 1161192 raw words (781531 effective words) took 4.5s, 174670 effective words/s\n",
            "2021-11-23 16:15:33,094 : INFO : EPOCH 5 - PROGRESS: at 20.81% examples, 173240 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:34,106 : INFO : EPOCH 5 - PROGRESS: at 42.29% examples, 175570 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:35,128 : INFO : EPOCH 5 - PROGRESS: at 62.56% examples, 178871 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:36,159 : INFO : EPOCH 5 - PROGRESS: at 90.29% examples, 176715 words/s, in_qsize 0, out_qsize 0\n",
            "2021-11-23 16:15:36,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-11-23 16:15:36,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-11-23 16:15:36,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-11-23 16:15:36,534 : INFO : EPOCH - 5 : training on 1161192 raw words (782022 effective words) took 4.4s, 175954 effective words/s\n",
            "2021-11-23 16:15:36,539 : INFO : training on a 5805960 raw words (3908888 effective words) took 22.6s, 173123 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ntZpYYBvGFc"
      },
      "source": [
        "Importamos un modelo de word2vec entrenado sobre google news, este modelo fue entrenado sobre un corpus de 3.000.000.000 de palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPnP7Rh5jVpk"
      },
      "source": [
        "news_path = gensim.downloader.load('word2vec-google-news-300', return_path=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr_Qjj5Lik5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587f48ce-ca69-4e4d-e56d-c0405684ac14"
      },
      "source": [
        "news = gensim.models.KeyedVectors.load_word2vec_format(news_path, binary=True, limit=20000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-23 16:15:36,629 : INFO : loading projection weights from /root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
            "2021-11-23 16:15:37,404 : INFO : loaded (20000, 300) matrix from /root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REu7SPwCrKK2"
      },
      "source": [
        "## Actividad 2: Exploración de los embeddings\n",
        "\n",
        "Después de calcular los embeddings, podemos asociar un vector de números reales, de dimensiones conocidas a una palabra de nuestro vocabulario.\n",
        "\n",
        "\n",
        "1.   ¿Cuántas dimensiones tiene cada vector asociado a las palabras en cada uno de los modelos?\n",
        "2.   ¿Cuántos vectores hay en cada uno de los modelos?\n",
        "3.   ¿Existen diferencian en el tamaño del vocabulario del modelo `model` y el modelo news?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RtInP-wrHEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b31cdc-982f-42ee-d0b7-6182d7794c59"
      },
      "source": [
        "news.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9pXmUsLeg0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d377d949-9bc3-4a11-d8da-695ee0104d5f"
      },
      "source": [
        "model.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15173, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBxFNhxZSoZ0"
      },
      "source": [
        "## Actividad 3: Similaridad y analogía\n",
        "\n",
        "Existen un par de cualidades semánticas de las palabras, las cuales pueden ser fácilmente demostradas a través de operaciones vectoriales sobre el espacio generado por el proceso de cálculo de embeddings.\n",
        "\n",
        "La similaridad es la métrica de cercanía que tienen 2 palabras, esta característica es fácil de representar a través de la similaridad coseno entre 2 vectores.\n",
        "\n",
        "La analogía es la relación semántica que tienen 2 palabras, por ejemplo, la palabra \"rey\" y \"reina\" están relacionadas por el concepto de \"género\". Estas analogías se pueden operacionalizar en el espacio vectorial de los word embeddings como la resta de los vectores asociados a las palabras.\n",
        "\n",
        "\n",
        "\n",
        "1.   Verifique cuáles son las palabras más cercanas a palabras que usted seleccione e interprete la correctitud de las palabras retornadas por los modelos `model` y `news`\n",
        "2.   Verifique cuál de los modelos resuelve mejor la prueba de analogía: \"man\" es a \"woman\" como \"king\" es a \"queen\". Invente otra analogía y pruebe si el modelo la puede resolver.\n",
        "3.   Según sus pruebas, ¿el tamaño del corpus de entrenamiento afecta el rendimiento del modelo?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fQ0w9XlNOHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2a0b58-1306-4a83-ba87-963e57f86b39"
      },
      "source": [
        "# así obtenemos las palabras más cercanas a las palabra \"woman\"\n",
        "model.wv.most_similar(\"woman\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-23 16:15:37,444 : INFO : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girl', 0.9568572044372559),\n",
              " ('boy', 0.8985123038291931),\n",
              " ('man', 0.8760168552398682),\n",
              " ('young', 0.8714863657951355),\n",
              " ('child', 0.8698967695236206),\n",
              " ('fellow', 0.8571248054504395),\n",
              " ('artist', 0.8556867837905884),\n",
              " ('old', 0.8551547527313232),\n",
              " ('youngster', 0.8550481796264648),\n",
              " ('distaste', 0.8539769649505615)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ov7uKOqrGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c30173a-11d1-4cb2-ed7f-ce5b8e30f574"
      },
      "source": [
        "news.most_similar(\"woman\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-23 16:15:37,484 : INFO : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('man', 0.7664012908935547),\n",
              " ('girl', 0.7494640946388245),\n",
              " ('teenager', 0.631708562374115),\n",
              " ('lady', 0.6288785934448242),\n",
              " ('mother', 0.607630729675293),\n",
              " ('boy', 0.5975908041000366),\n",
              " ('Woman', 0.5770983695983887),\n",
              " ('she', 0.5641393661499023),\n",
              " ('person', 0.5470173358917236),\n",
              " ('victim', 0.545007586479187)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo0IZTdVe-Vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73a5177-01aa-4a9c-cc3f-89f2b1057ccd"
      },
      "source": [
        "result = news.vectors[news.vocab[\"woman\"].index] - news.vectors[news.vocab[\"man\"].index] + news.vectors[news.vocab[\"king\"].index]\n",
        "news.similar_by_vector(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.8449392318725586),\n",
              " ('queen', 0.7300517559051514),\n",
              " ('princess', 0.6156251430511475),\n",
              " ('prince', 0.5777117609977722),\n",
              " ('ruler', 0.5247419476509094),\n",
              " ('throne', 0.5208988785743713),\n",
              " ('monarchy', 0.5182886123657227),\n",
              " ('royal', 0.5117030143737793),\n",
              " ('kingdom', 0.47109082341194153),\n",
              " ('palace', 0.4703429341316223)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TCneiXUfBIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccce4aa-6b83-46a8-a9bb-33decba351d5"
      },
      "source": [
        "result = model.wv.vectors[model.wv.vocab[\"woman\"].index] - model.wv.vectors[model.wv.vocab[\"man\"].index] + model.wv.vectors[model.wv.vocab[\"king\"].index]\n",
        "model.wv.similar_by_vector(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('per', 0.6182138323783875),\n",
              " ('6,000', 0.5889700651168823),\n",
              " ('cent', 0.5775361061096191),\n",
              " ('centum', 0.5632692575454712),\n",
              " ('Phase', 0.5398131608963013),\n",
              " ('capita', 0.5388073325157166),\n",
              " ('Profile', 0.5330788493156433),\n",
              " ('atmospheres', 0.5255193710327148),\n",
              " ('Rhode', 0.5178581476211548),\n",
              " ('under', 0.5053075551986694)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj4Hv0fkPKXg"
      },
      "source": [
        "## Actividad 4: Reducción de dimensionalidad y visualización\n",
        "\n",
        "Nuestros vectores tienen más de 2 dimensiones, por lo que no es muy fácil interptretar su ubicación espacial. Utiliza un método de reducción de dimensionalidad que conozcas para reducir hacia 2 dimensiones nuestros vectores y visualiza el resultado.\n",
        "\n",
        "\n",
        "*   ¿Existen agrupaciones aparentes de palabras dentro del espacio? y si es así, ¿las palabras agrupadas, son similares?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JhwXqJJeXaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "a1fe323d-0bb7-477a-be74-3fbaedc4e658"
      },
      "source": [
        "import sklearn.decomposition\n",
        "news_matrix_2d = sklearn.decomposition.PCA(2).fit_transform(news.vectors[:100,:])\n",
        "import plotly.express as px\n",
        "px.scatter(x=news_matrix_2d[:,0],y=news_matrix_2d[:,1],text=list(news.vocab)[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"cdf49604-e13e-49c5-9cea-24fa42562c1a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"cdf49604-e13e-49c5-9cea-24fa42562c1a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'cdf49604-e13e-49c5-9cea-24fa42562c1a',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"</s>\", \"in\", \"for\", \"that\", \"is\", \"on\", \"##\", \"The\", \"with\", \"said\", \"was\", \"the\", \"at\", \"not\", \"as\", \"it\", \"be\", \"from\", \"by\", \"are\", \"I\", \"have\", \"he\", \"will\", \"has\", \"####\", \"his\", \"an\", \"this\", \"or\", \"their\", \"who\", \"they\", \"but\", \"$\", \"had\", \"year\", \"were\", \"we\", \"more\", \"###\", \"up\", \"been\", \"you\", \"its\", \"one\", \"about\", \"would\", \"which\", \"out\", \"can\", \"It\", \"all\", \"also\", \"two\", \"after\", \"first\", \"He\", \"do\", \"time\", \"than\", \"when\", \"We\", \"over\", \"last\", \"new\", \"other\", \"her\", \"people\", \"into\", \"In\", \"our\", \"there\", \"A\", \"she\", \"could\", \"just\", \"years\", \"some\", \"U.S.\", \"three\", \"million\", \"them\", \"what\", \"But\", \"so\", \"no\", \"like\", \"if\", \"only\", \"percent\", \"get\", \"did\", \"him\", \"game\", \"back\", \"because\", \"now\", \"#.#\", \"before\"], \"type\": \"scatter\", \"x\": [0.20471715927124023, 0.3271665871143341, 0.24327783286571503, -0.16857191920280457, -0.05791927129030228, 0.15421828627586365, 1.0095276832580566, 0.5676600933074951, 0.16907428205013275, -0.315415620803833, -0.0013769882498309016, 0.1743440479040146, 0.2776801586151123, -0.6823506355285645, 0.025378011167049408, -0.3575935661792755, -0.2101593166589737, 0.43896517157554626, 0.4870210289955139, -0.20580650866031647, -1.1214569807052612, -0.26662683486938477, -0.3865021765232086, -0.16358335316181183, 0.2420123815536499, 0.8991965651512146, -0.031943123787641525, 0.39391985535621643, -0.11053511500358582, -0.07167136669158936, -0.1237722709774971, 0.03256624937057495, -0.6313999891281128, -0.29304561018943787, 1.3566392660140991, -0.08749759942293167, 0.7070679068565369, 0.025877710431814194, -1.0063031911849976, 0.1853027492761612, 1.1205569505691528, 0.10266250371932983, 0.03519624471664429, -1.0752499103546143, 0.48618805408477783, 0.09753440320491791, -0.07480322569608688, -0.3871647119522095, 0.36691439151763916, -0.2059185802936554, -0.6352223753929138, -0.37278860807418823, -0.21502774953842163, 0.17334802448749542, 0.5016746520996094, 0.41021832823753357, 0.4231993556022644, -0.12071460485458374, -0.9662526845932007, -0.02020138129591942, 0.4904322028160095, -0.09488581120967865, -1.049663782119751, 0.39208561182022095, 0.46977823972702026, 0.25069254636764526, -0.06326069682836533, -0.20612108707427979, -0.3856203854084015, 0.09278564155101776, 0.6012858152389526, -0.5188712477684021, -0.6270574927330017, 0.6182809472084045, -0.4542599320411682, -0.40824851393699646, -0.2806560695171356, 0.48572438955307007, -0.23742057383060455, 0.5585944652557373, 0.663575291633606, 1.4803190231323242, -0.5117660760879517, -0.5638426542282104, -0.3525819778442383, -0.5429996848106384, -0.36381515860557556, -0.5156723856925964, -0.5541519522666931, 0.014401222579181194, 1.2804816961288452, -0.570402979850769, -0.7731971740722656, -0.44890445470809937, -0.14176766574382782, -0.17714209854602814, -0.3554481267929077, -0.06848444789648056, 1.467623233795166, 0.12795034050941467], \"xaxis\": \"x\", \"y\": [0.007347999140620232, 0.18101537227630615, 0.03302741050720215, 0.15485802292823792, -0.14541089534759521, 0.1448667198419571, -0.2626210153102875, 1.2921111583709717, 0.11301688849925995, 0.03091522306203842, 0.022124778479337692, 0.046648018062114716, 0.07837490737438202, -0.30377981066703796, 0.2223285287618637, 0.12504035234451294, -0.21329693496227264, 0.06175079569220543, 0.20832645893096924, -0.9697326421737671, 0.08738238364458084, -0.3408467173576355, 0.21375326812267303, -0.6025135517120361, 0.23424041271209717, 0.1090790331363678, 0.5178364515304565, 0.4377841055393219, 0.06045282259583473, -0.24339011311531067, -0.20505167543888092, 0.2834952771663666, -0.45124033093452454, 0.36672917008399963, -0.4785057604312897, -0.09690152108669281, -0.10920696705579758, -0.7496208548545837, -0.41236093640327454, -0.332032173871994, -0.4584651291370392, 0.05205125734210014, -0.2284586876630783, -0.3290258049964905, 0.3411645293235779, -0.09012942016124725, -0.1442447155714035, -0.3813922703266144, 0.5089507699012756, 0.05377098545432091, -0.7289607524871826, 1.473668098449707, -0.38973379135131836, -0.04603235796093941, -0.3620074391365051, 0.30133429169654846, 0.09548630565404892, 1.3049829006195068, -0.47664040327072144, -0.08731769025325775, -0.2704741060733795, 0.301104873418808, 0.7452206611633301, 0.07039059698581696, 0.14764510095119476, -0.08098136633634567, -0.44647443294525146, 0.5113691687583923, -0.2455453872680664, 0.2580867111682892, 1.098019003868103, -0.2556229531764984, -0.23273976147174835, 1.2763668298721313, 0.24143487215042114, -0.4366041421890259, -0.08480945974588394, 0.03190619498491287, -0.33972811698913574, -0.025193439796566963, -0.35821333527565, -0.6280500888824463, -0.1855827271938324, 0.03044389933347702, 1.2226725816726685, 0.05143874138593674, -0.2517581880092621, -0.2312522828578949, -0.11382722854614258, -0.12971653044223785, -0.8561189770698547, -0.2869358956813812, -0.2793680727481842, 0.3660588264465332, 0.031103411689400673, 0.07374374568462372, 0.25374919176101685, -0.18748724460601807, -0.5009666085243225, 0.19169971346855164], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cdf49604-e13e-49c5-9cea-24fa42562c1a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}