{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-embeddings-classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4RMNhy8dikVJ2HXr6nAdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillena/dcc-ia-nlp/blob/master/5-embeddings-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXbTvZny7WAp"
      },
      "source": [
        "# Embeddings y clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES50nm3X1GCP",
        "outputId": "f796c600-f741-43df-800a-91e84ad1f853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/fvillena/workshopEmbeddingsAndClassifiers/master/corpus.txt\n",
        "!wget https://raw.githubusercontent.com/fvillena/workshopEmbeddingsAndClassifiers/master/data.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-08 04:22:24--  https://raw.githubusercontent.com/fvillena/workshopEmbeddingsAndClassifiers/master/corpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7394290 (7.1M) [text/plain]\n",
            "Saving to: ‘corpus.txt’\n",
            "\n",
            "corpus.txt          100%[===================>]   7.05M  20.7MB/s    in 0.3s    \n",
            "\n",
            "2020-11-08 04:22:25 (20.7 MB/s) - ‘corpus.txt’ saved [7394290/7394290]\n",
            "\n",
            "--2020-11-08 04:22:25--  https://raw.githubusercontent.com/fvillena/workshopEmbeddingsAndClassifiers/master/data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2125438 (2.0M) [text/plain]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>]   2.03M  9.30MB/s    in 0.2s    \n",
            "\n",
            "2020-11-08 04:22:27 (9.30 MB/s) - ‘data.csv’ saved [2125438/2125438]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbAl0fBixMWP"
      },
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import re\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmsItPYb7cD3"
      },
      "source": [
        "Cargamos nuestro corpus que contiene muchos diagnósticos en texto libre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbPyqTW1DoZ"
      },
      "source": [
        "corpus = []\n",
        "with open(\"corpus.txt\", encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "    corpus.append(line.rstrip())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd7WWcql7iCa"
      },
      "source": [
        "Cargamos nuestro conjunto de datos que contiene diagnósticos, junto a las especialidades a los que fueron referidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e26UiOrb2VwN"
      },
      "source": [
        "data = pd.read_csv(\"data.csv\")\n",
        "data = data.sample(len(data),random_state=11)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp-NxJIn60Mf",
        "outputId": "f6e5e702-09e7-4ca9-d0de-76d4b8d7cb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnostic</th>\n",
              "      <th>specialty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13599</th>\n",
              "      <td>Consulta, no especificada</td>\n",
              "      <td>TRAUMATOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14183</th>\n",
              "      <td>Coxartrosis (artrosis de la cadera) , (artrosis)</td>\n",
              "      <td>TRAUMATOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6169</th>\n",
              "      <td>Consulta no Especificada</td>\n",
              "      <td>TRAUMATOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40788</th>\n",
              "      <td>Retinopatia de la prematuridad</td>\n",
              "      <td>OFTALMOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18139</th>\n",
              "      <td>Consulta no Especificada</td>\n",
              "      <td>TRAUMATOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32081</th>\n",
              "      <td>Gingivoestomatitis y faringoamigdalitis herpética</td>\n",
              "      <td>OFTALMOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7259</th>\n",
              "      <td>Luxacion de la rodilla</td>\n",
              "      <td>TRAUMATOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21584</th>\n",
              "      <td>Catarata senil, no especificada</td>\n",
              "      <td>OFTALMOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36543</th>\n",
              "      <td>Diabetes mellitus, no especificada</td>\n",
              "      <td>OFTALMOLOGIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10137</th>\n",
              "      <td>Trastorno de los discos intervertebrales, no e...</td>\n",
              "      <td>TRAUMATOLOGIA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42964 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              diagnostic      specialty\n",
              "13599                          Consulta, no especificada  TRAUMATOLOGIA\n",
              "14183   Coxartrosis (artrosis de la cadera) , (artrosis)  TRAUMATOLOGIA\n",
              "6169                            Consulta no Especificada  TRAUMATOLOGIA\n",
              "40788                     Retinopatia de la prematuridad   OFTALMOLOGIA\n",
              "18139                           Consulta no Especificada  TRAUMATOLOGIA\n",
              "...                                                  ...            ...\n",
              "32081  Gingivoestomatitis y faringoamigdalitis herpética   OFTALMOLOGIA\n",
              "7259                              Luxacion de la rodilla  TRAUMATOLOGIA\n",
              "21584                    Catarata senil, no especificada   OFTALMOLOGIA\n",
              "36543                 Diabetes mellitus, no especificada   OFTALMOLOGIA\n",
              "10137  Trastorno de los discos intervertebrales, no e...  TRAUMATOLOGIA\n",
              "\n",
              "[42964 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d6rAQn11e1n"
      },
      "source": [
        "def normalizer(text): #normalizes a given string to lowercase and changes all vowels to their base form\n",
        "    text = text.lower() #string lowering\n",
        "    text = re.sub(r'[^A-Za-zñáéíóú]', ' ', text) #replaces every punctuation with a space\n",
        "    text = re.sub('á', 'a', text) #replaces special vowels to their base forms\n",
        "    text = re.sub('é', 'e', text)\n",
        "    text = re.sub('í', 'i', text)\n",
        "    text = re.sub('ó', 'o', text)\n",
        "    text = re.sub('ú', 'u', text)\n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ-iCU451mwB"
      },
      "source": [
        "def preprocessor(text):\n",
        "  text = normalizer(text)\n",
        "  tokens = nltk.tokenize.casual_tokenize(text)\n",
        "  return tokens"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-7oBaZt76Zc"
      },
      "source": [
        "def vectorizer(text, model): #returns a vector representation from a list of words and a given model\n",
        "    vectors = []\n",
        "    for i in text:\n",
        "        try:\n",
        "            vectors.append(model.wv[i])\n",
        "        except:\n",
        "            pass\n",
        "    return(np.nan_to_num(np.mean(vectors,axis=0)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlehFoo_5Rt9"
      },
      "source": [
        "## Actividad 1: Cálculo de los embeddings\n",
        "\n",
        "Calcule un word embedding utilizando word2vec sobre `corpus`. Recuerde que debe preprocesar el texto antes de calcular los embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4HneQ8m65lB"
      },
      "source": [
        "# prográmame\n",
        "#\n",
        "#\n",
        "#"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBzLdp8w5wlF"
      },
      "source": [
        "## Actividad 2: Clasificación\n",
        "\n",
        "Construya para cada documento almacenado en `data.diagnostic` un vector de características utilizando los embeddings calculados anteriormente. Debe decidir cómo va a combinar los embeddings de cada una de las palabras del documento en un sólo vector que defina cada documento.\n",
        "\n",
        "Cuando ya tenga calculada su matriz de características entrene un modelo que predica la especialidad almacenada en `data.specialty` dutilizando algún algoritmo conocido por usted y calcule la exactitud del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Du684Pc69H_"
      },
      "source": [
        "# prográmame\n",
        "#\n",
        "#\n",
        "#"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXO0XShV6Tt6"
      },
      "source": [
        "## Actividad 3: Predictor de especialidad\n",
        "\n",
        "Construya una función que dado un diagnóstico, retorne la especialidad más adecuada para referir utilizando su modelo entrenado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz-R3Smm7C6O"
      },
      "source": [
        "def predict_specialty(diagnostic):\n",
        "  # prográmame\n",
        "  #\n",
        "  #\n",
        "  #\n",
        "  pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA_d9p825uyw"
      },
      "source": [
        "predict_specialty(\"fractura de cadera\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5IHGPXFDABI"
      },
      "source": [
        "## Actividad 4: ELMo embeddings\n",
        "\n",
        "En las siguientes líneas, descargamos un modelo de ELMo entrenado en español y transformamos nuestros documentos a embeddings utilizando el modelo anteriormente cargado.\n",
        "\n",
        "\n",
        "\n",
        "1.   ¿Cuántas dimensiones tiene el embedding de cada palabra?\n",
        "2.   Busque 2 diagnósticos distintos que tengan una palabra en común, ¿el vector asociado a la palabra en común, es el mismo en cada diagnóstico?\n",
        "3.   Calcule un vector único asociado a cada diagnóstico y entrene un modelo de clasificación que resuelva la misma tarea anterior y compare los resultados de ELMo y Word2Vec\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtdJkC2r94HZ",
        "outputId": "a3901678-8663-494c-e57e-b175a9e94dc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install elmoformanylangs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elmoformanylangs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/84/4d8dcfaaece62c420254c1d860d02d3f79f7ed15206a73171ac2bbc8e57e/elmoformanylangs-0.0.4.post2-py3-none-any.whl (42kB)\n",
            "\r\u001b[K     |███████▋                        | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from elmoformanylangs) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from elmoformanylangs) (2.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from elmoformanylangs) (1.7.0+cu101)\n",
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->elmoformanylangs) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->elmoformanylangs) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->elmoformanylangs) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->elmoformanylangs) (0.7)\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10174 sha256=b63840a6855afaa492434360b5a29a0b55f4bbc5d52a03be6a8ea1fd41652386\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides, elmoformanylangs\n",
            "Successfully installed elmoformanylangs-0.0.4.post2 overrides-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFdd1_wv9UAO",
        "outputId": "a19d786b-0d92-4166-cd23-5e5f362502ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://vectors.nlpl.eu/repository/11/145.zip\n",
        "!unzip 145.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-08 04:22:34--  http://vectors.nlpl.eu/repository/11/145.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 419687058 (400M) [application/zip]\n",
            "Saving to: ‘145.zip’\n",
            "\n",
            "145.zip             100%[===================>] 400.24M  9.58MB/s    in 54s     \n",
            "\n",
            "2020-11-08 04:23:31 (7.36 MB/s) - ‘145.zip’ saved [419687058/419687058]\n",
            "\n",
            "Archive:  145.zip\n",
            "  inflating: char.dic                \n",
            "  inflating: config.json             \n",
            "  inflating: encoder.pkl             \n",
            "  inflating: meta.json               \n",
            "  inflating: README                  \n",
            "  inflating: token_embedder.pkl      \n",
            "  inflating: word.dic                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB-DTQw07p45"
      },
      "source": [
        "import elmoformanylangs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjtBwQR0-XDs",
        "outputId": "1490a1fb-6683-4b3f-bd1c-6fe6164466b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "e = elmoformanylangs.Embedder('')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-08 04:23:39,144 WARNING: Could not find config.  Trying cnn_50_100_512_4096_sample.json\n",
            "2020-11-08 04:23:39,149 WARNING: Could not find config.  Trying /usr/local/lib/python3.6/dist-packages/elmoformanylangs/configs/cnn_50_100_512_4096_sample.json\n",
            "2020-11-08 04:23:39,242 INFO: char embedding size: 2637\n",
            "2020-11-08 04:23:40,229 INFO: word embedding size: 185214\n",
            "2020-11-08 04:23:46,650 INFO: Model(\n",
            "  (token_embedder): ConvTokenEmbedder(\n",
            "    (word_emb_layer): EmbeddingLayer(\n",
            "      (embedding): Embedding(185214, 100, padding_idx=3)\n",
            "    )\n",
            "    (char_emb_layer): EmbeddingLayer(\n",
            "      (embedding): Embedding(2637, 50, padding_idx=2634)\n",
            "    )\n",
            "    (convolutions): ModuleList(\n",
            "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
            "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
            "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
            "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
            "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
            "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
            "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
            "    )\n",
            "    (highways): Highway(\n",
            "      (_layers): ModuleList(\n",
            "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
            "  )\n",
            "  (encoder): ElmobiLm(\n",
            "    (forward_layer_0): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (backward_layer_0): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (forward_layer_1): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (backward_layer_1): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvZeBbvT-dJ3"
      },
      "source": [
        "sentences = list(map(preprocessor,data.diagnostic))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO01udeX_EQF",
        "outputId": "9f8e6ca3-6d12-4a67-cd74-5e5d48ea0bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "features_raw = e.sents2elmo(sentences[:1000])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-08 04:23:48,654 INFO: 16 batches, avg len: 6.8\n",
            "2020-11-08 04:24:46,764 INFO: Finished 1000 sentences.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqaHkkokAfTJ"
      },
      "source": [
        "# programe\n",
        "#\n",
        "#\n",
        "#"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "459TL1PNFonP"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}