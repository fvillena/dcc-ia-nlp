{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-sequences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillena/dcc-ia-nlp/blob/master/7-sequences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeTp8ojxcxSw"
      },
      "source": [
        "import nltk\n",
        "\n",
        "#Partes de este notebook (RNN) fueron adaptadas desde el curso \n",
        "#fast.ai NLP course, USF programa MS Data Science May-June 2019.\n",
        "#https://github.com/fastai/course-nlp\n",
        "\n",
        "#El ejemplo de LSTM para el problema de POST fue adaptado desde\n",
        "#https://www.kaggle.com/krishanudb/lstm-character-word-pos-tag-model-pytorch\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7DdzhFMc-DZ",
        "outputId": "a16da18b-a7d5-451e-b557-83ca85374781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download(\"cess_esp\")\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRuZHqGprlME"
      },
      "source": [
        "#esto es un parche pues las etiquetas de cess_esp son antiguas y su mapeo a las \n",
        "#etiquetas universales no funciona bien\n",
        "if nltk.corpus.cess_esp._tagset != \"es-cast3lb\":\n",
        "  nltk.corpus.cess_esp._tagset = \"es-cast3lb\"\n",
        "  nltk.tag.mapping._load_universal_map(\"es-cast3lb\")  # initialize; normally loaded on demand\n",
        "  mapdict = nltk.tag.mapping._MAPPINGS[\"es-cast3lb\"][\"universal\"] # shortcut to the map\n",
        "  alltags = set(t for w, t in nltk.corpus.cess_esp.tagged_words())\n",
        "  for tag in alltags:\n",
        "      if len(tag) <= 2:   # These are complete\n",
        "          continue\n",
        "      mapdict[tag] = mapdict[tag[:2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBwZAoiRqRfS"
      },
      "source": [
        "es_pos_data = nltk.corpus.cess_esp.tagged_sents(tagset='universal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUKcVT_op_P1",
        "outputId": "6dcd0e25-47da-4163-9f78-e788c53c18ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "es_pos_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('El', 'DET'), ('grupo', 'NOUN'), ('estatal', 'ADJ'), ('Electricité_de_France', 'NOUN'), ('-Fpa-', '.'), ('EDF', 'NOUN'), ('-Fpt-', '.'), ('anunció', 'VERB'), ('hoy', 'ADV'), (',', '.'), ('jueves', 'X'), (',', '.'), ('la', 'DET'), ('compra', 'NOUN'), ('del', 'ADP'), ('51_por_ciento', 'NUM'), ('de', 'ADP'), ('la', 'DET'), ('empresa', 'NOUN'), ('mexicana', 'ADJ'), ('Electricidad_Águila_de_Altamira', 'NOUN'), ('-Fpa-', '.'), ('EAA', 'NOUN'), ('-Fpt-', '.'), (',', '.'), ('creada', 'ADJ'), ('por', 'ADP'), ('el', 'DET'), ('japonés', 'ADJ'), ('Mitsubishi_Corporation', 'NOUN'), ('para', 'ADP'), ('poner_en_marcha', 'VERB'), ('una', 'DET'), ('central', 'NOUN'), ('de', 'ADP'), ('gas', 'NOUN'), ('de', 'ADP'), ('495', 'X'), ('megavatios', 'NOUN'), ('.', '.')], [('Una', 'DET'), ('portavoz', 'NOUN'), ('de', 'ADP'), ('EDF', 'NOUN'), ('explicó', 'VERB'), ('a', 'ADP'), ('EFE', 'NOUN'), ('que', 'CONJ'), ('el', 'DET'), ('proyecto', 'NOUN'), ('para', 'ADP'), ('la', 'DET'), ('construcción', 'NOUN'), ('de', 'ADP'), ('Altamira_2', 'NOUN'), (',', '.'), ('al', 'ADP'), ('norte', 'NOUN'), ('de', 'ADP'), ('Tampico', 'NOUN'), (',', '.'), ('prevé', 'VERB'), ('la', 'DET'), ('utilización', 'NOUN'), ('de', 'ADP'), ('gas', 'NOUN'), ('natural', 'ADJ'), ('como', 'CONJ'), ('combustible', 'NOUN'), ('principal', 'ADJ'), ('en', 'ADP'), ('una', 'DET'), ('central', 'NOUN'), ('de', 'ADP'), ('ciclo', 'NOUN'), ('combinado', 'ADJ'), ('que', 'PRON'), ('debe', 'VERB'), ('empezar', 'VERB'), ('a', 'ADP'), ('funcionar', 'VERB'), ('en', 'ADP'), ('mayo_del_2002', 'X'), ('.', '.')], ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItSKFNbkdmgD"
      },
      "source": [
        "## Actividad 1: HMM\n",
        "\n",
        "Tipos de palabras:\n",
        "\n",
        "\n",
        "*   VERB - verbos\n",
        "*   NOUN - sustantivo\n",
        "*   PRON - pronombre \n",
        "*   ADJ - adjetivo\n",
        "*   ADV - adverbio\n",
        "*   ADP - preposición o posposición\n",
        "*   CONJ - conjunción\n",
        "*   DET - determinantes\n",
        "*   NUM - número\n",
        "*   PRT - partícula u otra palabra funcionale\n",
        "*   X - otro\n",
        "*   . - puntuación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVNasYqMdA8K"
      },
      "source": [
        "hmm_trainer = nltk.tag.hmm.HiddenMarkovModelTrainer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyg5OkmNdIBc"
      },
      "source": [
        "tagger = hmm_trainer.train_supervised(es_pos_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QhN4GHddPbL",
        "outputId": "772510cf-1a67-4ef0-b9d0-1b601aaedb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( tagger.tag(\"No coma ahora que entró en un coma inducido.\".split()) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('No', 'ADV'), ('coma', 'NOUN'), ('ahora', 'ADV'), ('que', 'PRON'), ('entró', 'VERB'), ('en', 'ADP'), ('un', 'DET'), ('coma', 'NOUN'), ('inducido.', 'DET')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAkMuG0t3Kh",
        "outputId": "39ef85d1-4036-499d-c3ee-814f16ea7d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( tagger.tag(\"El perro de Juan saltó muy alto.\".split()) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('El', 'DET'), ('perro', 'NOUN'), ('de', 'ADP'), ('Juan', 'NOUN'), ('saltó', 'VERB'), ('muy', 'ADV'), ('alto.', 'DET')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0F_Sn6Fd3SU"
      },
      "source": [
        "¿Cuáles son los símbolos de este modelo de HMM? ¿cuántos estados tiene? ¿qué  algoritmo se esta usando para crear el HMM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fF3g3sJduVx"
      },
      "source": [
        "# programe y responda\n",
        "#\n",
        "#\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDRjl-eWvdYB"
      },
      "source": [
        "# Redes neuronales\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK9lzKHQEfgR"
      },
      "source": [
        "import numpy\n",
        "from sklearn.datasets import make_blobs\n",
        "from fastai.text import *\n",
        "import fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoxIc_N9xSEI"
      },
      "source": [
        "## Ejemplo de uso de pytorch Modelo totalmente conectado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "619BY5Un90Ga",
        "outputId": "83b9dfbf-5c73-495e-b73b-7ba3953adffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## SOLUTION START\n",
        "class Feedforward(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(Feedforward, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "        def forward(self, x):\n",
        "            hidden = self.fc1(x)\n",
        "            relu = self.relu(hidden)\n",
        "            output = self.fc2(relu)\n",
        "            output = self.sigmoid(output)\n",
        "            return output\n",
        "# CREATE RANDOM DATA POINTS\n",
        "\n",
        "def blob_label(y, label, loc): # assign labels\n",
        "    target = numpy.copy(y)\n",
        "    for l in loc:\n",
        "        target[y == l] = label\n",
        "    return target\n",
        "\n",
        "x_train, y_train = make_blobs(n_samples=40, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 0, [0]))\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 1, [1,2,3]))\n",
        "\n",
        "x_test, y_test = make_blobs(n_samples=10, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 0, [0]))\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 1, [1,2,3]))\n",
        "\n",
        "model = Feedforward(2, 10)\n",
        "#ENTRENAMIENTO MANUAL\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "before_train = criterion(y_pred.squeeze(), y_test)\n",
        "print('Test loss before training' , before_train.item())\n",
        "model.train()\n",
        "epoch = 20\n",
        "for epoch in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "after_train = criterion(y_pred.squeeze(), y_test) \n",
        "print('Test loss after Training' , after_train.item())\n",
        "#SOLUTION END"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss before training 0.44255709648132324\n",
            "Epoch 0: train loss: 0.7305599451065063\n",
            "Epoch 1: train loss: 0.7124975323677063\n",
            "Epoch 2: train loss: 0.6969451904296875\n",
            "Epoch 3: train loss: 0.6835895776748657\n",
            "Epoch 4: train loss: 0.6721459627151489\n",
            "Epoch 5: train loss: 0.6623579859733582\n",
            "Epoch 6: train loss: 0.6539974808692932\n",
            "Epoch 7: train loss: 0.6468626856803894\n",
            "Epoch 8: train loss: 0.6407763361930847\n",
            "Epoch 9: train loss: 0.6355843544006348\n",
            "Epoch 10: train loss: 0.6311529874801636\n",
            "Epoch 11: train loss: 0.6273666620254517\n",
            "Epoch 12: train loss: 0.6241262555122375\n",
            "Epoch 13: train loss: 0.6213471293449402\n",
            "Epoch 14: train loss: 0.6189568638801575\n",
            "Epoch 15: train loss: 0.6168938875198364\n",
            "Epoch 16: train loss: 0.6151062250137329\n",
            "Epoch 17: train loss: 0.6135494709014893\n",
            "Epoch 18: train loss: 0.6121864318847656\n",
            "Epoch 19: train loss: 0.6109856367111206\n",
            "Test loss after Training 0.42662397027015686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igFH7vh2zqPF"
      },
      "source": [
        "## Redes recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULQngqHWpSP4"
      },
      "source": [
        "### Cargando datos para pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3qrFckTZMma",
        "outputId": "fd414b0b-b535-4d14-f78b-c3af9054116c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# from fastai.text import *\n",
        "# import fastai\n",
        "\n",
        "#fastai.torch_core.defaults.device = torch.device('cuda',0)\n",
        "fastai.torch_core.defaults.device = torch.device('cpu')\n",
        "defaults.device\n",
        "\n",
        "bs=64\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "def readnums(d): return [', '.join(o.strip() for o in open(path/d).readlines())]\n",
        "train_txt = readnums('train.txt'); train_txt[0][:80]\n",
        "valid_txt = readnums('valid.txt'); valid_txt[0][-80:]\n",
        "train = TextList(train_txt, path=path)\n",
        "valid = TextList(valid_txt, path=path)\n",
        "src = ItemLists(path=path, train=train, valid=valid).label_for_lm()\n",
        "data = src.databunch(bs=bs, bptt=3)\n",
        "v = data.valid_ds.vocab\n",
        "\n",
        "#miremos los datos\n",
        "print(valid_txt[0][:80])\n",
        "\n",
        "#numero de tokens en total\n",
        "print(len(data.train_ds[0][0].data))\n",
        "\n",
        "\n",
        "print(v.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "eight thousand one, eight thousand two, eight thousand three, eight thousand fou\n",
            "50079\n",
            "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', ',', 'hundred', 'thousand', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'xxfake']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1nABGVBipGZ",
        "outputId": "94f86db1-9da3-449a-df5d-ae4c9917dd0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#revisemos las dimensiones\n",
        "print( data.bptt) #esto es una division para el entrenamiento de RNN\n",
        "print(len(data.train_dl))\n",
        "\n",
        "it = iter(data.train_dl)\n",
        "x1,y1 = next(it)\n",
        "x2,y2 = next(it)\n",
        "x3,y3 = next(it)\n",
        "it.close()\n",
        "\n",
        "print(x1.numel()+x2.numel()+x3.numel())\n",
        "\n",
        "print(x1.shape)\n",
        "\n",
        "x1, y1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "261\n",
            "576\n",
            "torch.Size([64, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[13,  9, 14],\n",
              "         [13, 10, 30],\n",
              "         [10, 26, 17],\n",
              "         [ 9, 16, 10],\n",
              "         [18, 10, 20],\n",
              "         [ 9, 19, 10],\n",
              "         [11, 23, 13],\n",
              "         [11, 12, 10],\n",
              "         [13, 10, 28],\n",
              "         [19,  9, 12],\n",
              "         [16, 10, 21],\n",
              "         [23, 13,  9],\n",
              "         [24, 19,  9],\n",
              "         [ 9, 12, 11],\n",
              "         [12, 11, 20],\n",
              "         [ 9, 13, 11],\n",
              "         [13, 11, 13],\n",
              "         [14, 10, 26],\n",
              "         [15, 10, 27],\n",
              "         [11, 17, 10],\n",
              "         [10, 21, 13],\n",
              "         [22, 19,  9],\n",
              "         [15,  9, 13],\n",
              "         [ 9, 14, 11],\n",
              "         [10, 37,  9],\n",
              "         [14, 11, 14],\n",
              "         [11, 15, 10],\n",
              "         [16, 10, 25],\n",
              "         [10, 27, 14],\n",
              "         [28, 20,  9],\n",
              "         [11, 20, 10],\n",
              "         [ 9, 15, 11],\n",
              "         [20,  9, 15],\n",
              "         [ 9, 15, 11],\n",
              "         [15, 11, 15],\n",
              "         [15, 11, 16],\n",
              "         [11, 17, 10],\n",
              "         [18, 10, 25],\n",
              "         [10, 26, 20],\n",
              "         [28, 16,  9],\n",
              "         [23, 14,  9],\n",
              "         [24, 20,  9],\n",
              "         [ 9, 16, 11],\n",
              "         [16, 11, 15],\n",
              "         [10, 20,  9],\n",
              "         [16, 11, 18],\n",
              "         [19, 10, 23],\n",
              "         [20, 10, 24],\n",
              "         [12, 10, 16],\n",
              "         [10, 21, 14],\n",
              "         [22, 20,  9],\n",
              "         [16,  9, 17],\n",
              "         [17, 11, 16],\n",
              "         [17, 11, 17],\n",
              "         [17, 11, 19],\n",
              "         [11, 20, 10],\n",
              "         [24, 16,  9],\n",
              "         [10, 27, 15],\n",
              "         [ 9, 18, 11],\n",
              "         [15, 10, 38],\n",
              "         [16,  9, 18],\n",
              "         [ 9, 18, 11],\n",
              "         [18, 11, 18],\n",
              "         [11, 19, 10]]), tensor([[ 9, 14,  9],\n",
              "         [10, 30,  9],\n",
              "         [26, 17,  9],\n",
              "         [16, 10, 23],\n",
              "         [10, 20,  9],\n",
              "         [19, 10, 26],\n",
              "         [23, 13,  9],\n",
              "         [12, 10, 26],\n",
              "         [10, 28, 12],\n",
              "         [ 9, 12, 11],\n",
              "         [10, 21, 17],\n",
              "         [13,  9, 12],\n",
              "         [19,  9, 12],\n",
              "         [12, 11, 19],\n",
              "         [11, 20, 10],\n",
              "         [13, 11, 12],\n",
              "         [11, 13, 10],\n",
              "         [10, 26, 12],\n",
              "         [10, 27, 18],\n",
              "         [17, 10, 15],\n",
              "         [21, 13,  9],\n",
              "         [19,  9, 13],\n",
              "         [ 9, 13, 11],\n",
              "         [14, 11, 12],\n",
              "         [37,  9, 14],\n",
              "         [11, 14, 10],\n",
              "         [15, 10, 24],\n",
              "         [10, 25, 18],\n",
              "         [27, 14,  9],\n",
              "         [20,  9, 14],\n",
              "         [20, 10, 37],\n",
              "         [15, 11, 23],\n",
              "         [ 9, 15, 11],\n",
              "         [15, 11, 13],\n",
              "         [11, 15, 10],\n",
              "         [11, 16, 10],\n",
              "         [17, 10, 23],\n",
              "         [10, 25, 14],\n",
              "         [26, 20,  9],\n",
              "         [16,  9, 15],\n",
              "         [14,  9, 16],\n",
              "         [20,  9, 16],\n",
              "         [16, 11, 14],\n",
              "         [11, 15, 10],\n",
              "         [20,  9, 16],\n",
              "         [11, 18, 10],\n",
              "         [10, 23, 14],\n",
              "         [10, 24, 20],\n",
              "         [10, 16,  9],\n",
              "         [21, 14,  9],\n",
              "         [20,  9, 17],\n",
              "         [ 9, 17, 11],\n",
              "         [11, 16, 10],\n",
              "         [11, 17, 10],\n",
              "         [11, 19, 10],\n",
              "         [20, 10, 21],\n",
              "         [16,  9, 18],\n",
              "         [27, 15,  9],\n",
              "         [18, 11, 14],\n",
              "         [10, 38,  9],\n",
              "         [ 9, 18, 11],\n",
              "         [18, 11, 17],\n",
              "         [11, 18, 10],\n",
              "         [19, 10, 27]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SztR6D7PkZKn",
        "outputId": "4176a2ff-5290-462d-9def-6b1d81a39818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#miremos algunos vectores\n",
        "print(x1[0])\n",
        "print(y1[0])\n",
        "print(v.textify(x1[0]))\n",
        "print(v.textify(y1[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([13,  9, 14])\n",
            "tensor([ 9, 14,  9])\n",
            "two , three\n",
            ", three ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mM8SwpE3gML",
        "outputId": "0a09f759-0af2-42b9-cfab-6078dae73afe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nh=64\n",
        "bs=64\n",
        "\n",
        "data = src.databunch(bs=bs, bptt=3)\n",
        "nv = len(v.itos)\n",
        "print(nv)\n",
        "\n",
        "\n",
        "x,y = data.one_batch()\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "torch.Size([64, 3])\n",
            "torch.Size([64, 3])\n",
            "tensor([[13,  9, 14],\n",
            "        [13, 10, 30],\n",
            "        [10, 26, 17],\n",
            "        [ 9, 16, 10],\n",
            "        [18, 10, 20],\n",
            "        [ 9, 19, 10],\n",
            "        [11, 23, 13],\n",
            "        [11, 12, 10],\n",
            "        [13, 10, 28],\n",
            "        [19,  9, 12],\n",
            "        [16, 10, 21],\n",
            "        [23, 13,  9],\n",
            "        [24, 19,  9],\n",
            "        [ 9, 12, 11],\n",
            "        [12, 11, 20],\n",
            "        [ 9, 13, 11],\n",
            "        [13, 11, 13],\n",
            "        [14, 10, 26],\n",
            "        [15, 10, 27],\n",
            "        [11, 17, 10],\n",
            "        [10, 21, 13],\n",
            "        [22, 19,  9],\n",
            "        [15,  9, 13],\n",
            "        [ 9, 14, 11],\n",
            "        [10, 37,  9],\n",
            "        [14, 11, 14],\n",
            "        [11, 15, 10],\n",
            "        [16, 10, 25],\n",
            "        [10, 27, 14],\n",
            "        [28, 20,  9],\n",
            "        [11, 20, 10],\n",
            "        [ 9, 15, 11],\n",
            "        [20,  9, 15],\n",
            "        [ 9, 15, 11],\n",
            "        [15, 11, 15],\n",
            "        [15, 11, 16],\n",
            "        [11, 17, 10],\n",
            "        [18, 10, 25],\n",
            "        [10, 26, 20],\n",
            "        [28, 16,  9],\n",
            "        [23, 14,  9],\n",
            "        [24, 20,  9],\n",
            "        [ 9, 16, 11],\n",
            "        [16, 11, 15],\n",
            "        [10, 20,  9],\n",
            "        [16, 11, 18],\n",
            "        [19, 10, 23],\n",
            "        [20, 10, 24],\n",
            "        [12, 10, 16],\n",
            "        [10, 21, 14],\n",
            "        [22, 20,  9],\n",
            "        [16,  9, 17],\n",
            "        [17, 11, 16],\n",
            "        [17, 11, 17],\n",
            "        [17, 11, 19],\n",
            "        [11, 20, 10],\n",
            "        [24, 16,  9],\n",
            "        [10, 27, 15],\n",
            "        [ 9, 18, 11],\n",
            "        [15, 10, 38],\n",
            "        [16,  9, 18],\n",
            "        [ 9, 18, 11],\n",
            "        [18, 11, 18],\n",
            "        [11, 19, 10]])\n",
            "tensor([[ 9, 14,  9],\n",
            "        [10, 30,  9],\n",
            "        [26, 17,  9],\n",
            "        [16, 10, 23],\n",
            "        [10, 20,  9],\n",
            "        [19, 10, 26],\n",
            "        [23, 13,  9],\n",
            "        [12, 10, 26],\n",
            "        [10, 28, 12],\n",
            "        [ 9, 12, 11],\n",
            "        [10, 21, 17],\n",
            "        [13,  9, 12],\n",
            "        [19,  9, 12],\n",
            "        [12, 11, 19],\n",
            "        [11, 20, 10],\n",
            "        [13, 11, 12],\n",
            "        [11, 13, 10],\n",
            "        [10, 26, 12],\n",
            "        [10, 27, 18],\n",
            "        [17, 10, 15],\n",
            "        [21, 13,  9],\n",
            "        [19,  9, 13],\n",
            "        [ 9, 13, 11],\n",
            "        [14, 11, 12],\n",
            "        [37,  9, 14],\n",
            "        [11, 14, 10],\n",
            "        [15, 10, 24],\n",
            "        [10, 25, 18],\n",
            "        [27, 14,  9],\n",
            "        [20,  9, 14],\n",
            "        [20, 10, 37],\n",
            "        [15, 11, 23],\n",
            "        [ 9, 15, 11],\n",
            "        [15, 11, 13],\n",
            "        [11, 15, 10],\n",
            "        [11, 16, 10],\n",
            "        [17, 10, 23],\n",
            "        [10, 25, 14],\n",
            "        [26, 20,  9],\n",
            "        [16,  9, 15],\n",
            "        [14,  9, 16],\n",
            "        [20,  9, 16],\n",
            "        [16, 11, 14],\n",
            "        [11, 15, 10],\n",
            "        [20,  9, 16],\n",
            "        [11, 18, 10],\n",
            "        [10, 23, 14],\n",
            "        [10, 24, 20],\n",
            "        [10, 16,  9],\n",
            "        [21, 14,  9],\n",
            "        [20,  9, 17],\n",
            "        [ 9, 17, 11],\n",
            "        [11, 16, 10],\n",
            "        [11, 17, 10],\n",
            "        [11, 19, 10],\n",
            "        [20, 10, 21],\n",
            "        [16,  9, 18],\n",
            "        [27, 15,  9],\n",
            "        [18, 11, 14],\n",
            "        [10, 38,  9],\n",
            "        [ 9, 18, 11],\n",
            "        [18, 11, 17],\n",
            "        [11, 18, 10],\n",
            "        [19, 10, 27]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqjYB6wIvNlm"
      },
      "source": [
        "## Un primer ejemplo (Model 0) con la red desenrollada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J21n66pOvhTp"
      },
      "source": [
        "Layer names:\n",
        "- `i_h`: input to hidden\n",
        "- `h_h`: hidden to hidden\n",
        "- `h_o`: hidden to output\n",
        "- `bn`: batchnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEyMI893vuhq"
      },
      "source": [
        "Como primer ejemplo se usara ultima palabra como salida. Esto requiere redefinir las funciones error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNuDt5uvoes"
      },
      "source": [
        "def loss4(input,target): \n",
        "  return F.cross_entropy(input, target[:,-1])\n",
        "def acc4 (input,target):\n",
        "  #print('-------')\n",
        "  #print(input.shape)\n",
        "  #print(target.shape)\n",
        "\n",
        "  #print(input)\n",
        "  #print(target[:,-1])\n",
        "  #print(accuracy(input, target[:,-1]))\n",
        "  \n",
        "  return accuracy(input, target[:,-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD0e2HRJvMtW"
      },
      "source": [
        "class Model0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(x.shape[0])#  -> 64\n",
        "        #print(x.shape[1])#  -> 3 \n",
        "        h = self.bn(F.relu(self.i_h(x[:,0])))\n",
        "        if x.shape[1]>1:\n",
        "            h = h + self.i_h(x[:,1])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        if x.shape[1]>2:\n",
        "            h = h + self.i_h(x[:,2])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "\n",
        "        #print(h)\n",
        "        return self.h_o(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QUzOvXwwFcF",
        "outputId": "002c3ed2-cdda-49db-8944-389b051f6ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "learn = Learner(data, Model0(), loss_func=loss4, metrics=acc4)\n",
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc4</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.679572</td>\n",
              "      <td>3.562212</td>\n",
              "      <td>0.076057</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.816533</td>\n",
              "      <td>2.832781</td>\n",
              "      <td>0.430147</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.137094</td>\n",
              "      <td>2.355204</td>\n",
              "      <td>0.457261</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.889885</td>\n",
              "      <td>2.186115</td>\n",
              "      <td>0.460938</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.808680</td>\n",
              "      <td>2.135613</td>\n",
              "      <td>0.461857</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.792184</td>\n",
              "      <td>2.128844</td>\n",
              "      <td>0.462546</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZnY4oHayapO"
      },
      "source": [
        "## Un segundo ejemplo (Model 1) con la red desenrollada pero usando un ciclo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBV4gTJ0ycar",
        "outputId": "a8c287a2-32e6-4280-c079-5ad3f12b9930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        return self.h_o(h)\n",
        "\n",
        "\n",
        "learn = Learner(data, Model1(), loss_func=loss4, metrics=acc4)\n",
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc4</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.511042</td>\n",
              "      <td>3.450875</td>\n",
              "      <td>0.119485</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.567659</td>\n",
              "      <td>2.525012</td>\n",
              "      <td>0.449449</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.053900</td>\n",
              "      <td>2.137320</td>\n",
              "      <td>0.460708</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.860536</td>\n",
              "      <td>2.011841</td>\n",
              "      <td>0.465533</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.791066</td>\n",
              "      <td>1.974570</td>\n",
              "      <td>0.467831</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.776352</td>\n",
              "      <td>1.969590</td>\n",
              "      <td>0.467831</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kO9zt-3yFJg"
      },
      "source": [
        "## Un tercer ejemplo (Model 2) pero ahora no solo predecir la ultima palabra sino predecir con la 1 la palabra 2, y con 1 y la 2 la tercera, para utilizar mejor los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df6FVZqJzb0G",
        "outputId": "d2722be4-5633-43da-b598-cee7ef49f0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = src.databunch(bs=bs, bptt=20)\n",
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 20]), torch.Size([64, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbR8W9YPzhOv"
      },
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        res = []\n",
        "        #print(x.shape[0])  -> 64\n",
        "        #print(x.shape[1])  -> 20\n",
        "         \n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.h_o(self.bn(h)))\n",
        "            \n",
        "        return torch.stack(res, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfiOW3UwziKH",
        "outputId": "1387b4fc-7fe1-416d-d15c-ba99a2fd9045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "learn = Learner(data, Model2(), metrics=accuracy)\n",
        "learn.fit_one_cycle(10, 1e-4, pct_start=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.781072</td>\n",
              "      <td>3.838687</td>\n",
              "      <td>0.041335</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.609435</td>\n",
              "      <td>3.662476</td>\n",
              "      <td>0.096449</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.403097</td>\n",
              "      <td>3.490098</td>\n",
              "      <td>0.182955</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.196812</td>\n",
              "      <td>3.337445</td>\n",
              "      <td>0.215128</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.012440</td>\n",
              "      <td>3.212076</td>\n",
              "      <td>0.228480</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.862563</td>\n",
              "      <td>3.119693</td>\n",
              "      <td>0.254901</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.750993</td>\n",
              "      <td>3.061484</td>\n",
              "      <td>0.265980</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.675124</td>\n",
              "      <td>3.029965</td>\n",
              "      <td>0.269460</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.629149</td>\n",
              "      <td>3.017810</td>\n",
              "      <td>0.271236</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.605283</td>\n",
              "      <td>3.015990</td>\n",
              "      <td>0.271591</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lc21xye0Pnm"
      },
      "source": [
        "Notar que el rendimiento bajo! (hay menos historia para predecir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqCQMa5X0p6L"
      },
      "source": [
        "## Un cuarto ejemplo (Model 3), mejora levemente el rendimiento, ¿a qué se debe la diferencia?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHibgIdTz4yJ"
      },
      "source": [
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        self.h = torch.zeros(bs, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        #si quieren probar en GPU!\n",
        "        #h = self.h.to('cuda')\n",
        "        h = self.h\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.bn(h))\n",
        "        self.h = h.detach()\n",
        "        \n",
        "        res = torch.stack(res, dim=1)\n",
        "        res = self.h_o(res)\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb_6SN1xz6MY",
        "outputId": "81ac322a-1a3f-4ad5-b2c4-6e389d78f4ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "model3=Model3()\n",
        "#model3.cuda()\n",
        "model3.cpu()\n",
        "#al construir un \"DataBunch\" puedo entrenar directamente\n",
        "learn = Learner(data, model3, metrics=accuracy)\n",
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.556118</td>\n",
              "      <td>3.389250</td>\n",
              "      <td>0.155895</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.976181</td>\n",
              "      <td>2.428564</td>\n",
              "      <td>0.465909</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.250184</td>\n",
              "      <td>2.067140</td>\n",
              "      <td>0.323935</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.832530</td>\n",
              "      <td>2.164774</td>\n",
              "      <td>0.317685</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.627697</td>\n",
              "      <td>2.164879</td>\n",
              "      <td>0.320099</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.502320</td>\n",
              "      <td>2.015752</td>\n",
              "      <td>0.380753</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.368947</td>\n",
              "      <td>2.296233</td>\n",
              "      <td>0.363565</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.223000</td>\n",
              "      <td>2.309651</td>\n",
              "      <td>0.371733</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.099419</td>\n",
              "      <td>2.213777</td>\n",
              "      <td>0.379616</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.999777</td>\n",
              "      <td>2.084872</td>\n",
              "      <td>0.403196</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.912096</td>\n",
              "      <td>2.143486</td>\n",
              "      <td>0.409659</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.842912</td>\n",
              "      <td>2.142489</td>\n",
              "      <td>0.409304</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.785491</td>\n",
              "      <td>2.136141</td>\n",
              "      <td>0.429830</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.732986</td>\n",
              "      <td>2.159795</td>\n",
              "      <td>0.430824</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.692618</td>\n",
              "      <td>2.304249</td>\n",
              "      <td>0.429688</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.659637</td>\n",
              "      <td>2.330964</td>\n",
              "      <td>0.430043</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.633440</td>\n",
              "      <td>2.353627</td>\n",
              "      <td>0.430256</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.616311</td>\n",
              "      <td>2.346013</td>\n",
              "      <td>0.433878</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.604862</td>\n",
              "      <td>2.387492</td>\n",
              "      <td>0.432741</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.597595</td>\n",
              "      <td>2.391332</td>\n",
              "      <td>0.431960</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BeNQzXq1rgs"
      },
      "source": [
        "Ahora usamos directamente una RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUbWkqF_xtce"
      },
      "source": [
        "class Model4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.RNN(nh,nh, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1, bs, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpkfu0FbzvvC",
        "outputId": "d0b4b669-06ca-4e15-9391-8b7528d0cc8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "learn = Learner(data, Model4(), metrics=accuracy)\n",
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.439745</td>\n",
              "      <td>3.130227</td>\n",
              "      <td>0.356463</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.754354</td>\n",
              "      <td>2.151671</td>\n",
              "      <td>0.464844</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.119184</td>\n",
              "      <td>2.002382</td>\n",
              "      <td>0.394318</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.769323</td>\n",
              "      <td>2.036179</td>\n",
              "      <td>0.315696</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.575828</td>\n",
              "      <td>1.921741</td>\n",
              "      <td>0.443537</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.439355</td>\n",
              "      <td>1.907566</td>\n",
              "      <td>0.490980</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.273818</td>\n",
              "      <td>1.829573</td>\n",
              "      <td>0.511364</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.102830</td>\n",
              "      <td>1.729319</td>\n",
              "      <td>0.521520</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.942475</td>\n",
              "      <td>1.599891</td>\n",
              "      <td>0.538992</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.795896</td>\n",
              "      <td>1.414066</td>\n",
              "      <td>0.576278</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.672975</td>\n",
              "      <td>1.342687</td>\n",
              "      <td>0.593111</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.574366</td>\n",
              "      <td>1.329513</td>\n",
              "      <td>0.608381</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.497639</td>\n",
              "      <td>1.299045</td>\n",
              "      <td>0.631534</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.439153</td>\n",
              "      <td>1.281895</td>\n",
              "      <td>0.644318</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.395244</td>\n",
              "      <td>1.290387</td>\n",
              "      <td>0.637358</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.360791</td>\n",
              "      <td>1.264841</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.333755</td>\n",
              "      <td>1.281741</td>\n",
              "      <td>0.654616</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.315113</td>\n",
              "      <td>1.267189</td>\n",
              "      <td>0.656676</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.303198</td>\n",
              "      <td>1.283405</td>\n",
              "      <td>0.655611</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.296205</td>\n",
              "      <td>1.294677</td>\n",
              "      <td>0.654048</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz31SS-u1zsw"
      },
      "source": [
        "Ahora un modulo GRU en como RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfXfC62D0Jq5"
      },
      "source": [
        "class Model5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, bs, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjvrV9S50MIr",
        "outputId": "feaa4a29-4aac-4c5c-d6d3-ab8fd9bd525f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "learn = Learner(data, Model5(), metrics=accuracy)\n",
        "learn.fit_one_cycle(10, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.708057</td>\n",
              "      <td>2.210277</td>\n",
              "      <td>0.440341</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.596552</td>\n",
              "      <td>1.346402</td>\n",
              "      <td>0.647656</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.781611</td>\n",
              "      <td>0.921727</td>\n",
              "      <td>0.766477</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.379948</td>\n",
              "      <td>0.851926</td>\n",
              "      <td>0.813920</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.191776</td>\n",
              "      <td>0.883512</td>\n",
              "      <td>0.820383</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.102014</td>\n",
              "      <td>1.039995</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.057722</td>\n",
              "      <td>0.995301</td>\n",
              "      <td>0.795242</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.034585</td>\n",
              "      <td>1.142533</td>\n",
              "      <td>0.788920</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.022576</td>\n",
              "      <td>1.150154</td>\n",
              "      <td>0.793253</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.016299</td>\n",
              "      <td>1.150490</td>\n",
              "      <td>0.790838</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXIp1uBw7xSC"
      },
      "source": [
        "## POS tagger en español con LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ2JYIJ5HW6c"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
        "    Output: a tensor containing the indexes of the word\"\"\"\n",
        "    # idxs = [to_ix[w] for w in seq]\n",
        "    idxs = []\n",
        "    for w in seq:\n",
        "      if w in to_ix:\n",
        "        idxs.append(to_ix[w])\n",
        "      else:\n",
        "        idxs.append(to_ix[\"xxunk\"])\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV8_mpk7H8Pn"
      },
      "source": [
        "word_to_ix = {\"xxunk\":0}\n",
        "tag_to_ix = {}\n",
        "for sent in es_pos_data:\n",
        "  for token in sent:\n",
        "    word = token[0]\n",
        "    tag = token[1]\n",
        "    if word not in word_to_ix.keys():\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "    if tag not in tag_to_ix.keys():\n",
        "      tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4uiqfimI4Ka"
      },
      "source": [
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35E2F971I74H"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
        "        \n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqvK_faI_aP",
        "outputId": "96ad5465-60c4-4aa6-d4df-91d4ab137597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Here I initialize the model with all the necesarry parameters\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix.keys()), len(tag_to_ix.keys()))\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "# Define the loss function as the Negative Log Likelihood loss (NLLLoss)\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# We will be using a simple SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# The test sentence\n",
        "seq1 = \"No coma ahora que entró en un coma inducido .\".split()\n",
        "seq2 = \"El perro de Juan saltó muy alto .\".split()\n",
        "print(\"Running a check on the model before training.\\nSentences:\\n{}\\n{}\".format(\" \".join(seq1), \" \".join(seq2)))\n",
        "with torch.no_grad():\n",
        "    for seq in [seq1, seq2]:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs.to(device))\n",
        "        _, indices = torch.max(tag_scores, 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)\n",
        "    \n",
        "print(\"Training Started\")\n",
        "for epoch in range(10):\n",
        "    for sentence in es_pos_data[:10000]:\n",
        "        sentence_in = [token[0] for token in sentence]\n",
        "        tags = [token[1] for token in sentence]\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        \n",
        "        tag_scores = model(sentence_in.to(device))\n",
        "        \n",
        "        loss = loss_function(tag_scores.to(device), targets.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"epoch finished\")\n",
        "print(\"Training Finished!!!\\nAgain testing on unknown data\")\n",
        "with torch.no_grad():\n",
        "    for seq in [seq1, seq2]:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs.to(device))\n",
        "        _, indices = torch.max(tag_scores.to(device), 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running a check on the model before training.\n",
            "Sentences:\n",
            "No coma ahora que entró en un coma inducido .\n",
            "El perro de Juan saltó muy alto .\n",
            "[('No', 'CONJ'), ('coma', 'ADJ'), ('ahora', 'CONJ'), ('que', 'ADJ'), ('entró', 'ADJ'), ('en', 'NUM'), ('un', 'ADJ'), ('coma', 'ADJ'), ('inducido', 'ADJ'), ('.', 'ADJ')]\n",
            "[('El', 'ADJ'), ('perro', 'VERB'), ('de', 'CONJ'), ('Juan', 'ADJ'), ('saltó', 'PRON'), ('muy', 'PRON'), ('alto', 'CONJ'), ('.', 'CONJ')]\n",
            "Training Started\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "Training Finished!!!\n",
            "Again testing on unknown data\n",
            "[('No', 'ADP'), ('coma', 'ADP'), ('ahora', 'DET'), ('que', 'DET'), ('entró', 'DET'), ('en', 'ADP'), ('un', 'DET'), ('coma', 'DET'), ('inducido', 'DET'), ('.', 'ADP')]\n",
            "[('El', 'ADP'), ('perro', 'ADP'), ('de', 'DET'), ('Juan', 'DET'), ('saltó', 'DET'), ('muy', 'ADP'), ('alto', 'DET'), ('.', 'ADP')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XFxGXFcPe4y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}