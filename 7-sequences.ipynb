{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7-sequences.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillena/dcc-ia-nlp/blob/master/7-sequences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeTp8ojxcxSw"
      },
      "source": [
        "import nltk\n",
        "\n",
        "#Partes de este notebook (RNN) fueron adaptadas desde el curso \n",
        "#fast.ai NLP course, USF programa MS Data Science May-June 2019.\n",
        "#https://github.com/fastai/course-nlp\n",
        "\n",
        "#El ejemplo de LSTM para el problema de POST fue adaptado desde\n",
        "#https://www.kaggle.com/krishanudb/lstm-character-word-pos-tag-model-pytorch\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7DdzhFMc-DZ",
        "outputId": "8fbd4247-56e4-4989-cfe4-5c281821e643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download(\"cess_esp\")\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRuZHqGprlME"
      },
      "source": [
        "#esto es un parche pues las etiquetas de cess_esp son antiguas y su mapeo a las \n",
        "#etiquetas universales no funciona bien\n",
        "if nltk.corpus.cess_esp._tagset != \"es-cast3lb\":\n",
        "  nltk.corpus.cess_esp._tagset = \"es-cast3lb\"\n",
        "  nltk.tag.mapping._load_universal_map(\"es-cast3lb\")  # initialize; normally loaded on demand\n",
        "  mapdict = nltk.tag.mapping._MAPPINGS[\"es-cast3lb\"][\"universal\"] # shortcut to the map\n",
        "  alltags = set(t for w, t in nltk.corpus.cess_esp.tagged_words())\n",
        "  for tag in alltags:\n",
        "      if len(tag) <= 2:   # These are complete\n",
        "          continue\n",
        "      mapdict[tag] = mapdict[tag[:2]]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBwZAoiRqRfS"
      },
      "source": [
        "es_pos_data = nltk.corpus.cess_esp.tagged_sents(tagset='universal')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUKcVT_op_P1",
        "outputId": "6cd181d5-1834-49c6-f5bd-d98929698367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "es_pos_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('El', 'DET'), ('grupo', 'NOUN'), ('estatal', 'ADJ'), ('Electricité_de_France', 'NOUN'), ('-Fpa-', '.'), ('EDF', 'NOUN'), ('-Fpt-', '.'), ('anunció', 'VERB'), ('hoy', 'ADV'), (',', '.'), ('jueves', 'X'), (',', '.'), ('la', 'DET'), ('compra', 'NOUN'), ('del', 'ADP'), ('51_por_ciento', 'NUM'), ('de', 'ADP'), ('la', 'DET'), ('empresa', 'NOUN'), ('mexicana', 'ADJ'), ('Electricidad_Águila_de_Altamira', 'NOUN'), ('-Fpa-', '.'), ('EAA', 'NOUN'), ('-Fpt-', '.'), (',', '.'), ('creada', 'ADJ'), ('por', 'ADP'), ('el', 'DET'), ('japonés', 'ADJ'), ('Mitsubishi_Corporation', 'NOUN'), ('para', 'ADP'), ('poner_en_marcha', 'VERB'), ('una', 'DET'), ('central', 'NOUN'), ('de', 'ADP'), ('gas', 'NOUN'), ('de', 'ADP'), ('495', 'X'), ('megavatios', 'NOUN'), ('.', '.')], [('Una', 'DET'), ('portavoz', 'NOUN'), ('de', 'ADP'), ('EDF', 'NOUN'), ('explicó', 'VERB'), ('a', 'ADP'), ('EFE', 'NOUN'), ('que', 'CONJ'), ('el', 'DET'), ('proyecto', 'NOUN'), ('para', 'ADP'), ('la', 'DET'), ('construcción', 'NOUN'), ('de', 'ADP'), ('Altamira_2', 'NOUN'), (',', '.'), ('al', 'ADP'), ('norte', 'NOUN'), ('de', 'ADP'), ('Tampico', 'NOUN'), (',', '.'), ('prevé', 'VERB'), ('la', 'DET'), ('utilización', 'NOUN'), ('de', 'ADP'), ('gas', 'NOUN'), ('natural', 'ADJ'), ('como', 'CONJ'), ('combustible', 'NOUN'), ('principal', 'ADJ'), ('en', 'ADP'), ('una', 'DET'), ('central', 'NOUN'), ('de', 'ADP'), ('ciclo', 'NOUN'), ('combinado', 'ADJ'), ('que', 'PRON'), ('debe', 'VERB'), ('empezar', 'VERB'), ('a', 'ADP'), ('funcionar', 'VERB'), ('en', 'ADP'), ('mayo_del_2002', 'X'), ('.', '.')], ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItSKFNbkdmgD"
      },
      "source": [
        "## Actividad 1: HMM\n",
        "\n",
        "Tipos de palabras:\n",
        "\n",
        "\n",
        "*   VERB - verbos\n",
        "*   NOUN - sustantivo\n",
        "*   PRON - pronombre \n",
        "*   ADJ - adjetivo\n",
        "*   ADV - adverbio\n",
        "*   ADP - preposición o posposición\n",
        "*   CONJ - conjunción\n",
        "*   DET - determinantes\n",
        "*   NUM - número\n",
        "*   PRT - partícula u otra palabra funcionale\n",
        "*   X - otro\n",
        "*   . - puntuación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVNasYqMdA8K"
      },
      "source": [
        "hmm_trainer = nltk.tag.hmm.HiddenMarkovModelTrainer()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyg5OkmNdIBc"
      },
      "source": [
        "tagger = hmm_trainer.train_supervised(es_pos_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QhN4GHddPbL",
        "outputId": "2f6e7a3c-db00-44d3-9c4a-31b7fa73ca5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( tagger.tag(\"No coma ahora que entró en un coma inducido.\".split()) )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('No', 'ADV'), ('coma', 'NOUN'), ('ahora', 'ADV'), ('que', 'PRON'), ('entró', 'VERB'), ('en', 'ADP'), ('un', 'DET'), ('coma', 'NOUN'), ('inducido.', 'DET')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAkMuG0t3Kh",
        "outputId": "5acc8e5d-0904-49f1-9f44-b04b23aaa559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( tagger.tag(\"El perro de Juan saltó muy alto.\".split()) )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('El', 'DET'), ('perro', 'NOUN'), ('de', 'ADP'), ('Juan', 'NOUN'), ('saltó', 'VERB'), ('muy', 'ADV'), ('alto.', 'DET')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0F_Sn6Fd3SU"
      },
      "source": [
        "¿Cuáles son los símbolos de este modelo de HMM? ¿cuántos estados tiene? ¿qué  algoritmo se esta usando para crear el HMM?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fF3g3sJduVx"
      },
      "source": [
        "# programe y responda\n",
        "#\n",
        "#\n",
        "#"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDRjl-eWvdYB"
      },
      "source": [
        "# Redes neuronales\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK9lzKHQEfgR"
      },
      "source": [
        "import numpy\n",
        "from sklearn.datasets import make_blobs\n",
        "from fastai.text import *\n",
        "import fastai"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoxIc_N9xSEI"
      },
      "source": [
        "## Ejemplo de uso de pytorch Modelo totalmente conectado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "619BY5Un90Ga",
        "outputId": "0b72f310-1349-4ce7-e9a3-e60651561ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## SOLUTION START\n",
        "class Feedforward(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(Feedforward, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "        def forward(self, x):\n",
        "            hidden = self.fc1(x)\n",
        "            relu = self.relu(hidden)\n",
        "            output = self.fc2(relu)\n",
        "            output = self.sigmoid(output)\n",
        "            return output\n",
        "# CREATE RANDOM DATA POINTS\n",
        "\n",
        "def blob_label(y, label, loc): # assign labels\n",
        "    target = numpy.copy(y)\n",
        "    for l in loc:\n",
        "        target[y == l] = label\n",
        "    return target\n",
        "\n",
        "x_train, y_train = make_blobs(n_samples=40, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 0, [0]))\n",
        "y_train = torch.FloatTensor(blob_label(y_train, 1, [1,2,3]))\n",
        "\n",
        "x_test, y_test = make_blobs(n_samples=10, n_features=2, cluster_std=1.5, shuffle=True)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 0, [0]))\n",
        "y_test = torch.FloatTensor(blob_label(y_test, 1, [1,2,3]))\n",
        "\n",
        "model = Feedforward(2, 10)\n",
        "#ENTRENAMIENTO MANUAL\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "before_train = criterion(y_pred.squeeze(), y_test)\n",
        "print('Test loss before training' , before_train.item())\n",
        "model.train()\n",
        "epoch = 20\n",
        "for epoch in range(epoch):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "model.eval()\n",
        "y_pred = model(x_test)\n",
        "after_train = criterion(y_pred.squeeze(), y_test) \n",
        "print('Test loss after Training' , after_train.item())\n",
        "#SOLUTION END"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss before training 0.548934817314148\n",
            "Epoch 0: train loss: 1.4528684616088867\n",
            "Epoch 1: train loss: 1.3408582210540771\n",
            "Epoch 2: train loss: 1.238927960395813\n",
            "Epoch 3: train loss: 1.1460256576538086\n",
            "Epoch 4: train loss: 1.0621776580810547\n",
            "Epoch 5: train loss: 0.9871422648429871\n",
            "Epoch 6: train loss: 0.9212775230407715\n",
            "Epoch 7: train loss: 0.8641490936279297\n",
            "Epoch 8: train loss: 0.8148291707038879\n",
            "Epoch 9: train loss: 0.7725816965103149\n",
            "Epoch 10: train loss: 0.736286997795105\n",
            "Epoch 11: train loss: 0.7051050662994385\n",
            "Epoch 12: train loss: 0.6783002018928528\n",
            "Epoch 13: train loss: 0.6552902460098267\n",
            "Epoch 14: train loss: 0.6354434490203857\n",
            "Epoch 15: train loss: 0.6181377172470093\n",
            "Epoch 16: train loss: 0.6029897928237915\n",
            "Epoch 17: train loss: 0.589668869972229\n",
            "Epoch 18: train loss: 0.5778886079788208\n",
            "Epoch 19: train loss: 0.5674172639846802\n",
            "Test loss after Training 1.0997685194015503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igFH7vh2zqPF"
      },
      "source": [
        "## Redes recurrentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULQngqHWpSP4"
      },
      "source": [
        "### Cargando datos para pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3qrFckTZMma",
        "outputId": "e824f5d6-d8ad-44af-92d4-a4bbc4b23e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# from fastai.text import *\n",
        "# import fastai\n",
        "\n",
        "#fastai.torch_core.defaults.device = torch.device('cuda',0)\n",
        "fastai.torch_core.defaults.device = torch.device('cpu')\n",
        "defaults.device\n",
        "\n",
        "bs=64\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "def readnums(d): return [', '.join(o.strip() for o in open(path/d).readlines())]\n",
        "train_txt = readnums('train.txt'); train_txt[0][:80]\n",
        "valid_txt = readnums('valid.txt'); valid_txt[0][-80:]\n",
        "train = TextList(train_txt, path=path)\n",
        "valid = TextList(valid_txt, path=path)\n",
        "src = ItemLists(path=path, train=train, valid=valid).label_for_lm()\n",
        "data = src.databunch(bs=bs, bptt=3)\n",
        "v = data.valid_ds.vocab\n",
        "\n",
        "#miremos los datos\n",
        "print(valid_txt[0][:80])\n",
        "\n",
        "#numero de tokens en total\n",
        "print(len(data.train_ds[0][0].data))\n",
        "\n",
        "\n",
        "print(v.itos)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "eight thousand one, eight thousand two, eight thousand three, eight thousand fou\n",
            "50079\n",
            "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxmaj', 'xxup', 'xxrep', 'xxwrep', ',', 'hundred', 'thousand', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'twenty', 'thirty', 'forty', 'fifty', 'sixty', 'seventy', 'eighty', 'ninety', 'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen', 'nineteen', 'xxfake']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1nABGVBipGZ",
        "outputId": "585f8834-c543-452d-e5b7-dea5de1cd4fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#revisemos las dimensiones\n",
        "print( data.bptt) #esto es una division para el entrenamiento de RNN\n",
        "print(len(data.train_dl))\n",
        "\n",
        "it = iter(data.train_dl)\n",
        "x1,y1 = next(it)\n",
        "x2,y2 = next(it)\n",
        "x3,y3 = next(it)\n",
        "it.close()\n",
        "\n",
        "print(x1.numel()+x2.numel()+x3.numel())\n",
        "\n",
        "print(x1.shape)\n",
        "\n",
        "x1, y1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "261\n",
            "576\n",
            "torch.Size([64, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[13,  9, 14],\n",
              "         [13, 10, 30],\n",
              "         [10, 26, 17],\n",
              "         [ 9, 16, 10],\n",
              "         [18, 10, 20],\n",
              "         [ 9, 19, 10],\n",
              "         [11, 23, 13],\n",
              "         [11, 12, 10],\n",
              "         [13, 10, 28],\n",
              "         [19,  9, 12],\n",
              "         [16, 10, 21],\n",
              "         [23, 13,  9],\n",
              "         [24, 19,  9],\n",
              "         [ 9, 12, 11],\n",
              "         [12, 11, 20],\n",
              "         [ 9, 13, 11],\n",
              "         [13, 11, 13],\n",
              "         [14, 10, 26],\n",
              "         [15, 10, 27],\n",
              "         [11, 17, 10],\n",
              "         [10, 21, 13],\n",
              "         [22, 19,  9],\n",
              "         [15,  9, 13],\n",
              "         [ 9, 14, 11],\n",
              "         [10, 37,  9],\n",
              "         [14, 11, 14],\n",
              "         [11, 15, 10],\n",
              "         [16, 10, 25],\n",
              "         [10, 27, 14],\n",
              "         [28, 20,  9],\n",
              "         [11, 20, 10],\n",
              "         [ 9, 15, 11],\n",
              "         [20,  9, 15],\n",
              "         [ 9, 15, 11],\n",
              "         [15, 11, 15],\n",
              "         [15, 11, 16],\n",
              "         [11, 17, 10],\n",
              "         [18, 10, 25],\n",
              "         [10, 26, 20],\n",
              "         [28, 16,  9],\n",
              "         [23, 14,  9],\n",
              "         [24, 20,  9],\n",
              "         [ 9, 16, 11],\n",
              "         [16, 11, 15],\n",
              "         [10, 20,  9],\n",
              "         [16, 11, 18],\n",
              "         [19, 10, 23],\n",
              "         [20, 10, 24],\n",
              "         [12, 10, 16],\n",
              "         [10, 21, 14],\n",
              "         [22, 20,  9],\n",
              "         [16,  9, 17],\n",
              "         [17, 11, 16],\n",
              "         [17, 11, 17],\n",
              "         [17, 11, 19],\n",
              "         [11, 20, 10],\n",
              "         [24, 16,  9],\n",
              "         [10, 27, 15],\n",
              "         [ 9, 18, 11],\n",
              "         [15, 10, 38],\n",
              "         [16,  9, 18],\n",
              "         [ 9, 18, 11],\n",
              "         [18, 11, 18],\n",
              "         [11, 19, 10]]), tensor([[ 9, 14,  9],\n",
              "         [10, 30,  9],\n",
              "         [26, 17,  9],\n",
              "         [16, 10, 23],\n",
              "         [10, 20,  9],\n",
              "         [19, 10, 26],\n",
              "         [23, 13,  9],\n",
              "         [12, 10, 26],\n",
              "         [10, 28, 12],\n",
              "         [ 9, 12, 11],\n",
              "         [10, 21, 17],\n",
              "         [13,  9, 12],\n",
              "         [19,  9, 12],\n",
              "         [12, 11, 19],\n",
              "         [11, 20, 10],\n",
              "         [13, 11, 12],\n",
              "         [11, 13, 10],\n",
              "         [10, 26, 12],\n",
              "         [10, 27, 18],\n",
              "         [17, 10, 15],\n",
              "         [21, 13,  9],\n",
              "         [19,  9, 13],\n",
              "         [ 9, 13, 11],\n",
              "         [14, 11, 12],\n",
              "         [37,  9, 14],\n",
              "         [11, 14, 10],\n",
              "         [15, 10, 24],\n",
              "         [10, 25, 18],\n",
              "         [27, 14,  9],\n",
              "         [20,  9, 14],\n",
              "         [20, 10, 37],\n",
              "         [15, 11, 23],\n",
              "         [ 9, 15, 11],\n",
              "         [15, 11, 13],\n",
              "         [11, 15, 10],\n",
              "         [11, 16, 10],\n",
              "         [17, 10, 23],\n",
              "         [10, 25, 14],\n",
              "         [26, 20,  9],\n",
              "         [16,  9, 15],\n",
              "         [14,  9, 16],\n",
              "         [20,  9, 16],\n",
              "         [16, 11, 14],\n",
              "         [11, 15, 10],\n",
              "         [20,  9, 16],\n",
              "         [11, 18, 10],\n",
              "         [10, 23, 14],\n",
              "         [10, 24, 20],\n",
              "         [10, 16,  9],\n",
              "         [21, 14,  9],\n",
              "         [20,  9, 17],\n",
              "         [ 9, 17, 11],\n",
              "         [11, 16, 10],\n",
              "         [11, 17, 10],\n",
              "         [11, 19, 10],\n",
              "         [20, 10, 21],\n",
              "         [16,  9, 18],\n",
              "         [27, 15,  9],\n",
              "         [18, 11, 14],\n",
              "         [10, 38,  9],\n",
              "         [ 9, 18, 11],\n",
              "         [18, 11, 17],\n",
              "         [11, 18, 10],\n",
              "         [19, 10, 27]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SztR6D7PkZKn",
        "outputId": "390311ee-3535-4407-ab8e-b3657c773943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#miremos algunos vectores\n",
        "print(x1[0])\n",
        "print(y1[0])\n",
        "print(v.textify(x1[0]))\n",
        "print(v.textify(y1[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([13,  9, 14])\n",
            "tensor([ 9, 14,  9])\n",
            "two , three\n",
            ", three ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mM8SwpE3gML",
        "outputId": "965df674-b891-44b3-f218-3335cf33c322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nh=128\n",
        "bs=64\n",
        "\n",
        "data = src.databunch(bs=bs, bptt=3)\n",
        "nv = len(v.itos)\n",
        "print(nv)\n",
        "\n",
        "\n",
        "x,y = data.one_batch()\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "torch.Size([64, 3])\n",
            "torch.Size([64, 3])\n",
            "tensor([[13,  9, 14],\n",
            "        [13, 10, 30],\n",
            "        [10, 26, 17],\n",
            "        [ 9, 16, 10],\n",
            "        [18, 10, 20],\n",
            "        [ 9, 19, 10],\n",
            "        [11, 23, 13],\n",
            "        [11, 12, 10],\n",
            "        [13, 10, 28],\n",
            "        [19,  9, 12],\n",
            "        [16, 10, 21],\n",
            "        [23, 13,  9],\n",
            "        [24, 19,  9],\n",
            "        [ 9, 12, 11],\n",
            "        [12, 11, 20],\n",
            "        [ 9, 13, 11],\n",
            "        [13, 11, 13],\n",
            "        [14, 10, 26],\n",
            "        [15, 10, 27],\n",
            "        [11, 17, 10],\n",
            "        [10, 21, 13],\n",
            "        [22, 19,  9],\n",
            "        [15,  9, 13],\n",
            "        [ 9, 14, 11],\n",
            "        [10, 37,  9],\n",
            "        [14, 11, 14],\n",
            "        [11, 15, 10],\n",
            "        [16, 10, 25],\n",
            "        [10, 27, 14],\n",
            "        [28, 20,  9],\n",
            "        [11, 20, 10],\n",
            "        [ 9, 15, 11],\n",
            "        [20,  9, 15],\n",
            "        [ 9, 15, 11],\n",
            "        [15, 11, 15],\n",
            "        [15, 11, 16],\n",
            "        [11, 17, 10],\n",
            "        [18, 10, 25],\n",
            "        [10, 26, 20],\n",
            "        [28, 16,  9],\n",
            "        [23, 14,  9],\n",
            "        [24, 20,  9],\n",
            "        [ 9, 16, 11],\n",
            "        [16, 11, 15],\n",
            "        [10, 20,  9],\n",
            "        [16, 11, 18],\n",
            "        [19, 10, 23],\n",
            "        [20, 10, 24],\n",
            "        [12, 10, 16],\n",
            "        [10, 21, 14],\n",
            "        [22, 20,  9],\n",
            "        [16,  9, 17],\n",
            "        [17, 11, 16],\n",
            "        [17, 11, 17],\n",
            "        [17, 11, 19],\n",
            "        [11, 20, 10],\n",
            "        [24, 16,  9],\n",
            "        [10, 27, 15],\n",
            "        [ 9, 18, 11],\n",
            "        [15, 10, 38],\n",
            "        [16,  9, 18],\n",
            "        [ 9, 18, 11],\n",
            "        [18, 11, 18],\n",
            "        [11, 19, 10]])\n",
            "tensor([[ 9, 14,  9],\n",
            "        [10, 30,  9],\n",
            "        [26, 17,  9],\n",
            "        [16, 10, 23],\n",
            "        [10, 20,  9],\n",
            "        [19, 10, 26],\n",
            "        [23, 13,  9],\n",
            "        [12, 10, 26],\n",
            "        [10, 28, 12],\n",
            "        [ 9, 12, 11],\n",
            "        [10, 21, 17],\n",
            "        [13,  9, 12],\n",
            "        [19,  9, 12],\n",
            "        [12, 11, 19],\n",
            "        [11, 20, 10],\n",
            "        [13, 11, 12],\n",
            "        [11, 13, 10],\n",
            "        [10, 26, 12],\n",
            "        [10, 27, 18],\n",
            "        [17, 10, 15],\n",
            "        [21, 13,  9],\n",
            "        [19,  9, 13],\n",
            "        [ 9, 13, 11],\n",
            "        [14, 11, 12],\n",
            "        [37,  9, 14],\n",
            "        [11, 14, 10],\n",
            "        [15, 10, 24],\n",
            "        [10, 25, 18],\n",
            "        [27, 14,  9],\n",
            "        [20,  9, 14],\n",
            "        [20, 10, 37],\n",
            "        [15, 11, 23],\n",
            "        [ 9, 15, 11],\n",
            "        [15, 11, 13],\n",
            "        [11, 15, 10],\n",
            "        [11, 16, 10],\n",
            "        [17, 10, 23],\n",
            "        [10, 25, 14],\n",
            "        [26, 20,  9],\n",
            "        [16,  9, 15],\n",
            "        [14,  9, 16],\n",
            "        [20,  9, 16],\n",
            "        [16, 11, 14],\n",
            "        [11, 15, 10],\n",
            "        [20,  9, 16],\n",
            "        [11, 18, 10],\n",
            "        [10, 23, 14],\n",
            "        [10, 24, 20],\n",
            "        [10, 16,  9],\n",
            "        [21, 14,  9],\n",
            "        [20,  9, 17],\n",
            "        [ 9, 17, 11],\n",
            "        [11, 16, 10],\n",
            "        [11, 17, 10],\n",
            "        [11, 19, 10],\n",
            "        [20, 10, 21],\n",
            "        [16,  9, 18],\n",
            "        [27, 15,  9],\n",
            "        [18, 11, 14],\n",
            "        [10, 38,  9],\n",
            "        [ 9, 18, 11],\n",
            "        [18, 11, 17],\n",
            "        [11, 18, 10],\n",
            "        [19, 10, 27]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqjYB6wIvNlm"
      },
      "source": [
        "## Un primer ejemplo (Model 0) con la red desenrollada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J21n66pOvhTp"
      },
      "source": [
        "Layer names:\n",
        "- `i_h`: input to hidden\n",
        "- `h_h`: hidden to hidden\n",
        "- `h_o`: hidden to output\n",
        "- `bn`: batchnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEyMI893vuhq"
      },
      "source": [
        "Como primer ejemplo se usara ultima palabra como salida. Esto requiere redefinir las funciones error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNuDt5uvoes"
      },
      "source": [
        "def loss4(input,target): \n",
        "  return F.cross_entropy(input, target[:,-1])\n",
        "def acc4 (input,target):\n",
        "  #print('-------')\n",
        "  #print(input.shape)\n",
        "  #print(target.shape)\n",
        "\n",
        "  #print(input)\n",
        "  #print(target[:,-1])\n",
        "  #print(accuracy(input, target[:,-1]))\n",
        "  \n",
        "  return accuracy(input, target[:,-1])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD0e2HRJvMtW"
      },
      "source": [
        "class Model0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        # print(self.i_h)\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(x.shape[0])#  -> 64\n",
        "        #print(x.shape[1])#  -> 3 \n",
        "        h = self.bn(F.relu(self.i_h(x[:,0])))\n",
        "        # print(self.i_h(x[0,0]))\n",
        "        if x.shape[1]>1:\n",
        "            h = h + self.i_h(x[:,1])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        if x.shape[1]>2:\n",
        "            h = h + self.i_h(x[:,2])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "\n",
        "        #print(h)\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QUzOvXwwFcF",
        "outputId": "c6ac74ef-4806-46b6-8b03-0f28fa8f1ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "learn = Learner(data, Model0(), loss_func=loss4, metrics=acc4)\n",
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc4</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.448277</td>\n",
              "      <td>3.304796</td>\n",
              "      <td>0.272289</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.168148</td>\n",
              "      <td>2.314901</td>\n",
              "      <td>0.457950</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.773204</td>\n",
              "      <td>2.142758</td>\n",
              "      <td>0.462776</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.640036</td>\n",
              "      <td>2.115074</td>\n",
              "      <td>0.439338</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.596043</td>\n",
              "      <td>2.112854</td>\n",
              "      <td>0.403952</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.585421</td>\n",
              "      <td>2.112112</td>\n",
              "      <td>0.381434</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZnY4oHayapO"
      },
      "source": [
        "## Un segundo ejemplo (Model 1) con la red desenrollada pero usando un ciclo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBV4gTJ0ycar",
        "outputId": "5dc4e54c-73f9-458b-e128-651b45018e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        return self.h_o(h)\n",
        "\n",
        "\n",
        "learn = Learner(data, Model1(), loss_func=loss4, metrics=acc4)\n",
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc4</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.240372</td>\n",
              "      <td>2.961158</td>\n",
              "      <td>0.350184</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.040589</td>\n",
              "      <td>2.022088</td>\n",
              "      <td>0.465074</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.692793</td>\n",
              "      <td>1.937435</td>\n",
              "      <td>0.470129</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.595796</td>\n",
              "      <td>1.946746</td>\n",
              "      <td>0.470129</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.564188</td>\n",
              "      <td>1.964083</td>\n",
              "      <td>0.456112</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.555647</td>\n",
              "      <td>1.969098</td>\n",
              "      <td>0.421645</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kO9zt-3yFJg"
      },
      "source": [
        "## Un tercer ejemplo (Model 2) pero ahora no solo predecir la ultima palabra sino predecir con la 1 la palabra 2, y con 1 y la 2 la tercera, para utilizar mejor los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df6FVZqJzb0G",
        "outputId": "e63b529d-9305-4f34-fc3b-78da418b8ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = src.databunch(bs=bs, bptt=20)\n",
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 20]), torch.Size([64, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbR8W9YPzhOv"
      },
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        res = []\n",
        "        #print(x.shape[0])  -> 64\n",
        "        #print(x.shape[1])  -> 20\n",
        "         \n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.h_o(self.bn(h)))\n",
        "            \n",
        "        return torch.stack(res, dim=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfiOW3UwziKH",
        "outputId": "eef1c1e0-92f5-4cf2-ee6c-117ef095fd50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learn = Learner(data, Model2(), metrics=accuracy)\n",
        "learn.fit_one_cycle(10, 1e-4, pct_start=0.1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.722263</td>\n",
              "      <td>3.591238</td>\n",
              "      <td>0.071307</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.288330</td>\n",
              "      <td>3.117161</td>\n",
              "      <td>0.326847</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.841301</td>\n",
              "      <td>2.749927</td>\n",
              "      <td>0.370028</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.491697</td>\n",
              "      <td>2.535566</td>\n",
              "      <td>0.378054</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.244365</td>\n",
              "      <td>2.423941</td>\n",
              "      <td>0.378125</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.080340</td>\n",
              "      <td>2.367393</td>\n",
              "      <td>0.378551</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.975847</td>\n",
              "      <td>2.338260</td>\n",
              "      <td>0.378196</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.912085</td>\n",
              "      <td>2.324105</td>\n",
              "      <td>0.377202</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.875854</td>\n",
              "      <td>2.318799</td>\n",
              "      <td>0.375852</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.857515</td>\n",
              "      <td>2.317976</td>\n",
              "      <td>0.375497</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lc21xye0Pnm"
      },
      "source": [
        "Notar que el rendimiento bajo! (hay menos historia para predecir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqCQMa5X0p6L"
      },
      "source": [
        "## Un cuarto ejemplo (Model 3), mejora levemente el rendimiento, ¿a qué se debe la diferencia?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHibgIdTz4yJ"
      },
      "source": [
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        self.h = torch.zeros(bs, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        #si quieren probar en GPU!\n",
        "        #h = self.h.to('cuda')\n",
        "        h = self.h\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.bn(h))\n",
        "        self.h = h.detach()\n",
        "        \n",
        "        res = torch.stack(res, dim=1)\n",
        "        res = self.h_o(res)\n",
        "        return res"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb_6SN1xz6MY",
        "outputId": "d817b634-394a-4ee5-8585-e8e79c3709e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "model3=Model3()\n",
        "#model3.cuda()\n",
        "model3.cpu()\n",
        "#al construir un \"DataBunch\" puedo entrenar directamente\n",
        "learn = Learner(data, model3, metrics=accuracy)\n",
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.267189</td>\n",
              "      <td>2.980827</td>\n",
              "      <td>0.377202</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.434107</td>\n",
              "      <td>2.093276</td>\n",
              "      <td>0.467827</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.897304</td>\n",
              "      <td>2.114945</td>\n",
              "      <td>0.318324</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.652300</td>\n",
              "      <td>2.095558</td>\n",
              "      <td>0.322301</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.472572</td>\n",
              "      <td>1.735155</td>\n",
              "      <td>0.482955</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.286363</td>\n",
              "      <td>1.735731</td>\n",
              "      <td>0.476918</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.110159</td>\n",
              "      <td>1.832378</td>\n",
              "      <td>0.483665</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.934052</td>\n",
              "      <td>1.739038</td>\n",
              "      <td>0.542543</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.758340</td>\n",
              "      <td>1.864345</td>\n",
              "      <td>0.569460</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.599632</td>\n",
              "      <td>1.874578</td>\n",
              "      <td>0.564560</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.471631</td>\n",
              "      <td>1.876061</td>\n",
              "      <td>0.556250</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.377854</td>\n",
              "      <td>2.016307</td>\n",
              "      <td>0.564773</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.310156</td>\n",
              "      <td>1.909492</td>\n",
              "      <td>0.600497</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.256936</td>\n",
              "      <td>1.754585</td>\n",
              "      <td>0.619460</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.216386</td>\n",
              "      <td>1.857711</td>\n",
              "      <td>0.609659</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.189934</td>\n",
              "      <td>1.753736</td>\n",
              "      <td>0.623722</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.170111</td>\n",
              "      <td>1.830483</td>\n",
              "      <td>0.610938</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.155529</td>\n",
              "      <td>1.839639</td>\n",
              "      <td>0.621236</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.145521</td>\n",
              "      <td>1.848777</td>\n",
              "      <td>0.614844</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.139567</td>\n",
              "      <td>1.859760</td>\n",
              "      <td>0.614276</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BeNQzXq1rgs"
      },
      "source": [
        "Ahora usamos directamente una RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUbWkqF_xtce"
      },
      "source": [
        "class Model4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.RNN(nh,nh, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1, bs, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpkfu0FbzvvC",
        "outputId": "c4c8dfd7-aff5-4049-85db-15f35f6f6235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "learn = Learner(data, Model4(), metrics=accuracy)\n",
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.959105</td>\n",
              "      <td>2.398506</td>\n",
              "      <td>0.448437</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.178473</td>\n",
              "      <td>2.043206</td>\n",
              "      <td>0.437642</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.778394</td>\n",
              "      <td>2.095220</td>\n",
              "      <td>0.316477</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.599555</td>\n",
              "      <td>2.170799</td>\n",
              "      <td>0.317614</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.465879</td>\n",
              "      <td>1.981068</td>\n",
              "      <td>0.419531</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.230591</td>\n",
              "      <td>1.638586</td>\n",
              "      <td>0.525142</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.006330</td>\n",
              "      <td>1.704296</td>\n",
              "      <td>0.544460</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.822992</td>\n",
              "      <td>1.689860</td>\n",
              "      <td>0.605611</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.641542</td>\n",
              "      <td>1.620978</td>\n",
              "      <td>0.628054</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.478571</td>\n",
              "      <td>1.615303</td>\n",
              "      <td>0.636790</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.354535</td>\n",
              "      <td>1.567575</td>\n",
              "      <td>0.637926</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.265754</td>\n",
              "      <td>1.625107</td>\n",
              "      <td>0.630469</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.203415</td>\n",
              "      <td>1.580512</td>\n",
              "      <td>0.639489</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.162174</td>\n",
              "      <td>1.509534</td>\n",
              "      <td>0.657386</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.135625</td>\n",
              "      <td>1.639641</td>\n",
              "      <td>0.635582</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.114763</td>\n",
              "      <td>1.652235</td>\n",
              "      <td>0.634872</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.099415</td>\n",
              "      <td>1.598835</td>\n",
              "      <td>0.643892</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.088982</td>\n",
              "      <td>1.629088</td>\n",
              "      <td>0.640128</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.082154</td>\n",
              "      <td>1.589293</td>\n",
              "      <td>0.651989</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.078161</td>\n",
              "      <td>1.611762</td>\n",
              "      <td>0.647159</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz31SS-u1zsw"
      },
      "source": [
        "Ahora un modulo GRU en como RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfXfC62D0Jq5"
      },
      "source": [
        "class Model5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, bs, nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjvrV9S50MIr",
        "outputId": "79d1af57-e177-478a-e4b3-f43b3cad232e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learn = Learner(data, Model5(), metrics=accuracy)\n",
        "learn.fit_one_cycle(10, 1e-2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.172716</td>\n",
              "      <td>1.891673</td>\n",
              "      <td>0.550426</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.017122</td>\n",
              "      <td>1.315725</td>\n",
              "      <td>0.720526</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.454283</td>\n",
              "      <td>1.054829</td>\n",
              "      <td>0.767614</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.217216</td>\n",
              "      <td>0.895278</td>\n",
              "      <td>0.829545</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.108535</td>\n",
              "      <td>0.928129</td>\n",
              "      <td>0.820810</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.055948</td>\n",
              "      <td>1.054307</td>\n",
              "      <td>0.827557</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.029524</td>\n",
              "      <td>1.016421</td>\n",
              "      <td>0.816477</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.016059</td>\n",
              "      <td>1.223510</td>\n",
              "      <td>0.811080</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.008786</td>\n",
              "      <td>1.166751</td>\n",
              "      <td>0.812287</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.004933</td>\n",
              "      <td>1.175553</td>\n",
              "      <td>0.812003</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXIp1uBw7xSC"
      },
      "source": [
        "## POS tagger en español con LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ2JYIJ5HW6c"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
        "    Output: a tensor containing the indexes of the word\"\"\"\n",
        "    # idxs = [to_ix[w] for w in seq]\n",
        "    idxs = []\n",
        "    for w in seq:\n",
        "      if w in to_ix:\n",
        "        idxs.append(to_ix[w])\n",
        "      else:\n",
        "        idxs.append(to_ix[\"xxunk\"])\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV8_mpk7H8Pn"
      },
      "source": [
        "word_to_ix = {\"xxunk\":0}\n",
        "tag_to_ix = {}\n",
        "for sent in es_pos_data:\n",
        "  for token in sent:\n",
        "    word = token[0]\n",
        "    tag = token[1]\n",
        "    if word not in word_to_ix.keys():\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "    if tag not in tag_to_ix.keys():\n",
        "      tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4uiqfimI4Ka"
      },
      "source": [
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 64"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35E2F971I74H"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
        "        \n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tqvK_faI_aP",
        "outputId": "16834b33-2f9b-4271-936e-7a02280ac1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Here I initialize the model with all the necesarry parameters\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix.keys()), len(tag_to_ix.keys()))\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "# Define the loss function as the Negative Log Likelihood loss (NLLLoss)\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# We will be using a simple SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# The test sentence\n",
        "seq1 = \"No coma ahora que entró en un coma inducido .\".split()\n",
        "seq2 = \"El perro de Juan saltó muy alto .\".split()\n",
        "print(\"Running a check on the model before training.\\nSentences:\\n{}\\n{}\".format(\" \".join(seq1), \" \".join(seq2)))\n",
        "with torch.no_grad():\n",
        "    for seq in [seq1, seq2]:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs.to(device))\n",
        "        _, indices = torch.max(tag_scores, 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)\n",
        "    \n",
        "print(\"Training Started\")\n",
        "for epoch in range(10):\n",
        "    for sentence in es_pos_data[:10000]:\n",
        "        sentence_in = [token[0] for token in sentence]\n",
        "        tags = [token[1] for token in sentence]\n",
        "        model.zero_grad()\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        \n",
        "        tag_scores = model(sentence_in.to(device))\n",
        "        \n",
        "        loss = loss_function(tag_scores.to(device), targets.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"epoch finished\")\n",
        "print(\"Training Finished!!!\\nAgain testing on unknown data\")\n",
        "with torch.no_grad():\n",
        "    for seq in [seq1, seq2]:\n",
        "        inputs = prepare_sequence(seq, word_to_ix)\n",
        "        tag_scores = model(inputs.to(device))\n",
        "        _, indices = torch.max(tag_scores.to(device), 1)\n",
        "        ret = []\n",
        "        for i in range(len(indices)):\n",
        "            for key, value in tag_to_ix.items():\n",
        "                if indices[i] == value:\n",
        "                    ret.append((seq[i], key))\n",
        "        print(ret)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running a check on the model before training.\n",
            "Sentences:\n",
            "No coma ahora que entró en un coma inducido .\n",
            "El perro de Juan saltó muy alto .\n",
            "[('No', 'X'), ('coma', 'NUM'), ('ahora', 'ADJ'), ('que', 'NUM'), ('entró', 'NUM'), ('en', 'NUM'), ('un', 'NUM'), ('coma', 'NUM'), ('inducido', 'NUM'), ('.', 'X')]\n",
            "[('El', 'VERB'), ('perro', 'VERB'), ('de', 'NUM'), ('Juan', 'NUM'), ('saltó', 'NUM'), ('muy', 'NUM'), ('alto', 'NUM'), ('.', 'X')]\n",
            "Training Started\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "epoch finished\n",
            "Training Finished!!!\n",
            "Again testing on unknown data\n",
            "[('No', 'DET'), ('coma', 'DET'), ('ahora', 'DET'), ('que', 'DET'), ('entró', 'ADP'), ('en', 'DET'), ('un', 'DET'), ('coma', 'DET'), ('inducido', 'DET'), ('.', 'DET')]\n",
            "[('El', 'DET'), ('perro', 'DET'), ('de', 'DET'), ('Juan', 'DET'), ('saltó', 'DET'), ('muy', 'DET'), ('alto', 'DET'), ('.', 'DET')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XFxGXFcPe4y"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}