{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E5GavpLngNm"
      },
      "source": [
        "# Laboratorio 2: Preprocesamiento y descripción de corpora.\n",
        "\n",
        "\n",
        "### Cuerpo Docente\n",
        "\n",
        "- Profesores: [Andrés Abeliuk](https://aabeliuk.github.io/), [Felipe Villena](https://fabianvillena.cl/).\n",
        "- Profesor Auxiliar: [Gabriel Iturra](https://giturra.cl/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fpsz2pQt8x5"
      },
      "source": [
        "## Preguntas ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB92kQXspvbR"
      },
      "source": [
        "Leer atentamente las instrucciones entregadas a continuación para facilitar el proceso de revisión de sus trabajos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosWgWgRxHKp"
      },
      "source": [
        "` `\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "\n",
        "\n",
        "- Escribe tu código entre las lineas de comentarios **### Aquí inicia tu código ###** y **### Aquí termina tu código ###**.\n",
        "- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecución coincida con el resultado esperado.\n",
        "- Recuerde siempre mantener buenas prácticas de código.\n",
        "- Está permitido sólo utilizar las librerías importadas antes del Ejercicio 1.\n",
        "- **Recordar** que: *Documento = Oración. Dataset = Corpus. Vocabulario = Tokens*.\n",
        "- El **orden de los resultados** pueden variar dependiendo de su máquina, pero los valores de los resultados son los mismos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrmFHXhqUww"
      },
      "source": [
        "**Ejemplo:** Implemente una función **`hello_world()`** que imprima en pantalla `\"Hello World\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu7cIsawyJHx"
      },
      "outputs": [],
      "source": [
        "def hello_world():\n",
        "  ### Aquí inicia tu código ###\n",
        "  print(\"Hello World\")\n",
        "  ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6klw12lwbW"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-WMk2dyQbp",
        "outputId": "9030f89c-ed23-4f5e-e317-9153250b150e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoiAMxtyUjQ"
      },
      "source": [
        "***Resultado esperado***:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td> Hello World </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "``\n",
        "``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPyrPXiH0l4"
      },
      "source": [
        "Estas son las librerías permitidas. Si quieren utilizar alguna librería adicional, pueden realizar la consulta a través de Discord."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtP6Emjo1kF0"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9Do0LdC9w2"
      },
      "source": [
        "En caso de desarrollar la tarea desde colab, utilizar el siguiente código para cargar los archivos desde el drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EXq1VDeC-ml",
        "outputId": "fab8dcac-3af9-49df-f273-99b0965f1b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'path/to/marcianeke.txt'\n",
        "except:\n",
        "    print('Ignorando conexión drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O puede subirlo a google colab usando este código, sin interactuar con Google Drive, pero debe resubir el archivo cada que vuelve a entrar a este google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "file = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN4bBoY2Td4"
      },
      "source": [
        "` `\n",
        "\n",
        "**Ejercicio 1 - normalizador**  \n",
        "` `  \n",
        "` `\n",
        "\n",
        "En el primer ejercicio veremos la dificultad 😨 de normamilzar textos no estructurados, destacando la importancia de tener librerías que realicen este trabajo.\n",
        "\n",
        "El archivo adjunto al enunciado de la tarea contiene la letra de una canción del marcianeke 👽. Utilice este texto para realizar su primera tokenización y ver qué tan bien funciona su función.\n",
        "\n",
        "Ejecute el código a continuación para cargar el ejemplo. Recuerde realizar la modificación al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNUYlWo21g4",
        "outputId": "d38b4731-e05b-4bd7-b7b3-0e99d251cd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brr\r\n",
            "Marcianeke\r\n",
            "Vamo' a estar con Pailita\r\n",
            "Dimelo má\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar (brr)\r\n",
            "Tussi, keta quiere' mezclar\r\n",
            "Dimelo má\r\n",
            "\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta pura quiere' mezclar\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "\r\n",
            "Esperame que ahora entro yo\r\n",
            "Y lo que pide yo lo traje\r\n",
            "No visto de traje\r\n",
            "Puro corte calle, no de maquillaje\r\n",
            "Pronto coronamos y nos vamo' de viaje\r\n",
            "Tanto hit que hago que lo' culo bajen\r\n",
            "Ella se va de shopping\r\n",
            "Sale positivo si se hace el doping\r\n",
            "Baila twerk con un poco de popping\r\n",
            "Los fardos en el botín\r\n",
            "\r\n",
            "Si quieren letra llamen pa' mi booking\r\n",
            "Generando, sigo en la mía lowkey\r\n",
            "Cooking en el estudio con tu woman\r\n",
            "Tanto whisky, pisco que hasta lo' vecinos toman\r\n",
            "Si se tiran pa' aca puede que la arena coman\r\n",
            "Ja, en el chanteo titulado sin diploma\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "Di-dimelo má\r\n",
            "\r\n",
            "Ah, pe-peligrosa\r\n",
            "Quiero ver como perreando me acosa\r\n",
            "Eso de atra' con el Gucci me lo roza\r\n",
            "Tengo tussi del naranjo me aburrio el rosa\r\n",
            "Capaz que tosa con el blunt\r\n",
            "Sprite con Flemibron\r\n",
            "Louis Vuitton, le quito la polera Champion\r\n",
            "A tu pretendiente con la fory lo espanto\r\n",
            "Puro perro, le doy de comer Champion Dog\r\n",
            "Ese toto lo corono yo\r\n",
            "La movie en play no hay stop\r\n",
            "Flow de sobra no hay stock\r\n",
            "Me la topo en la disco queda en shock\r\n",
            "My love, rica en las redes y en persona\r\n",
            "No usa Photoshop\r\n",
            "La llevo a comprar blone' al growshop\r\n",
            "En ropa interior los do'\r\n",
            "Me roza su vicky con mi boxer Top\r\n",
            "Dimelo má\r\n",
            "Ando en busca de una cri\r\n",
            "minal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta quiere' mezclar\r\n",
            "Dimelo má\r\n",
            "\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta pura quiere' mezclar\r\n",
            "Marcianeke, Pailita\r\n",
            "Young Varas\n"
          ]
        }
      ],
      "source": [
        "text = codecs.open('marcianeke.txt', 'r', 'UTF-8').read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vu4HZeukAHx"
      },
      "source": [
        "Implemente la funcion **```normalize()```**, que normalize una cadena de texto convirtiéndo todo a minúsculas, quitando los caracteres no alfabéticos y los tildes. Note que la función tiene una variable nombrada ```remove_tildes```, que determina si hay que eliminar los tildes o no, considere dicha opción en su implementación. Luego, aplique esta función a cada una de las línea de la canción de marcianke 👽.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2NeTI6lj_k5"
      },
      "outputs": [],
      "source": [
        "def normalize(text, remove_tildes = True):\n",
        "    \"\"\"Normaliza una cadena de texto convirtiéndo todo a minúsculas,\n",
        "    quitando los caracteres no alfabéticos y los tildes\"\"\"\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaOYzMk3v1X"
      },
      "source": [
        "Implementen una función **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librerías con tokenizadores ya implementados. Pueden utilizar la librería **re** importada para trabajar símbolos. Esta función debe aplicar en el texto normalizado de la pregunta anterior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dl42-hgIhqB"
      },
      "source": [
        "Ejemplo de uso:\n",
        "\n",
        "`get_tokens('Este es un ejemplo de prueba.')`\n",
        "\n",
        "Nos entregaría:\n",
        "\n",
        "`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF1RcIwq4G2x"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "  ### Inicio del código ###\n",
        "\n",
        "  ...\n",
        "\n",
        "  ### Fin del código ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqlSpefv4_EH"
      },
      "outputs": [],
      "source": [
        "tokens = get_tokens(text)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbgTvAW-stF"
      },
      "source": [
        "**Describa cuáles fueron sus supuestos para realizar la tokenización y compare sus tokens con los entregados por la librería nltk en el bloque de código de más abajo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQ7CJy3-3aH"
      },
      "source": [
        "Supuestos aqui\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtmAXTr9KXK",
        "outputId": "4981a15d-89bc-4972-f91a-f4afe42659a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Brr',\n",
              " 'Marcianeke',\n",
              " 'Vamo',\n",
              " \"'\",\n",
              " 'a',\n",
              " 'estar',\n",
              " 'con',\n",
              " 'Pailita',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " '(',\n",
              " 'brr',\n",
              " ')',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Esperame',\n",
              " 'que',\n",
              " 'ahora',\n",
              " 'entro',\n",
              " 'yo',\n",
              " 'Y',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'pide',\n",
              " 'yo',\n",
              " 'lo',\n",
              " 'traje',\n",
              " 'No',\n",
              " 'visto',\n",
              " 'de',\n",
              " 'traje',\n",
              " 'Puro',\n",
              " 'corte',\n",
              " 'calle',\n",
              " ',',\n",
              " 'no',\n",
              " 'de',\n",
              " 'maquillaje',\n",
              " 'Pronto',\n",
              " 'coronamos',\n",
              " 'y',\n",
              " 'nos',\n",
              " 'vamo',\n",
              " \"'\",\n",
              " 'de',\n",
              " 'viaje',\n",
              " 'Tanto',\n",
              " 'hit',\n",
              " 'que',\n",
              " 'hago',\n",
              " 'que',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'culo',\n",
              " 'bajen',\n",
              " 'Ella',\n",
              " 'se',\n",
              " 'va',\n",
              " 'de',\n",
              " 'shopping',\n",
              " 'Sale',\n",
              " 'positivo',\n",
              " 'si',\n",
              " 'se',\n",
              " 'hace',\n",
              " 'el',\n",
              " 'doping',\n",
              " 'Baila',\n",
              " 'twerk',\n",
              " 'con',\n",
              " 'un',\n",
              " 'poco',\n",
              " 'de',\n",
              " 'popping',\n",
              " 'Los',\n",
              " 'fardos',\n",
              " 'en',\n",
              " 'el',\n",
              " 'botín',\n",
              " 'Si',\n",
              " 'quieren',\n",
              " 'letra',\n",
              " 'llamen',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'mi',\n",
              " 'booking',\n",
              " 'Generando',\n",
              " ',',\n",
              " 'sigo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'mía',\n",
              " 'lowkey',\n",
              " 'Cooking',\n",
              " 'en',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'con',\n",
              " 'tu',\n",
              " 'woman',\n",
              " 'Tanto',\n",
              " 'whisky',\n",
              " ',',\n",
              " 'pisco',\n",
              " 'que',\n",
              " 'hasta',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'vecinos',\n",
              " 'toman',\n",
              " 'Si',\n",
              " 'se',\n",
              " 'tiran',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'aca',\n",
              " 'puede',\n",
              " 'que',\n",
              " 'la',\n",
              " 'arena',\n",
              " 'coman',\n",
              " 'Ja',\n",
              " ',',\n",
              " 'en',\n",
              " 'el',\n",
              " 'chanteo',\n",
              " 'titulado',\n",
              " 'sin',\n",
              " 'diploma',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'má',\n",
              " 'Ah',\n",
              " ',',\n",
              " 'pe',\n",
              " '-',\n",
              " 'peligrosa',\n",
              " 'Quiero',\n",
              " 'ver',\n",
              " 'como',\n",
              " 'perreando',\n",
              " 'me',\n",
              " 'acosa',\n",
              " 'Eso',\n",
              " 'de',\n",
              " 'atra',\n",
              " \"'\",\n",
              " 'con',\n",
              " 'el',\n",
              " 'Gucci',\n",
              " 'me',\n",
              " 'lo',\n",
              " 'roza',\n",
              " 'Tengo',\n",
              " 'tussi',\n",
              " 'del',\n",
              " 'naranjo',\n",
              " 'me',\n",
              " 'aburrio',\n",
              " 'el',\n",
              " 'rosa',\n",
              " 'Capaz',\n",
              " 'que',\n",
              " 'tosa',\n",
              " 'con',\n",
              " 'el',\n",
              " 'blunt',\n",
              " 'Sprite',\n",
              " 'con',\n",
              " 'Flemibron',\n",
              " 'Louis',\n",
              " 'Vuitton',\n",
              " ',',\n",
              " 'le',\n",
              " 'quito',\n",
              " 'la',\n",
              " 'polera',\n",
              " 'Champion',\n",
              " 'A',\n",
              " 'tu',\n",
              " 'pretendiente',\n",
              " 'con',\n",
              " 'la',\n",
              " 'fory',\n",
              " 'lo',\n",
              " 'espanto',\n",
              " 'Puro',\n",
              " 'perro',\n",
              " ',',\n",
              " 'le',\n",
              " 'doy',\n",
              " 'de',\n",
              " 'comer',\n",
              " 'Champion',\n",
              " 'Dog',\n",
              " 'Ese',\n",
              " 'toto',\n",
              " 'lo',\n",
              " 'corono',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'movie',\n",
              " 'en',\n",
              " 'play',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stop',\n",
              " 'Flow',\n",
              " 'de',\n",
              " 'sobra',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stock',\n",
              " 'Me',\n",
              " 'la',\n",
              " 'topo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'disco',\n",
              " 'queda',\n",
              " 'en',\n",
              " 'shock',\n",
              " 'My',\n",
              " 'love',\n",
              " ',',\n",
              " 'rica',\n",
              " 'en',\n",
              " 'las',\n",
              " 'redes',\n",
              " 'y',\n",
              " 'en',\n",
              " 'persona',\n",
              " 'No',\n",
              " 'usa',\n",
              " 'Photoshop',\n",
              " 'La',\n",
              " 'llevo',\n",
              " 'a',\n",
              " 'comprar',\n",
              " 'blone',\n",
              " \"'\",\n",
              " 'al',\n",
              " 'growshop',\n",
              " 'En',\n",
              " 'ropa',\n",
              " 'interior',\n",
              " 'los',\n",
              " 'do',\n",
              " \"'\",\n",
              " 'Me',\n",
              " 'roza',\n",
              " 'su',\n",
              " 'vicky',\n",
              " 'con',\n",
              " 'mi',\n",
              " 'boxer',\n",
              " 'Top',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'cri',\n",
              " 'minal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'má',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Marcianeke',\n",
              " ',',\n",
              " 'Pailita',\n",
              " 'Young',\n",
              " 'Varas']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(text)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5QKlXAZwN1L"
      },
      "source": [
        "` `  \n",
        "` `\n",
        "\n",
        "**Ejercicio 3 - Stopwords y Stemming**\n",
        "` `  \n",
        "` `\n",
        "\n",
        "Considere el siguiente corpus:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEp83zESwb2j"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjdlJWuyS2E"
      },
      "source": [
        "Diseñe una función **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando. Puede utilizar la función del Ejercicio 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UudC-b6TzZgw"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset):\n",
        "  ### Aquí inicia tu código ###\n",
        "\n",
        "  ...\n",
        "\n",
        "  ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-m32IoNmSwM"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNzPKiAx0Aa1"
      },
      "outputs": [],
      "source": [
        "vocab = get_vocab(dataset)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZLV2hWf9FN7"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3KB0fL2zk2v"
      },
      "source": [
        "Ahora diseñe reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una función que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7g67Ml0aby"
      },
      "source": [
        "    Explique sus reglas aquí:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwQS8lcLJczI"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocab):\n",
        "  ### Aquí inicia tu código ###\n",
        "  pass\n",
        "  ### Aquí termina tu código ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onOSuS-_mL2F"
      },
      "outputs": [],
      "source": [
        "vocab = pre_processing(vocab)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKRZQnBlmUa4"
      },
      "source": [
        "` `  \n",
        "` `\n",
        "\n",
        "**Ejercicio 4 - WorldCloud**\n",
        "` `  \n",
        "` `\n",
        "\n",
        "Seleccione un corpus de texto de la librería **`nltk`**, y cree un word cloud de las principales palabras. Para esto corra la siguiente línea y elija un corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzHwHj9MmqiH"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.corpus.gutenberg.fileids())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De acuerdo, a los resultados obtenidos, considera que el WorldCloud refleja el contenido principal del que habla un documento, si es así ¿Porqué?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "` `  \n",
        "` `\n",
        "\n",
        "**Ejercicio 5 - Corpus Statistics**\n",
        "` `  \n",
        "` `\n",
        "\n",
        "Utilizando el corpus anterior, realice algunas estadísticas sobre los principales tokens del corpus, para esto:\n",
        "\n",
        "* Realice un gráfico de dispersión de algunas palabras claves que pudo observar en el WordCloud.\n",
        "* Realice un grafico de conteo de palabras sobre el corpus.\n",
        "* Realice un grafico de conteo de palabras sobre el corpus, eliminando el stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Luego, responda la siguientes preguntas:\n",
        "\n",
        "* ¿Las palabras reflejas en el corpus, son las mismas reflejas en los gráficos de conteo?\n",
        "* ¿Que sucede al eliminar las stopwords cambia algo, entre lo reflejado entre el WordCloud y lo mostrado en los gráficos?\n",
        "* En base a estos resultados, ¿Cree que es necesario eliminar stopwords? ¿Porqué no? o ¿Porque si?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUAc1zX0Lg16"
      },
      "source": [
        "![gato](https://live.staticflickr.com/4652/38904147065_0b6c446945_b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1A95IaXLHaB"
      },
      "source": [
        "**Cualquier recomendación que nos quisieran dar para una futura tarea es bienvenid@!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
