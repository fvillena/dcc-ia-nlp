{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E5GavpLngNm"
      },
      "source": [
        "# Laboratorio 2: Preprocesamiento y descripci칩n de corpora.\n",
        "\n",
        "\n",
        "### Cuerpo Docente\n",
        "\n",
        "- Profesores: [Andr칠s Abeliuk](https://aabeliuk.github.io/), [Felipe Villena](https://fabianvillena.cl/).\n",
        "- Profesor Auxiliar: [Gabriel Iturra](https://giturra.cl/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fpsz2pQt8x5"
      },
      "source": [
        "## Preguntas ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB92kQXspvbR"
      },
      "source": [
        "Leer atentamente las instrucciones entregadas a continuaci칩n para facilitar el proceso de revisi칩n de sus trabajos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosWgWgRxHKp"
      },
      "source": [
        "` `\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "\n",
        "\n",
        "- Escribe tu c칩digo entre las lineas de comentarios **### Aqu칤 inicia tu c칩digo ###** y **### Aqu칤 termina tu c칩digo ###**.\n",
        "- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecuci칩n coincida con el resultado esperado.\n",
        "- Recuerde siempre mantener buenas pr치cticas de c칩digo.\n",
        "- Est치 permitido s칩lo utilizar las librer칤as importadas antes del Ejercicio 1.\n",
        "- **Recordar** que: *Documento = Oraci칩n. Dataset = Corpus. Vocabulario = Tokens*.\n",
        "- El **orden de los resultados** pueden variar dependiendo de su m치quina, pero los valores de los resultados son los mismos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrmFHXhqUww"
      },
      "source": [
        "**Ejemplo:** Implemente una funci칩n **`hello_world()`** que imprima en pantalla `\"Hello World\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu7cIsawyJHx"
      },
      "outputs": [],
      "source": [
        "def hello_world():\n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "  print(\"Hello World\")\n",
        "  ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6klw12lwbW"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-WMk2dyQbp",
        "outputId": "9030f89c-ed23-4f5e-e317-9153250b150e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoiAMxtyUjQ"
      },
      "source": [
        "***Resultado esperado***:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td> Hello World </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "``\n",
        "``\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPyrPXiH0l4"
      },
      "source": [
        "Estas son las librer칤as permitidas. Si quieren utilizar alguna librer칤a adicional, pueden realizar la consulta a trav칠s de Discord."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtP6Emjo1kF0"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9Do0LdC9w2"
      },
      "source": [
        "En caso de desarrollar la tarea desde colab, utilizar el siguiente c칩digo para cargar los archivos desde el drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EXq1VDeC-ml",
        "outputId": "fab8dcac-3af9-49df-f273-99b0965f1b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = 'path/to/marcianeke.txt'\n",
        "except:\n",
        "    print('Ignorando conexi칩n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O puede subirlo a google colab usando este c칩digo, sin interactuar con Google Drive, pero debe resubir el archivo cada que vuelve a entrar a este google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "file = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN4bBoY2Td4"
      },
      "source": [
        "` `\n",
        "\n",
        "**Ejercicio 1 - normalizador**  \n",
        "` `  \n",
        "` `\n",
        "\n",
        "En el primer ejercicio veremos la dificultad 游땯 de normamilzar textos no estructurados, destacando la importancia de tener librer칤as que realicen este trabajo.\n",
        "\n",
        "El archivo adjunto al enunciado de la tarea contiene la letra de una canci칩n del marcianeke 游놓. Utilice este texto para realizar su primera tokenizaci칩n y ver qu칠 tan bien funciona su funci칩n.\n",
        "\n",
        "Ejecute el c칩digo a continuaci칩n para cargar el ejemplo. Recuerde realizar la modificaci칩n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNUYlWo21g4",
        "outputId": "d38b4731-e05b-4bd7-b7b3-0e99d251cd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brr\r\n",
            "Marcianeke\r\n",
            "Vamo' a estar con Pailita\r\n",
            "Dimelo m치\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar (brr)\r\n",
            "Tussi, keta quiere' mezclar\r\n",
            "Dimelo m치\r\n",
            "\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta pura quiere' mezclar\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "\r\n",
            "Esperame que ahora entro yo\r\n",
            "Y lo que pide yo lo traje\r\n",
            "No visto de traje\r\n",
            "Puro corte calle, no de maquillaje\r\n",
            "Pronto coronamos y nos vamo' de viaje\r\n",
            "Tanto hit que hago que lo' culo bajen\r\n",
            "Ella se va de shopping\r\n",
            "Sale positivo si se hace el doping\r\n",
            "Baila twerk con un poco de popping\r\n",
            "Los fardos en el bot칤n\r\n",
            "\r\n",
            "Si quieren letra llamen pa' mi booking\r\n",
            "Generando, sigo en la m칤a lowkey\r\n",
            "Cooking en el estudio con tu woman\r\n",
            "Tanto whisky, pisco que hasta lo' vecinos toman\r\n",
            "Si se tiran pa' aca puede que la arena coman\r\n",
            "Ja, en el chanteo titulado sin diploma\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "Di-dimelo m치\r\n",
            "\r\n",
            "Ah, pe-peligrosa\r\n",
            "Quiero ver como perreando me acosa\r\n",
            "Eso de atra' con el Gucci me lo roza\r\n",
            "Tengo tussi del naranjo me aburrio el rosa\r\n",
            "Capaz que tosa con el blunt\r\n",
            "Sprite con Flemibron\r\n",
            "Louis Vuitton, le quito la polera Champion\r\n",
            "A tu pretendiente con la fory lo espanto\r\n",
            "Puro perro, le doy de comer Champion Dog\r\n",
            "Ese toto lo corono yo\r\n",
            "La movie en play no hay stop\r\n",
            "Flow de sobra no hay stock\r\n",
            "Me la topo en la disco queda en shock\r\n",
            "My love, rica en las redes y en persona\r\n",
            "No usa Photoshop\r\n",
            "La llevo a comprar blone' al growshop\r\n",
            "En ropa interior los do'\r\n",
            "Me roza su vicky con mi boxer Top\r\n",
            "Dimelo m치\r\n",
            "Ando en busca de una cri\r\n",
            "minal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta quiere' mezclar\r\n",
            "Dimelo m치\r\n",
            "\r\n",
            "Ando en busca de una criminal (ah, ah)\r\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\r\n",
            "Que le guste flotar y fumar\r\n",
            "Tussi, keta pura quiere' mezclar\r\n",
            "Marcianeke, Pailita\r\n",
            "Young Varas\n"
          ]
        }
      ],
      "source": [
        "text = codecs.open('marcianeke.txt', 'r', 'UTF-8').read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vu4HZeukAHx"
      },
      "source": [
        "Implemente la funcion **```normalize()```**, que normalize una cadena de texto convirti칠ndo todo a min칰sculas, quitando los caracteres no alfab칠ticos y los tildes. Note que la funci칩n tiene una variable nombrada ```remove_tildes```, que determina si hay que eliminar los tildes o no, considere dicha opci칩n en su implementaci칩n. Luego, aplique esta funci칩n a cada una de las l칤nea de la canci칩n de marcianke 游놓.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2NeTI6lj_k5"
      },
      "outputs": [],
      "source": [
        "def normalize(text, remove_tildes = True):\n",
        "    \"\"\"Normaliza una cadena de texto convirti칠ndo todo a min칰sculas,\n",
        "    quitando los caracteres no alfab칠ticos y los tildes\"\"\"\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaOYzMk3v1X"
      },
      "source": [
        "Implementen una funci칩n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librer칤as con tokenizadores ya implementados. Pueden utilizar la librer칤a **re** importada para trabajar s칤mbolos. Esta funci칩n debe aplicar en el texto normalizado de la pregunta anterior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dl42-hgIhqB"
      },
      "source": [
        "Ejemplo de uso:\n",
        "\n",
        "`get_tokens('Este es un ejemplo de prueba.')`\n",
        "\n",
        "Nos entregar칤a:\n",
        "\n",
        "`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF1RcIwq4G2x"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "  ### Inicio del c칩digo ###\n",
        "\n",
        "  ...\n",
        "\n",
        "  ### Fin del c칩digo ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqlSpefv4_EH"
      },
      "outputs": [],
      "source": [
        "tokens = get_tokens(text)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbgTvAW-stF"
      },
      "source": [
        "**Describa cu치les fueron sus supuestos para realizar la tokenizaci칩n y compare sus tokens con los entregados por la librer칤a nltk en el bloque de c칩digo de m치s abajo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQ7CJy3-3aH"
      },
      "source": [
        "Supuestos aqui\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtmAXTr9KXK",
        "outputId": "4981a15d-89bc-4972-f91a-f4afe42659a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Brr',\n",
              " 'Marcianeke',\n",
              " 'Vamo',\n",
              " \"'\",\n",
              " 'a',\n",
              " 'estar',\n",
              " 'con',\n",
              " 'Pailita',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " '(',\n",
              " 'brr',\n",
              " ')',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Esperame',\n",
              " 'que',\n",
              " 'ahora',\n",
              " 'entro',\n",
              " 'yo',\n",
              " 'Y',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'pide',\n",
              " 'yo',\n",
              " 'lo',\n",
              " 'traje',\n",
              " 'No',\n",
              " 'visto',\n",
              " 'de',\n",
              " 'traje',\n",
              " 'Puro',\n",
              " 'corte',\n",
              " 'calle',\n",
              " ',',\n",
              " 'no',\n",
              " 'de',\n",
              " 'maquillaje',\n",
              " 'Pronto',\n",
              " 'coronamos',\n",
              " 'y',\n",
              " 'nos',\n",
              " 'vamo',\n",
              " \"'\",\n",
              " 'de',\n",
              " 'viaje',\n",
              " 'Tanto',\n",
              " 'hit',\n",
              " 'que',\n",
              " 'hago',\n",
              " 'que',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'culo',\n",
              " 'bajen',\n",
              " 'Ella',\n",
              " 'se',\n",
              " 'va',\n",
              " 'de',\n",
              " 'shopping',\n",
              " 'Sale',\n",
              " 'positivo',\n",
              " 'si',\n",
              " 'se',\n",
              " 'hace',\n",
              " 'el',\n",
              " 'doping',\n",
              " 'Baila',\n",
              " 'twerk',\n",
              " 'con',\n",
              " 'un',\n",
              " 'poco',\n",
              " 'de',\n",
              " 'popping',\n",
              " 'Los',\n",
              " 'fardos',\n",
              " 'en',\n",
              " 'el',\n",
              " 'bot칤n',\n",
              " 'Si',\n",
              " 'quieren',\n",
              " 'letra',\n",
              " 'llamen',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'mi',\n",
              " 'booking',\n",
              " 'Generando',\n",
              " ',',\n",
              " 'sigo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'm칤a',\n",
              " 'lowkey',\n",
              " 'Cooking',\n",
              " 'en',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'con',\n",
              " 'tu',\n",
              " 'woman',\n",
              " 'Tanto',\n",
              " 'whisky',\n",
              " ',',\n",
              " 'pisco',\n",
              " 'que',\n",
              " 'hasta',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'vecinos',\n",
              " 'toman',\n",
              " 'Si',\n",
              " 'se',\n",
              " 'tiran',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'aca',\n",
              " 'puede',\n",
              " 'que',\n",
              " 'la',\n",
              " 'arena',\n",
              " 'coman',\n",
              " 'Ja',\n",
              " ',',\n",
              " 'en',\n",
              " 'el',\n",
              " 'chanteo',\n",
              " 'titulado',\n",
              " 'sin',\n",
              " 'diploma',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm치',\n",
              " 'Ah',\n",
              " ',',\n",
              " 'pe',\n",
              " '-',\n",
              " 'peligrosa',\n",
              " 'Quiero',\n",
              " 'ver',\n",
              " 'como',\n",
              " 'perreando',\n",
              " 'me',\n",
              " 'acosa',\n",
              " 'Eso',\n",
              " 'de',\n",
              " 'atra',\n",
              " \"'\",\n",
              " 'con',\n",
              " 'el',\n",
              " 'Gucci',\n",
              " 'me',\n",
              " 'lo',\n",
              " 'roza',\n",
              " 'Tengo',\n",
              " 'tussi',\n",
              " 'del',\n",
              " 'naranjo',\n",
              " 'me',\n",
              " 'aburrio',\n",
              " 'el',\n",
              " 'rosa',\n",
              " 'Capaz',\n",
              " 'que',\n",
              " 'tosa',\n",
              " 'con',\n",
              " 'el',\n",
              " 'blunt',\n",
              " 'Sprite',\n",
              " 'con',\n",
              " 'Flemibron',\n",
              " 'Louis',\n",
              " 'Vuitton',\n",
              " ',',\n",
              " 'le',\n",
              " 'quito',\n",
              " 'la',\n",
              " 'polera',\n",
              " 'Champion',\n",
              " 'A',\n",
              " 'tu',\n",
              " 'pretendiente',\n",
              " 'con',\n",
              " 'la',\n",
              " 'fory',\n",
              " 'lo',\n",
              " 'espanto',\n",
              " 'Puro',\n",
              " 'perro',\n",
              " ',',\n",
              " 'le',\n",
              " 'doy',\n",
              " 'de',\n",
              " 'comer',\n",
              " 'Champion',\n",
              " 'Dog',\n",
              " 'Ese',\n",
              " 'toto',\n",
              " 'lo',\n",
              " 'corono',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'movie',\n",
              " 'en',\n",
              " 'play',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stop',\n",
              " 'Flow',\n",
              " 'de',\n",
              " 'sobra',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stock',\n",
              " 'Me',\n",
              " 'la',\n",
              " 'topo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'disco',\n",
              " 'queda',\n",
              " 'en',\n",
              " 'shock',\n",
              " 'My',\n",
              " 'love',\n",
              " ',',\n",
              " 'rica',\n",
              " 'en',\n",
              " 'las',\n",
              " 'redes',\n",
              " 'y',\n",
              " 'en',\n",
              " 'persona',\n",
              " 'No',\n",
              " 'usa',\n",
              " 'Photoshop',\n",
              " 'La',\n",
              " 'llevo',\n",
              " 'a',\n",
              " 'comprar',\n",
              " 'blone',\n",
              " \"'\",\n",
              " 'al',\n",
              " 'growshop',\n",
              " 'En',\n",
              " 'ropa',\n",
              " 'interior',\n",
              " 'los',\n",
              " 'do',\n",
              " \"'\",\n",
              " 'Me',\n",
              " 'roza',\n",
              " 'su',\n",
              " 'vicky',\n",
              " 'con',\n",
              " 'mi',\n",
              " 'boxer',\n",
              " 'Top',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'cri',\n",
              " 'minal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm치',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Marcianeke',\n",
              " ',',\n",
              " 'Pailita',\n",
              " 'Young',\n",
              " 'Varas']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(text)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5QKlXAZwN1L"
      },
      "source": [
        "` `  \n",
        "` `\n",
        "\n",
        "**Ejercicio 3 - Stopwords y Stemming**\n",
        "` `  \n",
        "` `\n",
        "\n",
        "Considere el siguiente corpus:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEp83zESwb2j"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjdlJWuyS2E"
      },
      "source": [
        "Dise침e una funci칩n **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando. Puede utilizar la funci칩n del Ejercicio 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UudC-b6TzZgw"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset):\n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "\n",
        "  ...\n",
        "\n",
        "  ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-m32IoNmSwM"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNzPKiAx0Aa1"
      },
      "outputs": [],
      "source": [
        "vocab = get_vocab(dataset)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZLV2hWf9FN7"
      },
      "source": [
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3KB0fL2zk2v"
      },
      "source": [
        "Ahora dise침e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci칩n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7g67Ml0aby"
      },
      "source": [
        "    Explique sus reglas aqu칤:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwQS8lcLJczI"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocab):\n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "  pass\n",
        "  ### Aqu칤 termina tu c칩digo ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onOSuS-_mL2F"
      },
      "outputs": [],
      "source": [
        "vocab = pre_processing(vocab)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKRZQnBlmUa4"
      },
      "source": [
        "` `  \n",
        "` `\n",
        "\n",
        "**Ejercicio 4 - WorldCloud**\n",
        "` `  \n",
        "` `\n",
        "\n",
        "Seleccione un corpus de texto de la librer칤a **`nltk`**, y cree un word cloud de las principales palabras. Para esto corra la siguiente l칤nea y elija un corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzHwHj9MmqiH"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.corpus.gutenberg.fileids())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De acuerdo, a los resultados obtenidos, considera que el WorldCloud refleja el contenido principal del que habla un documento, si es as칤 쯇orqu칠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "` `  \n",
        "` `\n",
        "\n",
        "**Ejercicio 5 - Corpus Statistics**\n",
        "` `  \n",
        "` `\n",
        "\n",
        "Utilizando el corpus anterior, realice algunas estad칤sticas sobre los principales tokens del corpus, para esto:\n",
        "\n",
        "* Realice un gr치fico de dispersi칩n de algunas palabras claves que pudo observar en el WordCloud.\n",
        "* Realice un grafico de conteo de palabras sobre el corpus.\n",
        "* Realice un grafico de conteo de palabras sobre el corpus, eliminando el stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C칩digo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Luego, responda la siguientes preguntas:\n",
        "\n",
        "* 쯃as palabras reflejas en el corpus, son las mismas reflejas en los gr치ficos de conteo?\n",
        "* 쯈ue sucede al eliminar las stopwords cambia algo, entre lo reflejado entre el WordCloud y lo mostrado en los gr치ficos?\n",
        "* En base a estos resultados, 쮺ree que es necesario eliminar stopwords? 쯇orqu칠 no? o 쯇orque si?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUAc1zX0Lg16"
      },
      "source": [
        "![gato](https://live.staticflickr.com/4652/38904147065_0b6c446945_b.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1A95IaXLHaB"
      },
      "source": [
        "**Cualquier recomendaci칩n que nos quisieran dar para una futura tarea es bienvenid@!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
