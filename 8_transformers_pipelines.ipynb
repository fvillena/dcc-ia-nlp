{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_transformers_pipelines.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5YUzajbkpjBgITdLyUwDk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillena/dcc-ia-nlp/blob/master/8_transformers_pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyIqs9QbvCn_"
      },
      "source": [
        "Los siguientes ejemplos ha sido basados en los ejemplos de \n",
        "https://github.com/huggingface/transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyTIjFJRwON1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcad6d1c-2de9-4f55-c3e3-976c70bfe44a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=f5b7c496aa846938a99ba650a816d3323bcf94bd46c676b71dfb06e66ce90fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIrwf1Tfwrpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd0efa0-07a4-4451-fde8-9ce2e24b6545"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#Responder pregunta segun el contexto\n",
        "nlp = pipeline(\"question-answering\")\n",
        "\n",
        "context = r\"\"\"\n",
        "... \n",
        "... Los datos han pasado a constituir parte esencial de cualquier empresa, desde el ámbito del entretenimiento personal hasta \n",
        "... los negocios y la planificación estratégica de grandes organizaciones. Las tecnologías de captura, procesamiento y \n",
        "... comunicación de datos los han puesto en primer plano. La noción de “diluvio de datos” hace referencia a esa marea \n",
        "... aparentemente incontenible de datos que rodean (y muchas veces ahogan) a las personas y organizaciones hoy.\n",
        "... Para analizar y sacar provecho de este diluvio de datos, los profesionales requieren tener conocimientos tanto \n",
        "... teóricos como prácticos de lo que se conoce como Ciencia de los Datos, que incluye áreas como Minería de Datos, \n",
        "... Recuperación de Información, Visualización y Gestión de Datos. El presente Diplomado apunta a formar profesionales \n",
        "... especialistas que trabajen como analistas expertos en el manejo de datos complejos y masivos..\n",
        "... \"\"\"\n",
        "\n",
        "result = nlp(question=\"¿Qué conocimientos se imparten en el diplomado?\", context=context)\n",
        "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Answer: 'El presente Diplomado apunta a formar profesionales', score: 0.0001, start: 784, end: 836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkcmQSBSrrhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2773b02-c098-4516-d225-9e7fb2683746"
      },
      "source": [
        "#clasificar si es positivo o negativo\n",
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "result = nlp(\"No me molestó\")[0]\n",
        "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n",
        "\n",
        "result = nlp(\"A nadie le gustó\")[0]\n",
        "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: POSITIVE, with score: 0.9945\n",
            "label: POSITIVE, with score: 0.999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTmgRg13sjCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ec261d-dd25-418c-dcf4-5ff32d12724b"
      },
      "source": [
        "#generacion de texto\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\", return_dict=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "# Padding text helps XLNet with short prompts - proposed by Aman Rusia in https://github.com/rusiaaman/XLNet-gen#methodology\n",
        "\n",
        "PADDING_TEXT =\"\"\" Los datos han pasado a constituir parte esencial de cualquier empresa, desde el ámbito del entretenimiento personal hasta \n",
        "... los negocios y la planificación estratégica de grandes organizaciones. Las tecnologías de captura, procesamiento y \n",
        "... comunicación de datos los han puesto en primer plano. La noción de “diluvio de datos” hace referencia a esa marea \n",
        "... aparentemente incontenible de datos que rodean (y muchas veces ahogan) a las personas y organizaciones hoy.\n",
        "... Para analizar y sacar provecho de este diluvio de datos, los profesionales requieren tener conocimientos tanto \n",
        "... teóricos como prácticos de lo que se conoce como Ciencia de los Datos, que incluye áreas como Minería de Datos, \n",
        "... Recuperación de Información, Visualización y Gestión de Datos. El presente Diplomado apunta a formar profesionales \n",
        "... especialistas que trabajen como analistas expertos en el manejo de datos complejos y masivos. <eod> </s> <eos>\n",
        "... \"\"\"\n",
        "\n",
        "prompt = \"Los datos en mi empresa \"\n",
        "inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "\n",
        "prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
        "outputs = model.generate(inputs, max_length=250, do_sample=True, top_p=0.95, top_k=60)\n",
        "generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
        "\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Los datos en mi empresa i empresa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6HfZNxHtxHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd10c692-8898-449c-a01b-6293e12d80b3"
      },
      "source": [
        "#resumir textos\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "ARTICLE = \"\"\" Los datos han pasado a constituir parte esencial de cualquier empresa, desde el ámbito del entretenimiento personal hasta \n",
        "... los negocios y la planificación estratégica de grandes organizaciones. Las tecnologías de captura, procesamiento y \n",
        "... comunicación de datos los han puesto en primer plano. La noción de “diluvio de datos” hace referencia a esa marea \n",
        "... aparentemente incontenible de datos que rodean (y muchas veces ahogan) a las personas y organizaciones hoy.\n",
        "... Para analizar y sacar provecho de este diluvio de datos, los profesionales requieren tener conocimientos tanto \n",
        "... teóricos como prácticos de lo que se conoce como Ciencia de los Datos, que incluye áreas como Minería de Datos, \n",
        "... Recuperación de Información, Visualización y Gestión de Datos. El presente Diplomado apunta a formar profesionales \n",
        "... especialistas que trabajen como analistas expertos en el manejo de datos complejos y masivos. <eod> </s> <eos>\n",
        "... \"\"\"\n",
        "\n",
        "\n",
        "print(summarizer(ARTICLE, max_length=5, min_length=4, do_sample=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'summary_text': ' Los datos han pasado a parte esencial de cualqu'}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}