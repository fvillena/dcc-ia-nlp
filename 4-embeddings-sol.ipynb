{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-embeddings-sol.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKRUWSbiMHh2tRY6mjg1AH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillena/dcc-ia-nlp/blob/master/4-embeddings-sol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOPcd3UfJ5ec"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sonMA0Csl_Z2"
      },
      "source": [
        "# Actividad 1: Word2vec en tensorflow\n",
        "\n",
        "Observe el preprocesamiento que se realiza al corpus, la estructura construida con Tensorflow y el procedimiento para entrenar el modelo.\n",
        "\n",
        "\n",
        "1.   Construya los word embeddings desde los pesos y sesgos del modelo entrenado\n",
        "2.   Visualice los embeddings bidimensionales en un gráfico de dispersión e interprete los resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zak8IEVRl8JD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCrljKgFmJFj"
      },
      "source": [
        "corpus = ['king is a strong man', \n",
        "          'queen is a wise woman', \n",
        "          'boy is a young man',\n",
        "          'girl is a young woman',\n",
        "          'prince is a young king',\n",
        "          'princess is a young queen',\n",
        "          'man is strong', \n",
        "          'woman is pretty',\n",
        "          'prince is a boy will be king',\n",
        "          'princess is a girl will be queen']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VnMZGnBmS4V"
      },
      "source": [
        "def preprocess(text):\n",
        "  tokens = text.split(\" \")\n",
        "  return [token for token in tokens if len(token) > 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA6vpojsnI9L"
      },
      "source": [
        "def get_vocabulary(corpus):\n",
        "  vocabulary = []\n",
        "  for text in corpus:\n",
        "    vocabulary += text\n",
        "  return sorted(list(set(vocabulary)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7InbdYdnmslf"
      },
      "source": [
        "sentences = list(map(preprocess, corpus))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaiaxx3Cm_eh"
      },
      "source": [
        "vocabulary = get_vocabulary(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCP-PFhln7wE"
      },
      "source": [
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        # Acá se toma una ventana de -WINDOWS_SIZE, WINDOWS_SIZE para generar el skip gram. Dado que las \n",
        "        # frases son cortas, se utiliza min y max para tener cuidado con los límites de la frase. \n",
        "        # Además, el +1 en el límite superior es para considerar el índice de la propia palabra en cuestión \n",
        "        # (probar qué ocurre cuando se elimina dicho +1)\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1]: \n",
        "            if neighbor != word:\n",
        "                data.append((word, neighbor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGhl12TpPEc"
      },
      "source": [
        "features = np.zeros((len(data),len(vocabulary)),dtype=np.float32)\n",
        "labels = np.zeros((len(data),len(vocabulary)),dtype=np.float32)\n",
        "for i,(feature,label) in enumerate(data):\n",
        "  features[i,vocabulary.index(feature)] = 1\n",
        "  labels[i,vocabulary.index(label)] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g1a0Y-szpRZ"
      },
      "source": [
        "class Word2Vec:\n",
        "  def __init__(self, vocab_size=0, embedding_dim=2, epochs=10000):\n",
        "    self.vocab_size=vocab_size\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.epochs=epochs\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
        "  def train(self, x_train=None, y_train=None):\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.vocab_size, self.embedding_dim]))\n",
        "    self.b1 = tf.Variable(tf.random.normal([self.embedding_dim])) #bias\n",
        " \n",
        "    self.W2 = tf.Variable(tf.random.normal([self.embedding_dim, self.vocab_size]))\n",
        "    self.b2 = tf.Variable(tf.random.normal([self.vocab_size]))\n",
        " \n",
        "    for _ in range(self.epochs):\n",
        "      with tf.GradientTape() as t:\n",
        "        hidden_layer = tf.add(tf.matmul(x_train,self.W1),self.b1) \n",
        "        output_layer = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, self.W2), self.b2))\n",
        "        cross_entropy_loss = tf.reduce_mean(-tf.math.reduce_sum(y_train * tf.math.log(output_layer), axis=[1]))\n",
        " \n",
        "      grads = t.gradient(cross_entropy_loss, [self.W1, self.b1, self.W2, self.b2])\n",
        "      self.optimizer.apply_gradients(zip(grads,[self.W1, self.b1, self.W2, self.b2]))\n",
        "      if(_ % 1000 == 0):\n",
        "        print(cross_entropy_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FswiyGsE0ETj",
        "outputId": "031d80f9-d4bc-4a27-ead1-42b2623e4a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "w2v = Word2Vec(vocab_size=len(vocabulary), epochs=10000)\n",
        "w2v.train(features, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.5579734, shape=(), dtype=float32)\n",
            "tf.Tensor(1.9996668, shape=(), dtype=float32)\n",
            "tf.Tensor(1.9211873, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8915883, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8771824, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8668216, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8576354, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8493826, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8402344, shape=(), dtype=float32)\n",
            "tf.Tensor(1.8302771, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazPhyRg6Xqi"
      },
      "source": [
        "vectors = w2v.W1 + w2v.b1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQpVwsWSDH0H",
        "outputId": "2b38228e-9027-421e-c8ae-d43447058c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "import plotly.express as px\n",
        "px.scatter(x=vectors[:,0],y=vectors[:,1],text=vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"81685286-e806-4135-9bd6-57acdc26752e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"81685286-e806-4135-9bd6-57acdc26752e\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '81685286-e806-4135-9bd6-57acdc26752e',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"boy\", \"girl\", \"king\", \"man\", \"pretty\", \"prince\", \"princess\", \"queen\", \"strong\", \"will\", \"wise\", \"woman\", \"young\"], \"type\": \"scatter\", \"x\": [0.167075514793396, -3.5144481658935547, 0.6009480357170105, 0.919240415096283, -5.108983993530273, 0.15572822093963623, -1.3569204807281494, -3.0850067138671875, 2.318002223968506, 0.011505186557769775, -1.7606146335601807, -1.2005813121795654, 0.207752525806427], \"xaxis\": \"x\", \"y\": [1.6253795623779297, -0.05759328603744507, 3.27994441986084, 4.20176887512207, -1.87477707862854, 2.099468946456909, 0.22561055421829224, 0.003721177577972412, 0.5712683200836182, -0.29113394021987915, -2.4476318359375, -0.08759480714797974, -0.6031336188316345], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('81685286-e806-4135-9bd6-57acdc26752e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUqZEv1-4RL7"
      },
      "source": [
        "## Embeddings con gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDcmrlhNLkSC"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import gensim\n",
        "import gensim.downloader\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pc9wPn4vQgL"
      },
      "source": [
        "Descargamos el corpus Brown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxoUU72HiAEb",
        "outputId": "bc9c27b7-8b84-477b-ed2e-516b35687922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2y8Lb66OMHs"
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKoP29UJM60q"
      },
      "source": [
        "corpus = nltk.corpus.brown.sents()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqhjOSpvBUF"
      },
      "source": [
        "Entrenamos un modelo model sobre el corpus Brown, el cual contiene alrededor de 1.000.000 de palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCFDEXJlNDxV",
        "outputId": "e5eda905-3f92-4f3d-b4bf-b1bef359b171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = gensim.models.word2vec.Word2Vec(sentences = corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 21:56:25,468 : INFO : collecting all words and their counts\n",
            "2020-11-10 21:56:25,472 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-11-10 21:56:25,945 : INFO : PROGRESS: at sentence #10000, processed 219770 words, keeping 23488 word types\n",
            "2020-11-10 21:56:26,402 : INFO : PROGRESS: at sentence #20000, processed 430477 words, keeping 34367 word types\n",
            "2020-11-10 21:56:26,871 : INFO : PROGRESS: at sentence #30000, processed 669056 words, keeping 42365 word types\n",
            "2020-11-10 21:56:27,303 : INFO : PROGRESS: at sentence #40000, processed 888291 words, keeping 49136 word types\n",
            "2020-11-10 21:56:27,639 : INFO : PROGRESS: at sentence #50000, processed 1039920 words, keeping 53024 word types\n",
            "2020-11-10 21:56:27,907 : INFO : collected 56057 word types from a corpus of 1161192 raw words and 57340 sentences\n",
            "2020-11-10 21:56:27,907 : INFO : Loading a fresh vocabulary\n",
            "2020-11-10 21:56:27,957 : INFO : effective_min_count=5 retains 15173 unique words (27% of original 56057, drops 40884)\n",
            "2020-11-10 21:56:27,958 : INFO : effective_min_count=5 leaves 1095086 word corpus (94% of original 1161192, drops 66106)\n",
            "2020-11-10 21:56:28,015 : INFO : deleting the raw counts dictionary of 56057 items\n",
            "2020-11-10 21:56:28,018 : INFO : sample=0.001 downsamples 42 most-common words\n",
            "2020-11-10 21:56:28,019 : INFO : downsampling leaves estimated 781596 word corpus (71.4% of prior 1095086)\n",
            "2020-11-10 21:56:28,078 : INFO : estimated required memory for 15173 words and 100 dimensions: 19724900 bytes\n",
            "2020-11-10 21:56:28,079 : INFO : resetting layer weights\n",
            "2020-11-10 21:56:31,012 : INFO : training model with 3 workers on 15173 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-11-10 21:56:32,030 : INFO : EPOCH 1 - PROGRESS: at 24.43% examples, 197765 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:33,057 : INFO : EPOCH 1 - PROGRESS: at 48.67% examples, 202759 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:34,082 : INFO : EPOCH 1 - PROGRESS: at 73.93% examples, 203484 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:34,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-10 21:56:34,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-10 21:56:34,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-10 21:56:34,899 : INFO : EPOCH - 1 : training on 1161192 raw words (781703 effective words) took 3.9s, 201433 effective words/s\n",
            "2020-11-10 21:56:35,907 : INFO : EPOCH 2 - PROGRESS: at 23.64% examples, 192774 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:36,937 : INFO : EPOCH 2 - PROGRESS: at 47.85% examples, 199823 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:37,955 : INFO : EPOCH 2 - PROGRESS: at 73.02% examples, 202094 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:38,794 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-10 21:56:38,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-10 21:56:38,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-10 21:56:38,810 : INFO : EPOCH - 2 : training on 1161192 raw words (782023 effective words) took 3.9s, 200088 effective words/s\n",
            "2020-11-10 21:56:39,841 : INFO : EPOCH 3 - PROGRESS: at 24.43% examples, 194722 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:40,848 : INFO : EPOCH 3 - PROGRESS: at 47.85% examples, 199801 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:41,871 : INFO : EPOCH 3 - PROGRESS: at 73.02% examples, 201717 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:42,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-10 21:56:42,710 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-10 21:56:42,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-10 21:56:42,722 : INFO : EPOCH - 3 : training on 1161192 raw words (781609 effective words) took 3.9s, 199976 effective words/s\n",
            "2020-11-10 21:56:43,744 : INFO : EPOCH 4 - PROGRESS: at 24.43% examples, 197147 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:44,752 : INFO : EPOCH 4 - PROGRESS: at 47.85% examples, 201067 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:45,763 : INFO : EPOCH 4 - PROGRESS: at 73.02% examples, 203251 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:46,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-10 21:56:46,616 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-10 21:56:46,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-10 21:56:46,621 : INFO : EPOCH - 4 : training on 1161192 raw words (781531 effective words) took 3.9s, 200823 effective words/s\n",
            "2020-11-10 21:56:47,639 : INFO : EPOCH 5 - PROGRESS: at 23.64% examples, 191075 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:48,651 : INFO : EPOCH 5 - PROGRESS: at 47.04% examples, 197594 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:49,656 : INFO : EPOCH 5 - PROGRESS: at 70.81% examples, 199163 words/s, in_qsize 0, out_qsize 0\n",
            "2020-11-10 21:56:50,599 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-10 21:56:50,608 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-10 21:56:50,612 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-10 21:56:50,614 : INFO : EPOCH - 5 : training on 1161192 raw words (782022 effective words) took 4.0s, 196110 effective words/s\n",
            "2020-11-10 21:56:50,615 : INFO : training on a 5805960 raw words (3908888 effective words) took 19.6s, 199419 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ntZpYYBvGFc"
      },
      "source": [
        "Importamos un modelo de word2vec entrenado sobre google news, este modelo fue entrenado sobre un corpus de 3.000.000.000 de palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPnP7Rh5jVpk",
        "outputId": "9d3004b5-8524-4ebd-c78c-5da51586ff83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "news = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 21:56:50,622 : INFO : Creating /root/gensim-data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[================================================--] 97.9% 1628.4/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 22:00:43,253 : INFO : word2vec-google-news-300 downloaded\n",
            "2020-11-10 22:00:43,256 : INFO : loading projection weights from /root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
            "2020-11-10 22:02:52,727 : INFO : loaded (3000000, 300) matrix from /root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REu7SPwCrKK2"
      },
      "source": [
        "## Actividad 2: Exploración de los embeddings\n",
        "\n",
        "Después de calcular los embeddings, podemos asociar un vector de números reales, de dimensiones conocidas a una palabra de nuestro vocabulario.\n",
        "\n",
        "\n",
        "1.   ¿Cuántas dimensiones tiene cada vector asociado a las palabras en cada uno de los modelos?\n",
        "2.   ¿Cuántos vectores hay en cada uno de los modelos?\n",
        "3.   ¿Existen diferencian en el tamaño del vocabulario del modelo `model` y el modelo news?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RtInP-wrHEn",
        "outputId": "eeb063d2-8c57-4b60-9ced-5c4da1a868c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# HINT\n",
        "# news.wv.vectors # esta es una matriz\n",
        "news.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLYZyAFWGt4q",
        "outputId": "6c549db4-b6a9-41c0-d54e-894a048ef290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15173, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBxFNhxZSoZ0"
      },
      "source": [
        "## Actividad 3: Similaridad y analogía\n",
        "\n",
        "Existen un par de cualidades semánticas de las palabras, las cuales pueden ser fácilmente demostradas a través de operaciones vectoriales sobre el espacio generado por el proceso de cálculo de embeddings.\n",
        "\n",
        "La similaridad es la métrica de cercanía que tienen 2 palabras, esta característica es fácil de representar a través de la similaridad coseno entre 2 vectores.\n",
        "\n",
        "La analogía es la relación semántica que tienen 2 palabras, por ejemplo, la palabra \"rey\" y \"reina\" están relacionadas por el concepto de \"género\". Estas analogías se pueden operacionalizar en el espacio vectorial de los word embeddings como la resta de los vectores asociados a las palabras.\n",
        "\n",
        "\n",
        "\n",
        "1.   Verifique cuáles son las palabras más cercanas a palabras que usted seleccione e interprete la correctitud de las palabras retornadas por los modelos `model` y `news`\n",
        "2.   Verifique cuál de los modelos resuelve mejor la prueba de analogía: \"man\" es a \"woman\" como \"king\" es a \"queen\". Invente otra analogía y pruebe si el modelo la puede resolver.\n",
        "3.   Según sus pruebas, ¿el tamaño del corpus de entrenamiento afecta el rendimiento del modelo?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fQ0w9XlNOHE",
        "outputId": "51a66f0a-6625-40bf-8973-1e1e4887c96b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# así obtenemos las palabras más cercanas a las palabra \"woman\"\n",
        "model.wv.most_similar(\"woman\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 22:02:52,757 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning:\n",
            "\n",
            "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girl', 0.9572885036468506),\n",
              " ('boy', 0.8980333805084229),\n",
              " ('man', 0.8774807453155518),\n",
              " ('child', 0.8735851049423218),\n",
              " ('young', 0.8711107969284058),\n",
              " ('distaste', 0.86578369140625),\n",
              " ('remark', 0.8602189421653748),\n",
              " ('artist', 0.8546708822250366),\n",
              " ('fellow', 0.8540172576904297),\n",
              " ('martyr', 0.8498712182044983)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKk_90mOIQBL",
        "outputId": "887a9a82-b1d8-46c5-da19-2efeb83e822b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "news.most_similar(\"woman\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-10 22:02:52,798 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning:\n",
            "\n",
            "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('man', 0.7664012908935547),\n",
              " ('girl', 0.7494640946388245),\n",
              " ('teenage_girl', 0.7336829900741577),\n",
              " ('teenager', 0.631708562374115),\n",
              " ('lady', 0.6288785934448242),\n",
              " ('teenaged_girl', 0.6141783595085144),\n",
              " ('mother', 0.607630729675293),\n",
              " ('policewoman', 0.6069462299346924),\n",
              " ('boy', 0.5975908041000366),\n",
              " ('Woman', 0.5770983695983887)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ov7uKOqrGR"
      },
      "source": [
        "#HINT:\n",
        "# news.wv.vectors[news.vocab[\"woman\"].index] # así obtenemos el vector asociado a la palabra woman\n",
        "# news.wv.similar_by_vector(vector) # así obtenemos las palabras más cercanas a un vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxE7-skeHDAX",
        "outputId": "741386e4-f0a6-4356-f4e0-6e7361f490bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = news.vectors[news.vocab[\"woman\"].index] - news.vectors[news.vocab[\"man\"].index] + news.vectors[news.vocab[\"king\"].index]\n",
        "news.similar_by_vector(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning:\n",
            "\n",
            "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.8449392318725586),\n",
              " ('queen', 0.7300517559051514),\n",
              " ('monarch', 0.6454660892486572),\n",
              " ('princess', 0.6156251430511475),\n",
              " ('crown_prince', 0.5818676948547363),\n",
              " ('prince', 0.5777117609977722),\n",
              " ('kings', 0.5613663792610168),\n",
              " ('sultan', 0.5376776456832886),\n",
              " ('Queen_Consort', 0.5344247817993164),\n",
              " ('queens', 0.5289887189865112)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3HM0gHMIc3g",
        "outputId": "9ccfe347-eda1-40f0-f405-b787304803fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = model.wv.vectors[model.wv.vocab[\"woman\"].index] - model.wv.vectors[model.wv.vocab[\"man\"].index] + model.wv.vectors[model.wv.vocab[\"king\"].index]\n",
        "model.wv.similar_by_vector(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning:\n",
            "\n",
            "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('per', 0.6255831718444824),\n",
              " ('6,000', 0.5924739837646484),\n",
              " ('cent', 0.5852186679840088),\n",
              " ('centum', 0.5601134896278381),\n",
              " ('capita', 0.5454519987106323),\n",
              " ('atmospheres', 0.5397146940231323),\n",
              " ('Phase', 0.5384734869003296),\n",
              " ('Profile', 0.5352369546890259),\n",
              " ('periodicals', 0.5215284824371338),\n",
              " ('Rhode', 0.5203348398208618)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj4Hv0fkPKXg"
      },
      "source": [
        "## Actividad 4: Reducción de dimensionalidad y visualización\n",
        "\n",
        "Nuestros vectores tienen más de 2 dimensiones, por lo que no es muy fácil interptretar su ubicación espacial. Utiliza un método de reducción de dimensionalidad que conozcas para reducir hacia 2 dimensiones nuestros vectores y visualiza el resultado.\n",
        "\n",
        "\n",
        "*   ¿Existen agrupaciones aparentes de palabras dentro del espacio? y si es así, ¿las palabras agrupadas, son similares?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JhwXqJJeXaD",
        "outputId": "cce48c96-7d87-46e4-a3c8-52e74842b7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "import sklearn.decomposition\n",
        "news_matrix_2d = sklearn.decomposition.PCA(2).fit_transform(news.vectors[:100,:])\n",
        "import plotly.express as px\n",
        "px.scatter(x=news_matrix_2d[:,0],y=news_matrix_2d[:,1],text=list(news.vocab)[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ce1f8b16-6d3f-45cc-89cf-e5cb0b221e5b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ce1f8b16-6d3f-45cc-89cf-e5cb0b221e5b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ce1f8b16-6d3f-45cc-89cf-e5cb0b221e5b',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>text=%{text}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers+text\", \"name\": \"\", \"showlegend\": false, \"text\": [\"</s>\", \"in\", \"for\", \"that\", \"is\", \"on\", \"##\", \"The\", \"with\", \"said\", \"was\", \"the\", \"at\", \"not\", \"as\", \"it\", \"be\", \"from\", \"by\", \"are\", \"I\", \"have\", \"he\", \"will\", \"has\", \"####\", \"his\", \"an\", \"this\", \"or\", \"their\", \"who\", \"they\", \"but\", \"$\", \"had\", \"year\", \"were\", \"we\", \"more\", \"###\", \"up\", \"been\", \"you\", \"its\", \"one\", \"about\", \"would\", \"which\", \"out\", \"can\", \"It\", \"all\", \"also\", \"two\", \"after\", \"first\", \"He\", \"do\", \"time\", \"than\", \"when\", \"We\", \"over\", \"last\", \"new\", \"other\", \"her\", \"people\", \"into\", \"In\", \"our\", \"there\", \"A\", \"she\", \"could\", \"just\", \"years\", \"some\", \"U.S.\", \"three\", \"million\", \"them\", \"what\", \"But\", \"so\", \"no\", \"like\", \"if\", \"only\", \"percent\", \"get\", \"did\", \"him\", \"game\", \"back\", \"because\", \"now\", \"#.#\", \"before\"], \"type\": \"scatter\", \"x\": [0.20471715927124023, 0.3271665871143341, 0.24327783286571503, -0.16857191920280457, -0.05791927129030228, 0.15421828627586365, 1.0095276832580566, 0.5676600933074951, 0.16907428205013275, -0.315415620803833, -0.0013769882498309016, 0.1743440479040146, 0.2776801586151123, -0.6823506355285645, 0.025378011167049408, -0.3575935661792755, -0.2101593166589737, 0.43896517157554626, 0.4870210289955139, -0.20580650866031647, -1.1214569807052612, -0.26662683486938477, -0.3865021765232086, -0.16358335316181183, 0.2420123815536499, 0.8991965651512146, -0.031943123787641525, 0.39391985535621643, -0.11053511500358582, -0.07167136669158936, -0.1237722709774971, 0.03256624937057495, -0.6313999891281128, -0.29304561018943787, 1.3566392660140991, -0.08749759942293167, 0.7070679068565369, 0.025877710431814194, -1.0063031911849976, 0.1853027492761612, 1.1205569505691528, 0.10266250371932983, 0.03519624471664429, -1.0752499103546143, 0.48618805408477783, 0.09753440320491791, -0.07480322569608688, -0.3871647119522095, 0.36691439151763916, -0.2059185802936554, -0.6352223753929138, -0.37278860807418823, -0.21502774953842163, 0.17334802448749542, 0.5016746520996094, 0.41021832823753357, 0.4231993556022644, -0.12071460485458374, -0.9662526845932007, -0.02020138129591942, 0.4904322028160095, -0.09488581120967865, -1.049663782119751, 0.39208561182022095, 0.46977823972702026, 0.25069254636764526, -0.06326069682836533, -0.20612108707427979, -0.3856203854084015, 0.09278564155101776, 0.6012858152389526, -0.5188712477684021, -0.6270574927330017, 0.6182809472084045, -0.4542599320411682, -0.40824851393699646, -0.2806560695171356, 0.48572438955307007, -0.23742057383060455, 0.5585944652557373, 0.663575291633606, 1.4803190231323242, -0.5117660760879517, -0.5638426542282104, -0.3525819778442383, -0.5429996848106384, -0.36381515860557556, -0.5156723856925964, -0.5541519522666931, 0.014401222579181194, 1.2804816961288452, -0.570402979850769, -0.7731971740722656, -0.44890445470809937, -0.14176766574382782, -0.17714209854602814, -0.3554481267929077, -0.06848444789648056, 1.467623233795166, 0.12795034050941467], \"xaxis\": \"x\", \"y\": [0.007347999140620232, 0.18101537227630615, 0.03302741050720215, 0.15485802292823792, -0.14541089534759521, 0.1448667198419571, -0.2626210153102875, 1.2921111583709717, 0.11301688849925995, 0.03091522306203842, 0.022124778479337692, 0.046648018062114716, 0.07837490737438202, -0.30377981066703796, 0.2223285287618637, 0.12504035234451294, -0.21329693496227264, 0.06175079569220543, 0.20832645893096924, -0.9697326421737671, 0.08738238364458084, -0.3408467173576355, 0.21375326812267303, -0.6025135517120361, 0.23424041271209717, 0.1090790331363678, 0.5178364515304565, 0.4377841055393219, 0.06045282259583473, -0.24339011311531067, -0.20505167543888092, 0.2834952771663666, -0.45124033093452454, 0.36672917008399963, -0.4785057604312897, -0.09690152108669281, -0.10920696705579758, -0.7496208548545837, -0.41236093640327454, -0.332032173871994, -0.4584651291370392, 0.05205125734210014, -0.2284586876630783, -0.3290258049964905, 0.3411645293235779, -0.09012942016124725, -0.1442447155714035, -0.3813922703266144, 0.5089507699012756, 0.05377098545432091, -0.7289607524871826, 1.473668098449707, -0.38973379135131836, -0.04603235796093941, -0.3620074391365051, 0.30133429169654846, 0.09548630565404892, 1.3049829006195068, -0.47664040327072144, -0.08731769025325775, -0.2704741060733795, 0.301104873418808, 0.7452206611633301, 0.07039059698581696, 0.14764510095119476, -0.08098136633634567, -0.44647443294525146, 0.5113691687583923, -0.2455453872680664, 0.2580867111682892, 1.098019003868103, -0.2556229531764984, -0.23273976147174835, 1.2763668298721313, 0.24143487215042114, -0.4366041421890259, -0.08480945974588394, 0.03190619498491287, -0.33972811698913574, -0.025193439796566963, -0.35821333527565, -0.6280500888824463, -0.1855827271938324, 0.03044389933347702, 1.2226725816726685, 0.05143874138593674, -0.2517581880092621, -0.2312522828578949, -0.11382722854614258, -0.12971653044223785, -0.8561189770698547, -0.2869358956813812, -0.2793680727481842, 0.3660588264465332, 0.031103411689400673, 0.07374374568462372, 0.25374919176101685, -0.18748724460601807, -0.5009666085243225, 0.19169971346855164], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ce1f8b16-6d3f-45cc-89cf-e5cb0b221e5b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg_LGzUfJQFm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}