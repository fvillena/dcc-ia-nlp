{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iW239eziMR7"
      },
      "source": [
        "# Tarea 1\n",
        "\n",
        "### Cuerpo Docente\n",
        "\n",
        "- Profesores: [Andr칠s Abeliuk](https://aabeliuk.github.io/), [Felipe Villena](https://fabianvillena.cl/).\n",
        "- Profesora Auxiliar: Mar칤a Jos칠 Zambrano\n",
        "\n",
        "### Instrucciones generales\n",
        "\n",
        "- Grupos de m치ximo 4 personas.\n",
        "- Ausentes deber치n realizar la actividad solos.\n",
        "- Esta prohibido compartir las respuestas con otros grupos.\n",
        "- Indicios de copia ser치n penalizados con la nota m칤nima.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente, si utiliza material extra debe citarlo.\n",
        "\n",
        "\n",
        "### Integrantes\n",
        "\n",
        "> POR FAVOR AGREGAR TODOS LOS NOMBRES DE LOS INTEGRANTES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvRYIoMgiiNn"
      },
      "source": [
        "# Preguntas Teoricas\n",
        "\n",
        "1. 쯇or qu칠 es importante realizar un preprocesamiento adecuado antes de aplicar modelos de aprendizaje autom치tico en NLP?\n",
        "  - *Respuesta*\n",
        "\n",
        "2. Imagina que trabajas con un corpus grande y sin limpiar (por ejemplo, tweets). 쯈u칠 pasos adicionales incluir칤as en el preprocesamiento para mejorar la calidad del an치lisis?\n",
        "  - *Respuesta*\n",
        "\n",
        "3. Explica brevemente la diferencia entre lematizaci칩n y stemming.\n",
        "  - *Respuesta*\n",
        "\n",
        "4. Si una palabra aparece con mucha frecuencia en un corpus, 쯖rees que siempre es relevante? Justifica tu respuesta.\n",
        "  - *Respuesta*\n",
        "\n",
        "5. Explica la principal diferencia entre las representaciones Bag of Words y TF-IDF.\n",
        "  - *Respuesta*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iljXpaTrLSsG"
      },
      "source": [
        "# Parte Pr치ctica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HLEsoDKj5zM"
      },
      "source": [
        "## Pregunta 1\n",
        "En muchas ocasiones, las bibliotecas necesitan inventariar la informaci칩n de todos los libros disponibles en su stock. Dado que la informaci칩n puede estar sin procesar o contener errores, se te solicita, en tu calidad de estudiante del m칩dulo de Procesamiento del Lenguaje Natural (NLP), que revises la informaci칩n contenida en el archivo libros.txt.\n",
        "\n",
        "Para revisar la informaci칩n debe realizar los siguientes pasos usando s칩lo funciones nativas de Python:\n",
        "\n",
        "- Leer el Archivo: Abrir el archivo libros.txt y leer su contenido.\n",
        "- Transformaci칩n de Strings: Convertir los t칤tulos de los libros y los nombres de los autores a may칰sculas.\n",
        "- B칰squeda de Strings: Encontrar y mostrar todos los libros que contienen la palabra 'la' en el t칤tulo.\n",
        "- Split de Strings: Para cada autor, extraer y mostrar solo su primer nombre.\n",
        "- Reemplazo de Strings: Reemplazar cualquier instancia de 'y' por '&' en los t칤tulos de los libros y mostrar los t칤tulos modificados.\n",
        "- Longitud de Strings: Calcular y mostrar la cantidad de palabras en el t칤tulo de cada libro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQi_jPmAL8iY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-ruh7qpMvsI"
      },
      "source": [
        "## Pregunta 2\n",
        "\n",
        " a) Dise침e una funci칩n **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando.\n",
        " dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]\n",
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr6Ig3yvwWEH"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUczCQ1kMvHS"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset):\n",
        "  ### Aqu칤 inicia tu c칩digo ###\n",
        "\n",
        "  ...\n",
        "\n",
        "  ### Aqu칤 termina tu c칩digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPSLm_LDOu6o"
      },
      "source": [
        "b) 4 - WorldCloud - Seleccione un corpus de texto de la librer칤a **`nltk`**, y cree un word cloud de las principales palabras. Para esto corra la siguiente l칤nea y elija un corpus.\n",
        "\n",
        "De acuerdo, a los resultados obtenidos, considera que el WorldCloud refleja el contenido principal del que habla un documento, si es as칤 쯇orqu칠?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsjDZmPsXjMs",
        "outputId": "d33eff62-617b-44e3-f4ed-398da1930235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDuI6a-3OvDk",
        "outputId": "49aba493-8b1b-4e4d-f79e-35478e2057ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "print(nltk.corpus.gutenberg.fileids())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBIKUH4tiMSH"
      },
      "source": [
        "## Pregunta 3\n",
        "### Contexto\n",
        "\n",
        "El discurso de odio es cualquier expresi칩n que promueva o incite a la discriminaci칩n, la hostilidad o la violencia hacia una persona o grupo de personas en una relaci칩n asim칠trica de poder, tal como la raza, la etnia, el g칠nero, la orientaci칩n sexual, la religi칩n, la nacionalidad, una discapacidad u otra caracter칤stica similar.\n",
        "\n",
        "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortes칤a y consideraci칩n en la interacci칩n entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
        "\n",
        "En esta tarea tendr치n a su disposici칩n un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en espa침ol de Chile. Con estos datos, deber치n entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
        "\n",
        "El corpus para esta tarea se compone de 3 datasets:  \n",
        "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
        "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
        "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
        "\n",
        "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabi치n Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computaci칩n, Universidad de Chile.\n",
        "\n",
        "Los datos solo pueden ser usados con fines de investigaci칩n y docencia. Est치 prohibida la difusi칩n externa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZjrxFD2iMSI"
      },
      "source": [
        "#### Para el siguiente informe deben:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcwwfIjriMSJ"
      },
      "source": [
        "Para la siguente tarea deber치 revolver una tarea de multi-clasificaci칩n, realizando los siguentes pasos:\n",
        "\n",
        "- Realizar un an치lisis estad칤stico del corpus.\n",
        "- Crear dos tipos de text representation.\n",
        "- Desarrollar al menos cuatros tipos de clasificadores que resuelvan la tarea.\n",
        "- An치lizar sus resultados.\n",
        "\n",
        "Sin embargo, primero cargaremos el datataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkPVO6ESiMSK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvB2UE62iMSM"
      },
      "source": [
        "### Cargar dataset\n",
        "\n",
        "En esta secci칩n, cargaremos el dataset desde el repositorio del m칩dulo. Para ello ejecute las siguientes l칤neas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rSTfQ2AiMSM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFJiPdc9iMSO"
      },
      "outputs": [],
      "source": [
        "# Dataset de entrenamiento.\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtg92w0iiMSP"
      },
      "source": [
        "### Analizar los datos\n",
        "\n",
        "En esta secci칩n analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi7mS3yViMSQ",
        "outputId": "4138dbf3-e97c-4376-a4df-b14333240c73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9466</th>\n",
              "      <td>13085</td>\n",
              "      <td>La recalcada put칤sima de mierda y la concha de...</td>\n",
              "      <td>odio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5578</th>\n",
              "      <td>7613</td>\n",
              "      <td>@user @user No es que los gaymers chilenos sea...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204</th>\n",
              "      <td>11375</td>\n",
              "      <td>@user Dios bendiga a #Colombia y autoridades @...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9202</th>\n",
              "      <td>15259</td>\n",
              "      <td>Cuando me enter칠 de que Shakira estaba saliend...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>10230</td>\n",
              "      <td>@user claro si los q la sacaron fueron los per...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                              texto   clase\n",
              "9466  13085  La recalcada put칤sima de mierda y la concha de...    odio\n",
              "5578   7613  @user @user No es que los gaymers chilenos sea...  normal\n",
              "2204  11375  @user Dios bendiga a #Colombia y autoridades @...  normal\n",
              "9202  15259  Cuando me enter칠 de que Shakira estaba saliend...  normal\n",
              "3271  10230  @user claro si los q la sacaron fueron los per...  normal"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhdWKPEZiMSR",
        "outputId": "2091318c-79eb-4545-d05d-c17fe75a98c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "incivilidad    5424\n",
              "normal         4280\n",
              "odio           2510\n",
              "Name: clase, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"clase\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLHWoi4TiMSS"
      },
      "source": [
        "### Instalar librerias\n",
        "\n",
        "Debe instalar las siguientes librer칤as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-AfecWmiMSS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi_mJozgiMST"
      },
      "source": [
        "Si lo desea, puede instalar m치s librer칤a que requiera, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfqkdt0kiMST"
      },
      "source": [
        "### Importar librer칤as\n",
        "\n",
        "En esta secci칩n, importamos la liber칤as necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librer칤as que no se en encuentran aqu칤, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4JcaTc0iMST"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.text import Text\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# importe aqu칤 sus clasificadores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phrases, Phraser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxbSG538iMSU"
      },
      "source": [
        "### An치lisis estad칤stico\n",
        "\n",
        "Para entender como esta compuesto el corpus de texto, y los principales conceptos que aborda, haremos un an치lisis estad칤stico de sus principales componentes, para esto se le pide:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_NJtqNuiMSU"
      },
      "source": [
        "#### 1. Tokenizador\n",
        "\n",
        "Como vimos en clases pasadas, el como separar los principales token de una oraci칩n no siempre es una tarea f치cil. Por lo que para separar los principales token del texto asociado a cada sentimiento se pide que defina un tokenizador, que entregue una lista de los principales tokens. Su tokenizador debe contener al menos tres expresiones regulares, que usted estime conveniente para hacer la separaci칩n de los token dentro de la oraci칩n, para ello complete le siguiente funci칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk4uTb07iMSU"
      },
      "outputs": [],
      "source": [
        "def tokenizador(oracion):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gv7CB0giMSV"
      },
      "source": [
        "En el siguiente ejemplo, se muestra un comportamiento esperado de su tokenizador, usando como ejemplo el `word_tokenize` de la librer칤a `nltk`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ibM0v0JiMSV",
        "outputId": "35ca9cd5-e8ea-4617-d3d2-37f7a00a0b2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Soy',\n",
              " 'el',\n",
              " '칰nico',\n",
              " 'que',\n",
              " 'se',\n",
              " 'ha',\n",
              " 'dado',\n",
              " 'cuenta',\n",
              " 'que',\n",
              " 'con',\n",
              " 'la',\n",
              " 'llegada',\n",
              " 'de',\n",
              " 'extranjeros',\n",
              " 'a',\n",
              " 'Chile',\n",
              " ',',\n",
              " 'los',\n",
              " 'asesinatos',\n",
              " 'aumentaron',\n",
              " 'en',\n",
              " 'numero',\n",
              " 'y',\n",
              " 'en',\n",
              " 'nivel',\n",
              " 'de',\n",
              " 'violencia',\n",
              " '.',\n",
              " 'Ya',\n",
              " 'cacharon',\n",
              " 'que',\n",
              " 'aqu칤',\n",
              " 'esta',\n",
              " 'el',\n",
              " '游']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejemplo\n",
        "\n",
        "oracion = df['texto'].sample(1).values[0]\n",
        "word_tokenize(oracion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyFsRmFhiMSV"
      },
      "source": [
        "Ahora pruebe su tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GGjvlZ8iMSW"
      },
      "outputs": [],
      "source": [
        "oracion = df['texto'].sample(1).values[0]\n",
        "tokenizador(oracion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x31twODfiMSW"
      },
      "source": [
        "Ahora responda, su tokenizador funciona igual que el provisto por la librer칤a, y si es as칤 explique porque, en caso contrario, indique las causa de porque no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR7kyQF7iMSW"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h14PvAq-iMSW"
      },
      "source": [
        "#### 2) Crear una lista de tokens.\n",
        "\n",
        "Dado que nos interesa entender cuales son los token que m치s impacto tienen dentro del corpus de texto provisto, debemos extraerlos del conjunto de entrenamiento. Para esto, guarde en la lista TODOS los token del conjunto de entrenamiento en la lista `tokens`, para separar los tokens de la oraciones utilice su tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWZX3lwhiMSX"
      },
      "outputs": [],
      "source": [
        "tokens = []\n",
        "\n",
        "# C칩digo (recuerde utilizar su tokenizador)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9SKRF7IiMSY"
      },
      "source": [
        "Para asegurarse que guardo correctamente las palabras, extraiga los primeros 10 tokens de la lista, y revise el largo de la lista. Ejecutando la siguiente l칤nea de c칩digo, ojo que el largo de la lista `tokens` debe ser cercano o mayor 300000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td5hq4c4iMSY"
      },
      "outputs": [],
      "source": [
        "print(len(tokens))\n",
        "print(tokens[:11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlH6YZoSiMSY"
      },
      "source": [
        "#### 3) An치lisis estad칤sticos los tokens.\n",
        "\n",
        "Para realizar nuestro an치lisis utilizaremos las primeras t칠cnicas en el curso:\n",
        "\n",
        "- a) Cree un gr치fico de dispersi칩n lexica (ver tutorial 2) sobre al menos 10 token escogidos al azar de la lista `tokens`, podr칤a serle 칰til usar el m칩dulo `random` de `Python`. Luego, repita el mismo gr치fico con al menos 10 `tokens` que usted considere interesante dentro del contexto del dataset. 쯇uede observar alg칰n tipo de relaci칩n entre los tokens escogidos por usted, y los escogidos azar? Explique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT3tJVMSiMSZ"
      },
      "outputs": [],
      "source": [
        "# Grafico de tokens escogidos al azar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn_RbltQiMSZ"
      },
      "outputs": [],
      "source": [
        "# Grafico de tokens escogidos por usted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1B4_xV_iMSZ"
      },
      "source": [
        "- b) Para estudiar los tokens m치s frequentes dentro del corpus, cree dos gr치fico de frecuencias (ver tutorial 2), uno con todos los tokens de la lista, y otro eliminandos las stopwords. 쯈u칠 puede decir sobre estos gr치ficos?, 쮼xiste alguna diferencia al mantener las stopwords vs a quitarlas de los tokens?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKoeX7KliMSZ"
      },
      "outputs": [],
      "source": [
        "# Grafico 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDG5VxLsiMSa"
      },
      "outputs": [],
      "source": [
        "# Grafico 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2pAVxl_iMSa"
      },
      "source": [
        "- c) Dado que siempre es importante, identificar los principales tokens mencionados en un corpus de texto, cree dos wordclouds (ver tutorial 2) sobre los tokens que obtuvo en la parte anterior, uno con stopwords y otro sin ellas. 쯈u칠 puede decir sobre estos gr치ficos?, 쮼xiste alguna diferencia al mantener las stopwords vs a quitarlas de los tokens?, considerando la parte a) existe alguna diferencia versus las palabras que usted pens칩 que era m치s interesantes?, que puede decir al respecto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAeRR1YZiMSa"
      },
      "outputs": [],
      "source": [
        "# Grafico 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J8AfuINiMSa"
      },
      "outputs": [],
      "source": [
        "# Grafico 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_XtXb8OiMSb"
      },
      "source": [
        "## Crear representaciones de texto\n",
        "\n",
        "Como hemos mencionado en las clases anteriores, los modelos de Machine Learning no son capaces de entender el texto directamente para resolver cualquier tarea. Es vital realizar un paso intermedio, que es buscar un mecanismo que permita traducir el texto a representaciones que puedan ser entendidas por los modelos de ML, y que conserven las propiedades sem치nticas y sintacticas del lenguaje. Es por esto, que en est치 secci칩n estudiaremos los m칠todos de text representation estudiados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_yZoSVGiMSj"
      },
      "source": [
        "- a) El primer m칠todo que se les solicita, es crear una representaci칩n de Bag of Words o TF-IDF (la que prefieran) utilizando la librer칤a `scikit-learn`. Para esto, puede serle 칰til revisar el tutorial tres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpeWWc6kiMSj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_n64dVDiMSk"
      },
      "source": [
        "- b) El segundo m칠todo que se les solicita, es crear una representaci칩n con word embeddings. Para esto, puede serle 칰til revisar el tutorial cuatro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYhF6Hm3iMSk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKQa25HSiMSk"
      },
      "source": [
        "## Definir clasificadores\n",
        "\n",
        "En esta parte, se procedera a entrenar, los clasificadores por cada representaci칩n de texto, creada en la parte anterior, para esto usted debe:\n",
        "\n",
        "Se sugiere revisar el tutorial 4, para recordar como utilizar los clasificadores de `scikit-learn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK8o4yBBiMSk"
      },
      "source": [
        "1. Definir los datos y las etiquetas de entrenamiento y testeo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-nGf6z9iMSk"
      },
      "outputs": [],
      "source": [
        "#separar df en entrenamiento y testing\n",
        "X_train = ...\n",
        "y_train = ...\n",
        "\n",
        "X_test = ...\n",
        "y_test = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZXAlliHiMSk"
      },
      "source": [
        "Una pregunta, que podr칤a hacerse: 쮼s necesario separar el dataset en training y testing, usando alguna funci칩n de `scikit-learn` en este caso? Fundamente:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUE_5S4hiMSl"
      },
      "source": [
        "2. Definir al menos dos clasificadores por representaci칩n:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxKJODgIiMSl"
      },
      "source": [
        "#### Bag of Words o TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwR3ZnN0iMSl"
      },
      "outputs": [],
      "source": [
        "clf1 = ...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDFbFKTDiMSl"
      },
      "outputs": [],
      "source": [
        "clf2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gquhv9F7iMSl"
      },
      "source": [
        "#### Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACUnu6LUiMSl"
      },
      "outputs": [],
      "source": [
        "clf3 = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDdqCVCKiMSl"
      },
      "outputs": [],
      "source": [
        "clf4 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tyvfoYYiMSl"
      },
      "source": [
        "Para esta secci칩n pueden utilizar cualquier clasificadores que estimen conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvUDccA9iMSm"
      },
      "source": [
        "3. Entrenar cada uno de los clasificadores desarrollados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-pTSK9hiMSm"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip6clmmziMSm"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO1K16xdiMSm"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEfGBGlxiMSn"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5zMy26iMSn"
      },
      "source": [
        "### Evaluar los clasificadores.\n",
        "\n",
        "En esta secci칩n, se espera que entregue la matriz de confusi칩n y el reporte de clasificaci칩n de los clasificadores en la secci칩n pasada. Por lo que seria 칰til estudiar las funciones `confusion_matrix` y `classification_report` de `scikit-lear`. Podr치 encontrar un ejemplo en el tutorial 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIjer8z_iMSn"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluaci칩n clasificador 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV26PdMviMSn"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluaci칩n clasificador 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8VkoD_AiMSn"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluaci칩n clasificador 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bix6uD2OiMSo"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluaci칩n clasificador 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjNWyooviMSo"
      },
      "source": [
        "Finalmente, 쯈u칠 pude decir del rendimiento de todos los clasificadores?, 쮺ree que alguna representaci칩n pudo resolver mejor la tarea? Jusfique, se espera que de un an치lsis para cada uno de los 4 clasificadores, identificado sus aciertos y fallas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
