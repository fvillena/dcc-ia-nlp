{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1\n",
    "\n",
    "### Cuerpo Docente\n",
    "\n",
    "- Profesores: [Andr칠s Abeliuk](https://aabeliuk.github.io/), [Felipe Villena](https://fabianvillena.cl/).\n",
    "- Profesor Auxiliar: [Gabriel Iturra](https://giturra.cl/)\n",
    "\n",
    "### Instrucciones generales\n",
    "\n",
    "- Grupos de m치ximo 4 personas.\n",
    "- Ausentes deber치n realizar la actividad solos.\n",
    "- Esta prohibido compartir las respuestas con otros grupos.\n",
    "- Indicios de copia ser치n penalizados con la nota m칤nima.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente, si utiliza material extra debe citarlo.\n",
    "\n",
    "\n",
    "### Integrantes\n",
    "\n",
    "> POR FAVOR AGREGAR TODOS LOS NOMBRES DE LOS INTEGRANTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "El discurso de odio es cualquier expresi칩n que promueva o incite a la discriminaci칩n, la hostilidad o la violencia hacia una persona o grupo de personas en una relaci칩n asim칠trica de poder, tal como la raza, la etnia, el g칠nero, la orientaci칩n sexual, la religi칩n, la nacionalidad, una discapacidad u otra caracter칤stica similar.\n",
    "\n",
    "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortes칤a y consideraci칩n en la interacci칩n entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
    "\n",
    "En esta tarea tendr치n a su disposici칩n un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en espa침ol de Chile. Con estos datos, deber치n entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
    "\n",
    "El corpus para esta tarea se compone de 3 datasets:  \n",
    "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
    "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
    "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
    "\n",
    "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabi치n Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computaci칩n, Universidad de Chile. \n",
    "\n",
    "Los datos solo pueden ser usados con fines de investigaci칩n y docencia. Est치 prohibida la difusi칩n externa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para el siguiente informe deben:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la siguente tarea deber치 revolver una tarea de multi-clasificaci칩n, realizando los siguentes pasos:\n",
    "\n",
    "- Realizar un an치lisis estad칤stico del corpus.\n",
    "- Crear tres tipos de text representation.\n",
    "- Desarrollar al menos tres tipos de clasificadores que resuelvan la tarea.\n",
    "- An치lizar sus resultados.\n",
    "\n",
    "Sin embargo, primero cargaremos el datataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar dataset\n",
    "\n",
    "En esta secci칩n, cargaremos el dataset desde el repositorio del m칩dulo. Para ello ejecute las siguientes l칤neas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de entrenamiento.\n",
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Dataset que deber치n predecir para la competencia.\n",
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/target/target.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizar los datos\n",
    "\n",
    "En esta secci칩n analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texto</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>13085</td>\n",
       "      <td>La recalcada put칤sima de mierda y la concha de...</td>\n",
       "      <td>odio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5578</th>\n",
       "      <td>7613</td>\n",
       "      <td>@user @user No es que los gaymers chilenos sea...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>11375</td>\n",
       "      <td>@user Dios bendiga a #Colombia y autoridades @...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>15259</td>\n",
       "      <td>Cuando me enter칠 de que Shakira estaba saliend...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>10230</td>\n",
       "      <td>@user claro si los q la sacaron fueron los per...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              texto   clase\n",
       "9466  13085  La recalcada put칤sima de mierda y la concha de...    odio\n",
       "5578   7613  @user @user No es que los gaymers chilenos sea...  normal\n",
       "2204  11375  @user Dios bendiga a #Colombia y autoridades @...  normal\n",
       "9202  15259  Cuando me enter칠 de que Shakira estaba saliend...  normal\n",
       "3271  10230  @user claro si los q la sacaron fueron los per...  normal"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incivilidad    5424\n",
       "normal         4280\n",
       "odio           2510\n",
       "Name: clase, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"clase\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar librerias\n",
    "\n",
    "Debe instalar las siguientes librer칤as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo desea, puede instalar m치s librer칤a que requiera, pero debe citar su fuente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librer칤as\n",
    "\n",
    "En esta secci칩n, importamos la liber칤as necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librer칤as que no se en encuentran aqu칤, pero debe citar su fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.text import Text\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# importe aqu칤 sus clasificadores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# word2vec\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.phrases import Phrases, Phraser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An치lisis estad칤stico\n",
    "\n",
    "Para entender como esta compuesto el corpus de texto, y los principales conceptos que aborda, haremos un an치lisis estad칤stico de sus principales componentes, para esto se le pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tokenizador\n",
    "\n",
    "Como vimos en clases pasadas, el como separar los principales token de una oraci칩n no siempre es una tarea f치cil. Por lo que para separar los principales token del texto asociado a cada sentimiento se pide que defina un tokenizador, que entregue una lista de los principales tokens. Su tokenizador debe contener al menos tres expresiones regulares, que usted estime conveniente para hacer la separaci칩n de los token dentro de la oraci칩n, para ello complete le siguiente funci칩n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizador(oracion):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra un comportamiento esperado de su tokenizador, usando como ejemplo el `word_tokenize` de la librer칤a `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Soy',\n",
       " 'el',\n",
       " '칰nico',\n",
       " 'que',\n",
       " 'se',\n",
       " 'ha',\n",
       " 'dado',\n",
       " 'cuenta',\n",
       " 'que',\n",
       " 'con',\n",
       " 'la',\n",
       " 'llegada',\n",
       " 'de',\n",
       " 'extranjeros',\n",
       " 'a',\n",
       " 'Chile',\n",
       " ',',\n",
       " 'los',\n",
       " 'asesinatos',\n",
       " 'aumentaron',\n",
       " 'en',\n",
       " 'numero',\n",
       " 'y',\n",
       " 'en',\n",
       " 'nivel',\n",
       " 'de',\n",
       " 'violencia',\n",
       " '.',\n",
       " 'Ya',\n",
       " 'cacharon',\n",
       " 'que',\n",
       " 'aqu칤',\n",
       " 'esta',\n",
       " 'el',\n",
       " '游']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "\n",
    "oracion = train_df['texto'].sample(1).values[0]\n",
    "word_tokenize(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pruebe su tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion = train_df['texto'].sample(1).values[0]\n",
    "tokenizador(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora responda, su tokenizador funciona igual que el provisto por la librer칤a, y si es as칤 explique porque, en caso contrario, indique las causa de porque no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Crear una lista de tokens.\n",
    "\n",
    "Dado que nos interesa entender cuales son los token que m치s impacto tienen dentro del corpus de texto provisto, debemos extraerlos del conjunto de entrenamiento. Para esto, guarde en la lista TODOS los token del conjunto de entrenamiento en la lista `tokens`, para separar los tokens de la oraciones utilice su tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "# C칩digo (recuerde utilizar su tokenizador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurarse que guardo correctamente las palabras, extraiga los primeros 10 tokens de la lista, y revise el largo de la lista. Ejecutando la siguiente l칤nea de c칩digo, ojo que el largo de la lista `tokens` debe ser cercano o mayor 300000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokens))\n",
    "print(tokens[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) An치lisis estad칤sticos los tokens.\n",
    "\n",
    "Para realizar nuestro an치lisis utilizaremos las primeras t칠cnicas en el curso:\n",
    "\n",
    "- a) Cree un gr치fico de dispersi칩n lexica (ver tutorial 2) sobre al menos 10 token escogidos al azar de la lista `tokens`, podr칤a serle 칰til usar el m칩dulo `random` de `Python`. Luego, repita el mismo gr치fico con al menos 10 `tokens` que usted considere interesante dentro del contexto del dataset. 쯇uede observar alg칰n tipo de relaci칩n entre los tokens escogidos por usted, y los escogidos azar? Explique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de tokens escogidos al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de tokens escogidos por usted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) Para estudiar los tokens m치s frequentes dentro del corpus, cree dos gr치fico de frecuencias (ver tutorial 2), uno con todos los tokens de la lista, y otro eliminandos las stopwords. 쯈u칠 puede decir sobre estos gr치ficos?, 쮼xiste alguna diferencia al mantener las stopwords vs a quitarlas de los tokens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) Dado que siempre es importante, identificar los principales tokens mencionados en un corpus de texto, cree dos wordclouds (ver tutorial 2) sobre los tokens que obtuvo en la parte anterior, uno con stopwords y otro sin ellas. 쯈u칠 puede decir sobre estos gr치ficos?, 쮼xiste alguna diferencia al mantener las stopwords vs a quitarlas de los tokens?, considerando la parte a) existe alguna diferencia versus las palabras que usted pens칩 que era m치s interesantes?, que puede decir al respecto? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear representaciones de texto\n",
    "\n",
    "Como hemos mencionado en las clases anteriores, los modelos de Machine Learning no son capaces de entender el texto directamente para resolver cualquier tarea. Es vital realizar un paso intermedio, que es buscar un mecanismo que permita traducir el texto a representaciones que puedan ser entendidas por los modelos de ML, y que conserven las propiedades sem치nticas y sintacticas del lenguaje. Es por esto, que en est치 secci칩n estudiaremos los m칠todos de text representation estudiados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) El primer m칠todo que se les solicita, es crear una representaci칩n de Bag of Words utilizando la librer칤a `scikit-learn`. Para esto, puede serle 칰til revisar el tutorial tres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) El segundo m칠todo que se les solicita, es crear una representaci칩n de TF-IDF utilizando la librer칤a `scikit-learn`. Para esto, puede serle 칰til revisar el tutorial tres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) El tercer m칠todo que se les solicita, es crear una representaci칩n basada en Word Embeddings utilizando la librer칤a `gensim`. Para esto, puede serle 칰til revisar el tutorial cuatro.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d) Dado que los primeros dos m칠todos, BOW y TF-IDF, son m칠todos que codifican el texto a nivel de oraci칩n, para el caso de los Word Embeddings, la codificaci칩n se realizar a nivel de token, por lo que es necesario desarrollar un m칠todo para codificar las oraciones usando los Word Embeddings de la parte anterior. Para esto, se le pide implementar una clase `Doc2Vec`, que utilice los Word Embeddings y una funci칩n de agregaci칩n (suma, promedio, m치ximo o m칤nimos) para definir la codificaci칩n a nivel de oracion. Se le recomienda revisar el tutorial 4 para insipirarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Transforma tweets a representaciones vectoriales usando alg칰n modelo de Word Embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, aggregation_func):\n",
    "        # Implementar\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # Implementar\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir clasificadores\n",
    "\n",
    "En esta parte, se procedera a entrenar, los clasificadores por cada representaci칩n de texto, creada en la parte anterior, para esto usted debe:\n",
    "\n",
    "Se sugiere revisar el tutorial 4, para recordar como utilizar los clasificadores de `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definir los datos y las etiquetas de entrenamiento y testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "y_train = ...\n",
    "\n",
    "X_test = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una pregunta, que podr칤a hacerse: 쮼s necesario separar el dataset en training y testing, usando alguna funci칩n de `scikit-learn` en este caso? Fundamente:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definir al menos dos clasificadores por representaci칩n:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta secci칩n pueden utilizar cualquier clasificadores que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Entrenar cada uno de los clasificadores desarrollados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar los clasificadores.\n",
    "\n",
    "En esta secci칩n, se espera que entregue la matriz de confusi칩n y el reporte de clasificaci칩n de los clasificadores en la secci칩n pasada. Por lo que seria 칰til estudiar las funciones `confusion_matrix` y `classification_report` de `scikit-lear`. Podr치 encontrar un ejemplo en el tutorial 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluaci칩n clasificador 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluaci칩n clasificador 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluaci칩n clasificador 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluaci칩n clasificador 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluaci칩n clasificador 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluaci칩n clasificador 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, 쯈u칠 pude decir del rendimiento de todos los clasificadores?, 쮺ree que alguna representaci칩n pudo resolver mejor la tarea? Jusfique, se espera que de un an치lsis para cada uno de los 6 clasificadores, identificado sus aciertos y fallas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
