{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1\n",
    "\n",
    "### Cuerpo Docente\n",
    "\n",
    "- Profesores: [Andrés Abeliuk](https://aabeliuk.github.io/), [Felipe Villena](https://fabianvillena.cl/).\n",
    "- Profesor Auxiliar: [Gabriel Iturra](https://giturra.cl/)\n",
    "\n",
    "### Instrucciones generales\n",
    "\n",
    "- Grupos de máximo 4 personas.\n",
    "- Ausentes deberán realizar la actividad solos.\n",
    "- Esta prohibido compartir las respuestas con otros grupos.\n",
    "- Indicios de copia serán penalizados con la nota mínima.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente, si utiliza material extra debe citarlo.\n",
    "\n",
    "\n",
    "### Integrantes\n",
    "\n",
    "> POR FAVOR AGREGAR TODOS LOS NOMBRES DE LOS INTEGRANTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "El discurso de odio es cualquier expresión que promueva o incite a la discriminación, la hostilidad o la violencia hacia una persona o grupo de personas en una relación asimétrica de poder, tal como la raza, la etnia, el género, la orientación sexual, la religión, la nacionalidad, una discapacidad u otra característica similar.\n",
    "\n",
    "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortesía y consideración en la interacción entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
    "\n",
    "En esta tarea tendrán a su disposición un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en español de Chile. Con estos datos, deberán entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
    "\n",
    "El corpus para esta tarea se compone de 3 datasets:  \n",
    "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
    "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
    "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
    "\n",
    "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabián Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computación, Universidad de Chile. \n",
    "\n",
    "Los datos solo pueden ser usados con fines de investigación y docencia. Está prohibida la difusión externa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para el siguiente informe deben:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la siguente tarea deberá revolver una tarea de multi-clasificación, realizando los siguentes pasos:\n",
    "\n",
    "- Realizar un análisis estadístico del corpus.\n",
    "- Crear tres tipos de text representation.\n",
    "- Desarrollar al menos tres tipos de clasificadores que resuelvan la tarea.\n",
    "- Análizar sus resultados.\n",
    "\n",
    "Sin embargo, primero cargaremos el datataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar dataset\n",
    "\n",
    "En esta sección, cargaremos el dataset desde el repositorio del módulo. Para ello ejecute las siguientes líneas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de entrenamiento.\n",
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Dataset que deberán predecir para la competencia.\n",
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/target/target.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizar los datos\n",
    "\n",
    "En esta sección analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texto</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>13085</td>\n",
       "      <td>La recalcada putísima de mierda y la concha de...</td>\n",
       "      <td>odio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5578</th>\n",
       "      <td>7613</td>\n",
       "      <td>@user @user No es que los gaymers chilenos sea...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>11375</td>\n",
       "      <td>@user Dios bendiga a #Colombia y autoridades @...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>15259</td>\n",
       "      <td>Cuando me enteré de que Shakira estaba saliend...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>10230</td>\n",
       "      <td>@user claro si los q la sacaron fueron los per...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              texto   clase\n",
       "9466  13085  La recalcada putísima de mierda y la concha de...    odio\n",
       "5578   7613  @user @user No es que los gaymers chilenos sea...  normal\n",
       "2204  11375  @user Dios bendiga a #Colombia y autoridades @...  normal\n",
       "9202  15259  Cuando me enteré de que Shakira estaba saliend...  normal\n",
       "3271  10230  @user claro si los q la sacaron fueron los per...  normal"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incivilidad    5424\n",
       "normal         4280\n",
       "odio           2510\n",
       "Name: clase, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"clase\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar librerias\n",
    "\n",
    "Debe instalar las siguientes librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo desea, puede instalar más librería que requiera, pero debe citar su fuente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías\n",
    "\n",
    "En esta sección, importamos la liberías necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librerías que no se en encuentran aquí, pero debe citar su fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.text import Text\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# importe aquí sus clasificadores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# word2vec\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.phrases import Phrases, Phraser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis estadístico\n",
    "\n",
    "Para entender como esta compuesto el corpus de texto, y los principales conceptos que aborda, haremos un análisis estadístico de sus principales componentes, para esto se le pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tokenizador\n",
    "\n",
    "Como vimos en clases pasadas, el como separar los principales token de una oración no siempre es una tarea fácil. Por lo que para separar los principales token del texto asociado a cada sentimiento se pide que defina un tokenizador, que entregue una lista de los principales tokens. Su tokenizador debe contener al menos tres expresiones regulares, que usted estime conveniente para hacer la separación de los token dentro de la oración, para ello complete le siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizador(oracion):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra un comportamiento esperado de su tokenizador, usando como ejemplo el `word_tokenize` de la librería `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Soy',\n",
       " 'el',\n",
       " 'único',\n",
       " 'que',\n",
       " 'se',\n",
       " 'ha',\n",
       " 'dado',\n",
       " 'cuenta',\n",
       " 'que',\n",
       " 'con',\n",
       " 'la',\n",
       " 'llegada',\n",
       " 'de',\n",
       " 'extranjeros',\n",
       " 'a',\n",
       " 'Chile',\n",
       " ',',\n",
       " 'los',\n",
       " 'asesinatos',\n",
       " 'aumentaron',\n",
       " 'en',\n",
       " 'numero',\n",
       " 'y',\n",
       " 'en',\n",
       " 'nivel',\n",
       " 'de',\n",
       " 'violencia',\n",
       " '.',\n",
       " 'Ya',\n",
       " 'cacharon',\n",
       " 'que',\n",
       " 'aquí',\n",
       " 'esta',\n",
       " 'el',\n",
       " '🧀']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo\n",
    "\n",
    "oracion = train_df['texto'].sample(1).values[0]\n",
    "word_tokenize(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pruebe su tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion = train_df['texto'].sample(1).values[0]\n",
    "tokenizador(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora responda, su tokenizador funciona igual que el provisto por la librería, y si es así explique porque, en caso contrario, indique las causa de porque no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Crear una lista de tokens.\n",
    "\n",
    "Dado que nos interesa entender cuales son los token que más impacto tienen dentro del corpus de texto provisto, debemos extraerlos del conjunto de entrenamiento. Para esto, guarde en la lista TODOS los token del conjunto de entrenamiento en la lista `tokens`, para separar los tokens de la oraciones utilice su tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "# Código (recuerde utilizar su tokenizador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurarse que guardo correctamente las palabras, extraiga los primeros 10 tokens de la lista, y revise el largo de la lista. Ejecutando la siguiente línea de código, ojo que el largo de la lista `tokens` debe ser cercano o mayor 300000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokens))\n",
    "print(tokens[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Análisis estadísticos los tokens.\n",
    "\n",
    "Para realizar nuestro análisis utilizaremos las primeras técnicas en el curso:\n",
    "\n",
    "- a) Cree un gráfico de dispersión lexica (ver tutorial 2) sobre al menos 10 token escogidos al azar de la lista `tokens`, podría serle útil usar el módulo `random` de `Python`. Luego, repita el mismo gráfico con al menos 10 `tokens` que usted considere interesante dentro del contexto del dataset. ¿Puede observar algún tipo de relación entre los tokens escogidos por usted, y los escogidos azar? Explique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de tokens escogidos al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de tokens escogidos por usted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) Para estudiar los tokens más frequentes dentro del corpus, cree dos gráfico de frecuencias (ver tutorial 2), uno con todos los tokens de la lista, y otro eliminandos las stopwords. ¿Qué puede decir sobre estos gráficos?, ¿Existe alguna diferencia al mantener las stopwords vs a quitarlas de los tokens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) Dado que siempre es importante, identificar los principales tokens mencionados en un corpus de texto, cree dos wordclouds (ver tutorial 2) sobre los tokens que obtuvo en la parte anterior, uno con stopwords y otro sin ellas. ¿Qué puede decir sobre estos gráficos?, ¿Existe alguna diferencia al mantener las stopwords vs a quitarlas de los tokens?, considerando la parte a) existe alguna diferencia versus las palabras que usted pensó que era más interesantes?, que puede decir al respecto? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear representaciones de texto\n",
    "\n",
    "Como hemos mencionado en las clases anteriores, los modelos de Machine Learning no son capaces de entender el texto directamente para resolver cualquier tarea. Es vital realizar un paso intermedio, que es buscar un mecanismo que permita traducir el texto a representaciones que puedan ser entendidas por los modelos de ML, y que conserven las propiedades semánticas y sintacticas del lenguaje. Es por esto, que en está sección estudiaremos los métodos de text representation estudiados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) El primer método que se les solicita, es crear una representación de Bag of Words utilizando la librería `scikit-learn`. Para esto, puede serle útil revisar el tutorial tres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) El segundo método que se les solicita, es crear una representación de TF-IDF utilizando la librería `scikit-learn`. Para esto, puede serle útil revisar el tutorial tres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- c) El tercer método que se les solicita, es crear una representación basada en Word Embeddings utilizando la librería `gensim`. Para esto, puede serle útil revisar el tutorial cuatro.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d) Dado que los primeros dos métodos, BOW y TF-IDF, son métodos que codifican el texto a nivel de oración, para el caso de los Word Embeddings, la codificación se realizar a nivel de token, por lo que es necesario desarrollar un método para codificar las oraciones usando los Word Embeddings de la parte anterior. Para esto, se le pide implementar una clase `Doc2Vec`, que utilice los Word Embeddings y una función de agregación (suma, promedio, máximo o mínimos) para definir la codificación a nivel de oracion. Se le recomienda revisar el tutorial 4 para insipirarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Transforma tweets a representaciones vectoriales usando algún modelo de Word Embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, aggregation_func):\n",
    "        # Implementar\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # Implementar\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir clasificadores\n",
    "\n",
    "En esta parte, se procedera a entrenar, los clasificadores por cada representación de texto, creada en la parte anterior, para esto usted debe:\n",
    "\n",
    "Se sugiere revisar el tutorial 4, para recordar como utilizar los clasificadores de `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definir los datos y las etiquetas de entrenamiento y testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "y_train = ...\n",
    "\n",
    "X_test = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una pregunta, que podría hacerse: ¿Es necesario separar el dataset en training y testing, usando alguna función de `scikit-learn` en este caso? Fundamente:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definir al menos dos clasificadores por representación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta sección pueden utilizar cualquier clasificadores que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Entrenar cada uno de los clasificadores desarrollados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento classificador 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar los clasificadores.\n",
    "\n",
    "En esta sección, se espera que entregue la matriz de confusión y el reporte de clasificación de los clasificadores en la sección pasada. Por lo que seria útil estudiar las funciones `confusion_matrix` y `classification_report` de `scikit-lear`. Podrá encontrar un ejemplo en el tutorial 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluación clasificador 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluación clasificador 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluación clasificador 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluación clasificador 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluación clasificador 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informe de evaluación clasificador 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, ¿Qué pude decir del rendimiento de todos los clasificadores?, ¿Cree que alguna representación pudo resolver mejor la tarea? Jusfique, se espera que de un análsis para cada uno de los 6 clasificadores, identificado sus aciertos y fallas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
